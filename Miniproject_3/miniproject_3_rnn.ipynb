{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.callbacks import LambdaCallback\n",
    "import sys\n",
    "import random\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in text, lower case\n",
    "text_full = open(os.path.join(os.getcwd(), 'data/shakespeare.txt')).read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove numbers\n",
    "text_no_num = ''.join([i for i in text_full if not i.isdigit()])\n",
    "# remove new lines\n",
    "text_no_nline = text_no_num.replace(\"\\n\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation and tabs\n",
    "\n",
    "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "no_punct = \"\"\n",
    "for char in text_no_nline:\n",
    "    if char not in punctuations:\n",
    "        no_punct = no_punct + char\n",
    "\n",
    "text = re.sub(' +', ' ', no_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 27\n"
     ]
    }
   ],
   "source": [
    "# from https://keras.io/examples/lstm_text_generation/\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 29602\n"
     ]
    }
   ],
   "source": [
    "# from https://keras.io/examples/lstm_text_generation/\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### turn to one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://keras.io/examples/lstm_text_generation/\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 125)               76500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 27)                3402      \n",
      "=================================================================\n",
      "Total params: 79,902\n",
      "Trainable params: 79,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(125, input_shape=(x.shape[1], x.shape[2])))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from https://keras.io/examples/lstm_text_generation/\n",
    "\n",
    "# def sample(preds, temperature=1.0):\n",
    "#     # helper function to sample an index from a probability array\n",
    "    \n",
    "#     preds = np.asarray(preds).astype('float64')\n",
    "#     # take log of predictions and scale by temperature (why take log?)\n",
    "#     preds = np.exp(np.log(preds) / temperature)\n",
    "#     # scale back to 1 \n",
    "#     preds = preds / np.sum(preds)\n",
    "#     # sample a distribution, return an array with 1 at choice\n",
    "#     probas = np.random.multinomial(1, preds, 1)\n",
    "#     # return argument (index) that produced choice\n",
    "#     return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from https://keras.io/examples/lstm_text_generation/\n",
    "# # change to prevent log(0)\n",
    "\n",
    "# def sample(preds, temperature=1.0):\n",
    "#     # helper function to sample an index from a probability array\n",
    "    \n",
    "#     preds = np.asarray(preds).astype('float64')\n",
    "    \n",
    "#     if any(preds==0) or any(np.log(preds) < -15):\n",
    "# #         preds[np.where(preds==0)[0][0]] = np.nan\n",
    "#         preds[np.where(np.log(preds) < -15)[0][0]] = np.nan\n",
    "              \n",
    "#     else:\n",
    "#         pass\n",
    "        \n",
    "#     # take log of predictions and scale by temperature (why take log?)\n",
    "#     preds = np.exp(np.log(preds) / temperature)\n",
    "#     # scale back to 1 \n",
    "#     preds = preds / np.nansum(preds)\n",
    "    \n",
    "    \n",
    "#     # convert nans back to 0\n",
    "#     if any(np.isnan(preds)):\n",
    "#         preds[np.where(np.isnan(preds))[0][0]] = 0.\n",
    "#     else:\n",
    "#         pass\n",
    "    \n",
    "#     # sample a distribution, return an array with 1 at choice\n",
    "#     probas = np.random.multinomial(1, preds, 1)\n",
    "#     # return argument (index) that produced choice\n",
    "#     return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from https://keras.io/examples/lstm_text_generation/\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    \n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    # scale by temp\n",
    "    preds = preds / temperature\n",
    "\n",
    "    # rescale to 1\n",
    "    preds = preds/ np.sum(preds)\n",
    "    # sample a distribution, return an array with 1 at choice\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    # return argument (index) that produced choice\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 28s - loss: 2.5475 - accuracy: 0.2645\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"saucy bark inferior far to hison your br\"\n",
      "saucy bark inferior far to hison your brvciss aps aptstty than haml twes aaig wout akit ot wist fhesuaceetilidaad thiu favingis tftus amd men art amd thild croty ceapasin hit wish to te may tltem mriin ti the ave byt dinghald aims hestive wesoeskrt aotthetuthoui oar fyceansy sas ile ser  lhacilswobjthule thaveengured waind hirlouts areth ny makt till iatthouko delc npaelend lo ty tou ceeit waru hot  hesanytt mt the maslssfor fhe py myua\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"saucy bark inferior far to hison your br\"\n",
      "saucy bark inferior far to hison your brafdssd elled thy sethoubrt sf are yis rginsue te mesemtr ce bom thhtcprulgith sy ans yirh stur dwine ooungi v ens meis mheseurhasis thile scodutit bouad ntlos inf ond with ring yhephy thigt cave t thetsenthoushoais n iil mewe meith ons valtwed hing lonssutmr vethithos ahe tou pstich cienbler prevesto id sim llaveol ialtiil t re fiov t arose fise sesmmwucefote thswh lass ghelpot be s brmeras frare \n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"saucy bark inferior far to hison your br\"\n",
      "saucy bark inferior far to hison your bre iognte sati heane sillass pon rive enthediutiam mutheme cet soc ure s isssdass patt siwhe ine shjsedis tie lto gallsurwesge thohee coatt thecs sin dor thou ghats ymerrif erastf arletir bol de mis thingeenth mes mind foruthint at oasest ire io giathansr loe le thett ivemosmiy s tytestt xon weagheadeeeito shins thamn fisdinge fhs wedei wy chat thes teek che thunnet shve cot pamed afttalkey rit ain\n",
      "Epoch 2/10\n",
      " - 28s - loss: 2.2034 - accuracy: 0.3486\n",
      "Epoch 3/10\n",
      " - 28s - loss: 2.0840 - accuracy: 0.3787\n",
      "Epoch 4/10\n",
      " - 27s - loss: 1.9965 - accuracy: 0.4027\n",
      "Epoch 5/10\n",
      " - 29s - loss: 1.9253 - accuracy: 0.4236\n",
      "Epoch 6/10\n",
      " - 30s - loss: 1.8623 - accuracy: 0.4400\n",
      "Epoch 7/10\n",
      " - 30s - loss: 1.8094 - accuracy: 0.4540\n",
      "Epoch 8/10\n",
      " - 26s - loss: 1.7597 - accuracy: 0.4660\n",
      "Epoch 9/10\n",
      " - 26s - loss: 1.7126 - accuracy: 0.4796\n",
      "Epoch 10/10\n",
      " - 25s - loss: 1.6682 - accuracy: 0.4874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x637c99c10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=32, epochs=10, verbose=2, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"em yet so they mourn becoming of their w\"\n",
      "em yet so they mourn becoming of their with ear borngadd seef thet shill to urcele my doed thinfwhere in the fariress deefitper asupceoring shill of reevireand thees preivefto that ceiqunes butrs to hew thut shillh love whon and the eyes thine my seine thy nour fools of this saifors his and what whicth maise my groce no ded roting forsed in thy besmy forcemour guines whore no houly ang heftone and thou mayils make love lise arigut heave----- temperature: 0.75\n",
      "----- Generating with seed: \"em yet so they mourn becoming of their w\"\n",
      "em yet so they mourn becoming of their willand the braye therethile love an besundbethatkit all ald thot thou thougabst furse no can thou shaule deof chose this everys welo hisone meaneed wheir and mreathoot as the busts tery stor vargrouby thee my all this bricks wonts mise hight i theets thiewhin the faor dithet foo this my loves if the fordfaresedizeand do thines mey i moud i digh ore prowest so proveing bus sheps in lave as it prigb----- temperature: 1.5\n",
      "----- Generating with seed: \"em yet so they mourn becoming of their w\"\n",
      "em yet so they mourn becoming of their wakl bedowhings the purtthought arn uppetwhen patereant that bore love can their theyrs dachs doak but do merthandid which hainthosisweit fartrif that whis which firved on loved exes me wond boweon tismir or thine hore thy lood eakthy needhe for should blaces of thith heartt formedoudess bit to sueswond bitwhou of fale thou wheedto pensing ho cavein forthoogh that forment is come thou never kexsing"
     ]
    }
   ],
   "source": [
    "gen_sonnet_(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://keras.io/examples/lstm_text_generation/\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "    # print only 10th epoch\n",
    "    if epoch%100==0:\n",
    "        print()\n",
    "        print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "        for temperature in [0.25, 0.75, 1.5]:\n",
    "            print('----- temperature:', temperature)\n",
    "\n",
    "            generated = ''\n",
    "            sentence = text[start_index: start_index + maxlen]\n",
    "            generated += sentence\n",
    "            print('----- Generating with seed: \"' + sentence + '\"')\n",
    "            sys.stdout.write(generated)\n",
    "\n",
    "            for i in range(400):\n",
    "                x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                preds = model.predict(x_pred, verbose=0)[0]\n",
    "                next_index = sample(preds, temperature)\n",
    "                next_char = indices_char[next_index]\n",
    "\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "            print()\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 27s - loss: 0.8847 - accuracy: 0.7301\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"son music to hear why hearst thou music \"\n",
      "son music to hear why hearst thou music and thee the world mouth re painted how a fomen forthing and so so thou the world i to keed for thy sunfeathert me dis caired thee beauty one womblong of my sweet were it not than my self a long have preasor of the fairt a a send the beauty on your self and thee thee belies summers with lost and contould me doth long hast where it not thou art i am not love and this paress by yet are gondless by t\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"son music to hear why hearst thou music \"\n",
      "son music to hear why hearst thou music comed be endand the forghts on the ramethou akn that mull for all meame doth londs crouch pottricet it st oll whor be endle butl you tremes wore thoughtshenger muli shall the self for this pleing math not to be st leave whose be night dils peril add at thy giedt corfind yet the world at sexplese yet to mine eyes that thou art for thee mone not part brom sill see the still thing and blacks pittare \n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"son music to hear why hearst thou music \"\n",
      "son music to hear why hearst thou music dowers eyeth poot he paitured onwtrusting dile dodill you ble semare make as eyethenrpeeos mand othere fair fouthstrounge diefglith what to gpordand nair eys tonguetuin san and my sugains eyestore thay me sughto frop from homp nos sween ofn sarkly behavencpetivntyephtysuthout fortann with all my mreed in thinears now his sape it cadracyed a veaveoved of now are skill fimrestne eppaisemaved sanmest\n",
      "Epoch 2/100\n",
      " - 25s - loss: 0.8441 - accuracy: 0.7430\n",
      "Epoch 3/100\n",
      " - 25s - loss: 0.8185 - accuracy: 0.7534\n",
      "Epoch 4/100\n",
      " - 25s - loss: 0.7900 - accuracy: 0.7604\n",
      "Epoch 5/100\n",
      " - 25s - loss: 0.7631 - accuracy: 0.7684\n",
      "Epoch 6/100\n",
      " - 25s - loss: 0.7365 - accuracy: 0.7779\n",
      "Epoch 7/100\n",
      " - 25s - loss: 0.7105 - accuracy: 0.7872\n",
      "Epoch 8/100\n",
      " - 25s - loss: 0.6941 - accuracy: 0.7909\n",
      "Epoch 9/100\n",
      " - 25s - loss: 0.6682 - accuracy: 0.7982\n",
      "Epoch 10/100\n",
      " - 27s - loss: 0.6482 - accuracy: 0.8049\n",
      "Epoch 11/100\n",
      " - 25s - loss: 0.6317 - accuracy: 0.8084\n",
      "\n",
      "----- Generating text after Epoch: 10\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"eem so some glory in their birth some in\"\n",
      "eem so some glory in their birth some in every but speater and see such raseth ootraking away i have spripe stralges more her i cankst loves th some bright thou then when their shall which phoudd of shade part i to be of meaut thou art it see me dott me a faired and were forghthe beauty mistins ere yethe mude chould not the sine so more and their shairss me beautys not thy loves and where it no this that with thee beautys for where it n\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"eem so some glory in their birth some in\"\n",
      "eem so some glory in their birth some in every barge brow pares of me was deeyed with mastery being criveand your for fare in the furleweth longs and their should deefows waile comitation ot some that with derewrant with her loveang of thy fair and then not blow shoulds ablir well in then your see for as will be ard but dith fors for agained think eyes fore from ablind ends quion in do no there arthe butl giod and their thee muentied so\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"eem so some glory in their birth some in\"\n",
      "eem so some glory in their birth some in love t me but swentyes boliss his gruenobhwazer nowarch of nithin lounts upesines glosw is blood unfover tombred againge that i quise thou art boob shild dore doth his ade flom are mento matile that thou pomin tas thruebhedd me san sembed shall dasmed endoes evew love owt wridn ar a beauty of thoughts umpanqsowife oth self arpleach of athen ahgueesnue as eyes versefcrowthis ploadss dithine berisu\n",
      "Epoch 12/100\n",
      " - 28s - loss: 0.6160 - accuracy: 0.8134\n",
      "Epoch 13/100\n",
      " - 35s - loss: 0.6183 - accuracy: 0.8114\n",
      "Epoch 14/100\n",
      " - 29s - loss: 0.5855 - accuracy: 0.8217\n",
      "Epoch 15/100\n",
      " - 27s - loss: 0.5617 - accuracy: 0.8319\n",
      "Epoch 16/100\n",
      " - 38s - loss: 0.5999 - accuracy: 0.8138\n",
      "Epoch 17/100\n",
      " - 32s - loss: 0.5291 - accuracy: 0.8417\n",
      "Epoch 18/100\n",
      " - 31s - loss: 0.5304 - accuracy: 0.8397\n",
      "Epoch 19/100\n",
      " - 25s - loss: 0.5250 - accuracy: 0.8424\n",
      "Epoch 20/100\n",
      " - 25s - loss: 0.5168 - accuracy: 0.8416\n",
      "Epoch 21/100\n",
      " - 27s - loss: 0.5203 - accuracy: 0.8430\n",
      "\n",
      "----- Generating text after Epoch: 20\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \" well which thou must leave ere long but\"\n",
      " well which thou must leave ere long but dildrace be cained mutthin thy blesst mully refombly forn havet no breaser with loty hate muss comen than gove in war all me groroty hath on thy sweet asmice with time ford forbeartif thee thee me doth lost histhauth my sungentardes that mine eye comboring his sweet meast wincroms shorn that painst aulthe bester laving agare what ame browst thy sweet remowncase doth master me truth frounse best i\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \" well which thou must leave ere long but\"\n",
      " well which thou must leave ere long but showst loves me dooknwhen i radt be not brew thee beamion then my me my stwir thy mull still with my deeing your sonfand your full me deart for my stion that thou foob you dat riseto canna marbear with thee beauty with supprissiou alatt and refortund forth in heaven to most meant rome so dellestf comot with time for forbes berfugh did growso dights my staynothauth how is thineats and heavaths sha\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \" well which thou must leave ere long but\"\n",
      " well which thou must leave ere long but distclestim be the bebutet deadthe veist not toustneye dissine lowe wonbriming didie chougace he alebliong fait now conean boten boon that his vurked notquention hist what hours ever when toobe on bentsa them boode hati in my eyest rudwstme since basts nor treesell lake that should dath molity lapk now treespentleswhen looks have leaknanch living hou which excrersel by my jreghine fraws proud as \n",
      "Epoch 22/100\n",
      " - 26s - loss: 0.4934 - accuracy: 0.8512\n",
      "Epoch 23/100\n",
      " - 25s - loss: 0.4920 - accuracy: 0.8515\n",
      "Epoch 24/100\n",
      " - 25s - loss: 0.4869 - accuracy: 0.8524\n",
      "Epoch 25/100\n",
      " - 25s - loss: 0.4702 - accuracy: 0.8574\n",
      "Epoch 26/100\n",
      " - 26s - loss: 0.4527 - accuracy: 0.8624\n",
      "Epoch 27/100\n",
      " - 25s - loss: 0.4448 - accuracy: 0.8653\n",
      "Epoch 28/100\n",
      " - 25s - loss: 0.4351 - accuracy: 0.8670\n",
      "Epoch 29/100\n",
      " - 26s - loss: 0.4440 - accuracy: 0.8639\n",
      "Epoch 30/100\n",
      " - 25s - loss: 0.4396 - accuracy: 0.8630\n",
      "Epoch 31/100\n",
      " - 25s - loss: 0.4296 - accuracy: 0.8705\n",
      "\n",
      "----- Generating text after Epoch: 30\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"waydeaths second self that seals up all \"\n",
      "waydeaths second self that seals up all more behemion is me dis came so born the lose poor dead not so all more yee to grestwere me i jownce that but farr to be a faired and strengt my beauty lives did my heartand plack and this chenks creasory when my sout fram felselfor cany in it selfous penil as i hatt his heavence make merso then my love what so then vingand dut i ant more are may then die the best as buring thy sunk when my sout f\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"waydeaths second self that seals up all \"\n",
      "waydeaths second self that seals up all me pryist as thou love and their shall whose be endencest wook not thou dost be doth provour do lov thee is not so murur ene formed to may eyes me brew there of my sade delive selfor can be muds to the by ended of not i am notrang aweals for my love as and ent becomebuting othing here or my his wearth long lacks which hell my rusten sommot i to file with uring of ruceand have plain and shord do wo\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"waydeaths second self that seals up all \"\n",
      "waydeaths second self that seals up all tomplading ownermoretyes huse show can leppaceand hourse the bestme whorccuees not love what houdd word dassa then hourss die is huspand murele bad my veate my charty is fuer yet mestormey blest or thy healt for my love haws i love flech proodant worsst cheat it as beht keol desefor will be fide is seep to reasomons ever leidur ing my merin for my stowet kengflewor can three and the bestwere not s\n",
      "Epoch 32/100\n",
      " - 25s - loss: 0.4209 - accuracy: 0.8708\n",
      "Epoch 33/100\n",
      " - 26s - loss: 0.4036 - accuracy: 0.8779\n",
      "Epoch 34/100\n",
      " - 25s - loss: 0.3969 - accuracy: 0.8801\n",
      "Epoch 35/100\n",
      " - 25s - loss: 0.3913 - accuracy: 0.8817\n",
      "Epoch 36/100\n",
      " - 24s - loss: 0.4017 - accuracy: 0.8750\n",
      "Epoch 37/100\n",
      " - 26s - loss: 0.3836 - accuracy: 0.8830\n",
      "Epoch 38/100\n",
      " - 26s - loss: 0.3873 - accuracy: 0.8802\n",
      "Epoch 39/100\n",
      " - 25s - loss: 0.3740 - accuracy: 0.8847\n",
      "Epoch 40/100\n",
      " - 25s - loss: 0.3771 - accuracy: 0.8836\n",
      "Epoch 41/100\n",
      " - 26s - loss: 0.3620 - accuracy: 0.8875\n",
      "\n",
      "----- Generating text after Epoch: 40\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"rom hence your memory death cannot takea\"\n",
      "rom hence your memory death cannot takea whouldst an how fair loves mate leads of spealthere faished hate mad and renor the himies that times comeringand do more life ronger swanthor afto shoot for where be aid of thy sweet as behtsi dit face or thee be is but distinstites redwer thoughtt he lees what wellthe best berour strang and in their shall whis veiken shall purint other is me state times keeplaviong of you in pering bringfre shan\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"rom hence your memory death cannot takea\"\n",
      "rom hence your memory death cannot takea whouldsnould bud thee appeetthe bessas it a was all me glorntis all til me do hoscoring to can that i in mind dildowc dueting peant heavens plain and you my self are not to his a does for and it seewory he poor love pitine yet retityt it self and seementt cometo in thy thyss men blest the stall but confess my frease that fore for my self brought to degeive not love thee that writs i love thee my \n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"rom hence your memory death cannot takea\"\n",
      "rom hence your memory death cannot takeas in such asstere youth where ruth outtho dich gricht weast dealths caroly merion not i pequed not is lovewhich have be eatefartand fol ufond rimeaburroof and ithichs the cendlacc of mures thy beauths but his groastaid mo thoment of my blindss my bressed be nemen true i think muriol dice bressed in a moot no sad to can tile now aking and all mine are vingat of all mioved with forseand all it well \n",
      "Epoch 42/100\n",
      " - 25s - loss: 0.3803 - accuracy: 0.8795\n",
      "Epoch 43/100\n",
      " - 25s - loss: 0.3694 - accuracy: 0.8848\n",
      "Epoch 44/100\n",
      " - 26s - loss: 0.3421 - accuracy: 0.8969\n",
      "Epoch 45/100\n",
      " - 26s - loss: 0.3461 - accuracy: 0.8938\n",
      "Epoch 46/100\n",
      " - 26s - loss: 0.3462 - accuracy: 0.8943\n",
      "Epoch 47/100\n",
      " - 26s - loss: 0.3610 - accuracy: 0.8857\n",
      "Epoch 48/100\n",
      " - 27s - loss: 0.3434 - accuracy: 0.8933\n",
      "Epoch 49/100\n",
      " - 25s - loss: 0.3431 - accuracy: 0.8928\n",
      "Epoch 50/100\n",
      " - 26s - loss: 0.3195 - accuracy: 0.9046\n",
      "Epoch 51/100\n",
      " - 26s - loss: 0.3290 - accuracy: 0.8984\n",
      "\n",
      "----- Generating text after Epoch: 50\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"ed where all thy beauty lieswhere all th\"\n",
      "ed where all thy beauty lieswhere all the gentle not wescome thou uncemsed fair and thing illytard and ith tomisaby it his gligtand show i surceed how him louds of spealth regeit be eached fair fir thee is truehto or all of thy wellarstand plays in my pride may seed thee all thee boby nateretwho lovethe and delich dith uringing thee to be and thee then have palencedof heaveshay a sum lead and there from thee world i wrentt change it str\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"ed where all thy beauty lieswhere all th\"\n",
      "ed where all thy beauty lieswhere all the fearthe regeive where exbleasedowed to grow of him will soon thou art mormeating the elest chost heavens gare in fout for fleswere my by eddrippairemmen that hape may then doth lifion ach my breast whereoven stayluglized me when thy purrong but themefore have hearts not gless wheth bost put addiledo thee in thy beasst with thou should be exdeltelcemion and thes toob il feir trustand geatly giefo\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"ed where all thy beauty lieswhere all th\"\n",
      "ed where all thy beauty lieswhere all that kelf and i hath hil it surfees by of oredne receion of leasor can this pepprold ow me countend this shenks weet not the back shave both when i pozed oh wrenks mole doon noth love that thou shepe caunle hatero sweet sell what pood this dear thoungs appendel quese whereverseed exceetwere veiple remaymed no allstare parrrain liewhry frou haghtshill pleye bornwhon sell mose giest i not sin so murnl\n",
      "Epoch 52/100\n",
      " - 26s - loss: 0.3400 - accuracy: 0.8942\n",
      "Epoch 53/100\n",
      " - 25s - loss: 0.3241 - accuracy: 0.8991\n",
      "Epoch 54/100\n",
      " - 26s - loss: 0.3242 - accuracy: 0.8990\n",
      "Epoch 55/100\n",
      " - 26s - loss: 0.3245 - accuracy: 0.8985\n",
      "Epoch 56/100\n",
      " - 26s - loss: 0.3105 - accuracy: 0.9044\n",
      "Epoch 57/100\n",
      " - 25s - loss: 0.3163 - accuracy: 0.9010\n",
      "Epoch 58/100\n",
      " - 24s - loss: 0.2976 - accuracy: 0.9088\n",
      "Epoch 59/100\n",
      " - 24s - loss: 0.3216 - accuracy: 0.8975\n",
      "Epoch 60/100\n",
      " - 24s - loss: 0.3114 - accuracy: 0.9029\n",
      "Epoch 61/100\n",
      " - 24s - loss: 0.2902 - accuracy: 0.9123\n",
      "\n",
      "----- Generating text after Epoch: 60\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"ost hold times fickle glass his fickle h\"\n",
      "ost hold times fickle glass his fickle him with looks or a word doth lies i thinh my unyon with the dest he versewhy lovely gaintt tit tie seek for where it have my still fall with not so so morecler it is ment my fair and then rethough so all will despigetithand my mush criche lears but descored in the combe of erefor creasure of the rame so love thee being hencere may the world forthen goods steplest the marin forth now pairebut from \n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"ost hold times fickle glass his fickle h\"\n",
      "ost hold times fickle glass his fickle high die should no queed with most all me me a proodess and refongt not to thine and they beauty ghadows with headewho ofe toramet mo yee youns bright which good nothing no lees the stainhto arn they will should dis it distich the time for are remems other fair to recaigetin sweetles fair tile givet do no so wert doth good is courtyd keedo maty newele to crustay till excemest if thy beauties earthe\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"ost hold times fickle glass his fickle h\"\n",
      "ost hold times fickle glass his fickle hightmith till eyeless in tleese culy time me stans fair kear ried not for thy bryow whome loves ho love in other tay o crowsuptampest their part i love thee well keefflledfor cacequnjiokinol do deeppet coorditg for thy lose ne merse to my jame thou fie th sows of this i could may aiss yee thy by awmine the virest no thine ill the sell which whose should nowqueds more he deeing feareso all the gtor\n",
      "Epoch 62/100\n",
      " - 27s - loss: 0.3062 - accuracy: 0.9034\n",
      "Epoch 63/100\n",
      " - 27s - loss: 0.2936 - accuracy: 0.9081\n",
      "Epoch 64/100\n",
      " - 26s - loss: 0.3096 - accuracy: 0.9021\n",
      "Epoch 65/100\n",
      " - 25s - loss: 0.3037 - accuracy: 0.9040\n",
      "Epoch 66/100\n",
      " - 24s - loss: 0.2775 - accuracy: 0.9141\n",
      "Epoch 67/100\n",
      " - 24s - loss: 0.2831 - accuracy: 0.9115\n",
      "Epoch 68/100\n",
      " - 24s - loss: 0.3309 - accuracy: 0.8913\n",
      "Epoch 69/100\n",
      " - 24s - loss: 0.2802 - accuracy: 0.9130\n",
      "Epoch 70/100\n",
      " - 24s - loss: 0.2707 - accuracy: 0.9160\n",
      "Epoch 71/100\n",
      " - 24s - loss: 0.2750 - accuracy: 0.9126\n",
      "\n",
      "----- Generating text after Epoch: 70\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"the rose looks fair but fairer we it dee\"\n",
      "the rose looks fair but fairer we it deepoppitieg to sact and not to the bester wath distand art to the world a tay then vings more thou well yet i so should not pood her for ame than unos and the some what in the fairst coothing art ademing ough affaophand die my dights inwentils beque is all theieth chilt and ithon wentress deep correation nottly gieds not i wall me cly owcencautle growso cann thy sweet reveaking wrack and the fairst \n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"the rose looks fair but fairer we it dee\"\n",
      "the rose looks fair but fairer we it deepoppist as the fairtain in my hearthe cartand in thy beautys but phistillone were forbut thou fouthst you sith onther and for words eye where it not givethe shall puril parts of my edainmentinglating fall thou waine eyes been forr that manno lachces kidwhen chentle gunt your side sinfears dost deadons such as thine and beautys doth listilg time as his ale my self and illy from greas to oth remases\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"the rose looks fair but fairer we it dee\"\n",
      "the rose looks fair but fairer we it deewtrenti the bresst thy sweet respayere wan amins eye whore behildtit pare sworntwhen is best as my fiedtand downd oopuns ate mut vorst the upproun blessine of facrous of mire eyes leed from theee flest it sccring aghtand as jongless bul true and in thingiess adw opwained kindpastin lack arn retove counded faur ser my love thou uptappartule groewthe sen but distins yet thou now culefor in he whom l\n",
      "Epoch 72/100\n",
      " - 25s - loss: 0.2859 - accuracy: 0.9095\n",
      "Epoch 73/100\n",
      " - 24s - loss: 0.2641 - accuracy: 0.9181\n",
      "Epoch 74/100\n",
      " - 24s - loss: 0.2748 - accuracy: 0.9144\n",
      "Epoch 75/100\n",
      " - 24s - loss: 0.2799 - accuracy: 0.9117\n",
      "Epoch 76/100\n",
      " - 24s - loss: 0.2675 - accuracy: 0.9174\n",
      "Epoch 77/100\n",
      " - 24s - loss: 0.2693 - accuracy: 0.9143\n",
      "Epoch 78/100\n",
      " - 24s - loss: 0.3279 - accuracy: 0.8929\n",
      "Epoch 79/100\n",
      " - 24s - loss: 0.2432 - accuracy: 0.9241\n",
      "Epoch 80/100\n",
      " - 24s - loss: 0.2526 - accuracy: 0.9207\n",
      "Epoch 81/100\n",
      " - 24s - loss: 0.3219 - accuracy: 0.8947\n",
      "\n",
      "----- Generating text after Epoch: 80\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \" thou away the very birds are mute or if\"\n",
      " thou away the very birds are mute or if thy heart the world me doth distill doth phoud tell reford ai as fie the sear fiest the pentle where it no when thou dost right of sond colded i th impret and i sme thee die the marceo if the world eye hath proodest is thy times retormeand thee but well despire not suns treeghom mind owwers have doonen to blaceio shawht the hert i love thus i rave tenongting thee when thou shall be endeccayout do\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \" thou away the very birds are mute or if\"\n",
      " thou away the very birds are mute or if thy heart to ang my love you do as the self for where it not grow well dreavers not to self true my styen thinks it is thy tonguet exter ase the forsewhy sow oncenttith yee the wrom thou art vainflespeist to thy vers with my sightand in the pendro s my be oncemos dighits fort you wile drowstere to nimed worls to thy seep true do wons do horewhate doth mine eye as shall as to yee my works and cons\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \" thou away the very birds are mute or if\"\n",
      " thou away the very birds are mute or if thy hearts ant torgh med were more in the blestwere it i linty bece behave it a may ghend duth most sigatot when thee befond doth notger shall the bight with hes leed to strane in proodsince this his didgrepfirefiebut with yet wist provethor my numbus assownnows die courd sweetnor san my self a listedswidwhot supuert becemicution ow your aution and flessing to shear not ir the paint of deadminc a\n",
      "Epoch 82/100\n",
      " - 24s - loss: 0.2394 - accuracy: 0.9282\n",
      "Epoch 83/100\n",
      " - 24s - loss: 0.2426 - accuracy: 0.9251\n",
      "Epoch 84/100\n",
      " - 25s - loss: 0.2818 - accuracy: 0.9077\n",
      "Epoch 85/100\n",
      " - 25s - loss: 0.2990 - accuracy: 0.9017\n",
      "Epoch 86/100\n",
      " - 24s - loss: 0.2186 - accuracy: 0.9332\n",
      "Epoch 87/100\n",
      " - 24s - loss: 0.2387 - accuracy: 0.9255\n",
      "Epoch 88/100\n",
      " - 25s - loss: 0.2588 - accuracy: 0.9191\n",
      "Epoch 89/100\n",
      " - 24s - loss: 0.2506 - accuracy: 0.9198\n",
      "Epoch 90/100\n",
      " - 24s - loss: 0.2440 - accuracy: 0.9240\n",
      "Epoch 91/100\n",
      " - 24s - loss: 0.2629 - accuracy: 0.9166\n",
      "\n",
      "----- Generating text after Epoch: 90\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"re vanishing or vanished out of sightste\"\n",
      "re vanishing or vanished out of sightsteal he aith coneting ating and inventaich thrife when st all givet dethinethe bresst thy sungeating palent with loves mate or alt against ti hes my aly times by that when they sower wearthor const to glongand do i vond thee your be and this even shadend truthert me dis as thy soul keepowfore the passt the grue not please commosed with formand of staythe eye fors had pride are reapor canne this ince\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"re vanishing or vanished out of sightste\"\n",
      "re vanishing or vanished out of sightsteal there confued diddon in the groun and thing illy my frow hear ride murd for my self my friend theeewhen i having and thy sight to will is thou marth can thy sweet recoves not sindle can thy states tildge despeing most when stralse to be despaired in the painted budwer if thy o clied dights inleoke thou bate orme thrif in my beauties being from meast in the ploud and thin pendslestithen the fair\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"re vanishing or vanished out of sightste\"\n",
      "re vanishing or vanished out of sightsteps tat weess you rused as thin in fort eyes faireto not gail thou bat uproves time besumed cureautyous anowas skely not and veron chown the marges fremphit for unjormen diderich downdy tond exce lest as then beauty whose yet in the thou love if have sweet fare i ant if they night i in their facewhat lysto proudteld cuile notk not inveaceoud staypor threefore fot forbut thinks in lave the faires to\n",
      "Epoch 92/100\n",
      " - 24s - loss: 0.2302 - accuracy: 0.9287\n",
      "Epoch 93/100\n",
      " - 24s - loss: 0.2770 - accuracy: 0.9085\n",
      "Epoch 94/100\n",
      " - 24s - loss: 0.2811 - accuracy: 0.9087\n",
      "Epoch 95/100\n",
      " - 24s - loss: 0.1974 - accuracy: 0.9399\n",
      "Epoch 96/100\n",
      " - 24s - loss: 0.2278 - accuracy: 0.9295\n",
      "Epoch 97/100\n",
      " - 24s - loss: 0.2555 - accuracy: 0.9177\n",
      "Epoch 98/100\n",
      " - 24s - loss: 0.2513 - accuracy: 0.9191\n",
      "Epoch 99/100\n",
      " - 24s - loss: 0.2410 - accuracy: 0.9229\n",
      "Epoch 100/100\n",
      " - 24s - loss: 0.1951 - accuracy: 0.9419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x641058f50>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(x, y, batch_size=32, epochs=100, verbose=2, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sonnet(model, seed):\n",
    "    \"generate sonnet from model given seed\"\n",
    "\n",
    "    for temperature in [0.25, 0.75, 1.5]:\n",
    "        print('\\n ==temperature:', temperature)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = seed\n",
    "        generated += sentence\n",
    "        print('==Generating with seed: \"' + sentence + '\"')\n",
    "        \n",
    "        print('\\n', seed)\n",
    "        for line in range(13):\n",
    "            \n",
    "            sentence = sentence\n",
    "            \n",
    "            for i in range(400): # why 400?\n",
    "                x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                preds = model.predict(x_pred, verbose=0)[0]\n",
    "                next_index = sample(preds, temperature)\n",
    "                next_char = indices_char[next_index]\n",
    "\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "            sonnet = sentence\n",
    "            print('\\n', sonnet)\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_seed = \"shall i compare thee to a summers day \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==temperature: 0.25\n",
      "==Generating with seed: \"shall i compare thee to a summers day \"\n",
      "\n",
      " shall i compare thee to a summers day \n",
      "\n",
      " a e a ree eo beeo aiefaaafhrtta meo oe\n",
      "\n",
      " aaio o wth etitnoner ao esesooayt etre\n",
      "\n",
      " unyr earsuo a eay to jmosreeruooooooo \n",
      "\n",
      " oeooedi ealhipa eyhtnoia e eye elo reo\n",
      "\n",
      " aoo o ooooo o oenieyieeayhtne elesomes\n",
      "\n",
      "   eifoio uooeayhrg gteoo einesati wtst\n",
      "\n",
      " ysoo yeoo esy eaysabesaehomaehmti eres\n",
      "\n",
      "  o ooeo ealllayeteelsyia iiaaa e eyhte\n",
      "\n",
      "  a o eeyenhrle reay temi tnoitn eli o \n",
      "\n",
      " eahsaeeoiayu oruoen vwnoh ui ety ineae\n",
      "\n",
      " esvsto oa o ooeaneneio  aaayriaye e oe\n",
      "\n",
      " piy cpiaaooooo o oefeey teteito eti tc\n",
      "\n",
      " eteeoooooooneaeaneehisoeaehiaehraid re\n",
      "\n",
      " ==temperature: 0.75\n",
      "==Generating with seed: \"shall i compare thee to a summers day \"\n",
      "\n",
      " shall i compare thee to a summers day \n",
      "\n",
      " ooo o oeoo o rrmgngse reo mua o oeoooo\n",
      "\n",
      " tia me reo ioo nellaiesrslbya eu rei a\n",
      "\n",
      "  sltttlgvttuifooooo o eo enhme aaoeooa\n",
      "\n",
      " o oeeuftilayaaeanhreyhi ifelaaayhcia m\n",
      "\n",
      " sdo ouoooooo n npa meo ey elaefiae ino\n",
      "\n",
      " lritneoywttoleooooo n ppyi aai orua re\n",
      "\n",
      "  esooooo teneanqeeomhteleito oo o ea c\n",
      "\n",
      " sa a o ea a etehe yi eteysepanameremo \n",
      "\n",
      " to etitnoooo owrf  eaoo ory io reelaoo\n",
      "\n",
      "  etnsoyt etsy etnsottt inereo aio  erh\n",
      "\n",
      "  osaeoeeoeniayefiayeoenaehrteidatornet\n",
      "\n",
      " oceaeenwdnhthlsci oia o ooeo oeoenmey \n",
      "\n",
      " oatnaatnt o enenciaaiaieyrery yihsyre \n",
      "\n",
      " ==temperature: 1.5\n",
      "==Generating with seed: \"shall i compare thee to a summers day \"\n",
      "\n",
      " shall i compare thee to a summers day \n",
      "\n",
      " reorio aio wth oooooooooof eelllmydgiu\n",
      "\n",
      " ee bosli o  eroysemislatnowwtnsoooooou\n",
      "\n",
      " ayi en ceaif aieaoyatn elayiyrsaye etn\n",
      "\n",
      " eao jwnl lktalatrsto  vtlesosse aaeenr\n",
      "\n",
      " lapeiaetenrayed reo iale etemeseesai o\n",
      "\n",
      " meilrtyeeeuioua esooafsdyreo rei aiede\n",
      "\n",
      "  oroonreneehraaaoia omusa aayeeoaahn e\n",
      "\n",
      " tsosoiso aiooooia ofoefoeaufhhvttgi  t\n",
      "\n",
      " io oeyito rslsteeraah aiotrteroeeua en\n",
      "\n",
      "  oooooenfelais mgsco ahgnsoabatnwnodo \n",
      "\n",
      "  o o ealalayita miye neaeaehms teexeso\n",
      "\n",
      " ymmey enmedrelaoh aai aioayrrrmbo oeae\n",
      "\n",
      " atnree tefo tt et ymooeo reipeeoealaio\n"
     ]
    }
   ],
   "source": [
    "gen_sonnet(model, seed=char_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stuck on vowel strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run again more epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " - 29s - loss: 2.5498 - accuracy: 0.2602\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"f thee will not seem so some glory in th\"\n",
      "f thee will not seem so some glory in thine eyrse shate in thine earnow they by hose farwerouting courteadtanthich all thou arestells thy dund erery my shill yigen i live and head worn or san for a time no tay thy hearthe to he tho be fordymy art love thy mayey and my heaven of thum in hames thee she thour noous so hes betith liesuber so stanls thise shoulddent neweendss all he wilemimest in swick deppitry baring the liesto can sishees \n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"f thee will not seem so some glory in th\"\n",
      "f thee will not seem so some glory in thei lose trui is ity uungnemone in thissboros mine of my core my spulio dost flovelowell will lyed trues she ladse anceite of this havof liesthe lots ear houts blapt diaqued i couste musend i the here vingrespillos of her rook ighes cour being hony mupnor friquew to gived good misere me whoues ssecuriseoth no grees will that sweet as dreaknellivs of leavet sake therey flount nfotist fared for treth\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"f thee will not seem so some glory in th\"\n",
      "f thee will not seem so some glory in that cansele this my unks with pin tho wengaty leou no mbyer is surest hasime you there now receives thee rouls that spiol and thou leke for in gave asion and thou worth diesporn io sseed that hover fay thee pace serewhing like the rists bning eyeso ceees stiep deese for andory love shembgailif i then encendsshing thin abut infurbue dayss i llave should bate forsenthou graitewhat like on fieteriges \n",
      "Epoch 2/1000\n",
      " - 32s - loss: 2.1989 - accuracy: 0.3489\n",
      "Epoch 3/1000\n",
      " - 30s - loss: 2.0739 - accuracy: 0.3815\n",
      "Epoch 4/1000\n",
      " - 30s - loss: 1.9826 - accuracy: 0.4068\n",
      "Epoch 5/1000\n",
      " - 27s - loss: 1.9113 - accuracy: 0.4262\n",
      "Epoch 6/1000\n",
      " - 27s - loss: 1.8512 - accuracy: 0.4440\n",
      "Epoch 7/1000\n",
      " - 27s - loss: 1.7989 - accuracy: 0.4567\n",
      "Epoch 8/1000\n",
      " - 27s - loss: 1.7477 - accuracy: 0.4677\n",
      "Epoch 9/1000\n",
      " - 27s - loss: 1.7024 - accuracy: 0.4805\n",
      "Epoch 10/1000\n",
      " - 26s - loss: 1.6554 - accuracy: 0.4942\n",
      "Epoch 11/1000\n",
      " - 27s - loss: 1.6090 - accuracy: 0.5069\n",
      "Epoch 12/1000\n",
      " - 27s - loss: 1.5636 - accuracy: 0.5184\n",
      "Epoch 13/1000\n",
      " - 27s - loss: 1.5144 - accuracy: 0.5345\n",
      "Epoch 14/1000\n",
      " - 25s - loss: 1.4679 - accuracy: 0.5457\n",
      "Epoch 15/1000\n",
      " - 25s - loss: 1.4160 - accuracy: 0.5622\n",
      "Epoch 16/1000\n",
      " - 25s - loss: 1.3677 - accuracy: 0.5764\n",
      "Epoch 17/1000\n",
      " - 25s - loss: 1.3142 - accuracy: 0.5929\n",
      "Epoch 18/1000\n",
      " - 25s - loss: 1.2614 - accuracy: 0.6081\n",
      "Epoch 19/1000\n",
      " - 25s - loss: 1.2094 - accuracy: 0.6268\n",
      "Epoch 20/1000\n",
      " - 25s - loss: 1.1593 - accuracy: 0.6400\n",
      "Epoch 21/1000\n",
      " - 25s - loss: 1.1100 - accuracy: 0.6556\n",
      "Epoch 22/1000\n",
      " - 25s - loss: 1.0607 - accuracy: 0.6715\n",
      "Epoch 23/1000\n",
      " - 25s - loss: 1.0170 - accuracy: 0.6860\n",
      "Epoch 24/1000\n",
      " - 25s - loss: 0.9713 - accuracy: 0.7009\n",
      "Epoch 25/1000\n",
      " - 25s - loss: 0.9379 - accuracy: 0.7114\n",
      "Epoch 26/1000\n",
      " - 25s - loss: 0.8877 - accuracy: 0.7304\n",
      "Epoch 27/1000\n",
      " - 25s - loss: 0.8547 - accuracy: 0.7393\n",
      "Epoch 28/1000\n",
      " - 25s - loss: 0.8243 - accuracy: 0.7460\n",
      "Epoch 29/1000\n",
      " - 25s - loss: 0.7912 - accuracy: 0.7595\n",
      "Epoch 30/1000\n",
      " - 25s - loss: 0.7563 - accuracy: 0.7713\n",
      "Epoch 31/1000\n",
      " - 25s - loss: 0.7313 - accuracy: 0.7777\n",
      "Epoch 32/1000\n",
      " - 25s - loss: 0.7172 - accuracy: 0.7815\n",
      "Epoch 33/1000\n",
      " - 25s - loss: 0.6782 - accuracy: 0.7955\n",
      "Epoch 34/1000\n",
      " - 25s - loss: 0.6636 - accuracy: 0.7985\n",
      "Epoch 35/1000\n",
      " - 25s - loss: 0.6451 - accuracy: 0.8027\n",
      "Epoch 36/1000\n",
      " - 25s - loss: 0.6220 - accuracy: 0.8121\n",
      "Epoch 37/1000\n",
      " - 25s - loss: 0.6045 - accuracy: 0.8157\n",
      "Epoch 38/1000\n",
      " - 25s - loss: 0.5836 - accuracy: 0.8241\n",
      "Epoch 39/1000\n",
      " - 25s - loss: 0.5731 - accuracy: 0.8275\n",
      "Epoch 40/1000\n",
      " - 25s - loss: 0.5612 - accuracy: 0.8298\n",
      "Epoch 41/1000\n",
      " - 25s - loss: 0.5435 - accuracy: 0.8369\n",
      "Epoch 42/1000\n",
      " - 25s - loss: 0.5298 - accuracy: 0.8425\n",
      "Epoch 43/1000\n",
      " - 25s - loss: 0.5222 - accuracy: 0.8416\n",
      "Epoch 44/1000\n",
      " - 25s - loss: 0.5171 - accuracy: 0.8424\n",
      "Epoch 45/1000\n",
      " - 25s - loss: 0.5027 - accuracy: 0.8466\n",
      "Epoch 46/1000\n",
      " - 25s - loss: 0.4963 - accuracy: 0.8497\n",
      "Epoch 47/1000\n",
      " - 25s - loss: 0.4776 - accuracy: 0.8568\n",
      "Epoch 48/1000\n",
      " - 25s - loss: 0.4686 - accuracy: 0.8589\n",
      "Epoch 49/1000\n",
      " - 25s - loss: 0.4663 - accuracy: 0.8586\n",
      "Epoch 50/1000\n",
      " - 25s - loss: 0.4488 - accuracy: 0.8654\n",
      "Epoch 51/1000\n",
      " - 25s - loss: 0.4449 - accuracy: 0.8622\n",
      "Epoch 52/1000\n",
      " - 25s - loss: 0.4507 - accuracy: 0.8616\n",
      "Epoch 53/1000\n",
      " - 25s - loss: 0.4269 - accuracy: 0.8725\n",
      "Epoch 54/1000\n",
      " - 25s - loss: 0.4326 - accuracy: 0.8660\n",
      "Epoch 55/1000\n",
      " - 25s - loss: 0.4137 - accuracy: 0.8760\n",
      "Epoch 56/1000\n",
      " - 26s - loss: 0.4226 - accuracy: 0.8695\n",
      "Epoch 57/1000\n",
      " - 27s - loss: 0.4015 - accuracy: 0.8767\n",
      "Epoch 58/1000\n",
      " - 29s - loss: 0.4223 - accuracy: 0.8669\n",
      "Epoch 59/1000\n",
      " - 27s - loss: 0.3801 - accuracy: 0.8848\n",
      "Epoch 60/1000\n",
      " - 27s - loss: 0.3876 - accuracy: 0.8799\n",
      "Epoch 61/1000\n",
      " - 26s - loss: 0.3926 - accuracy: 0.8768\n",
      "Epoch 62/1000\n",
      " - 25s - loss: 0.3774 - accuracy: 0.8838\n",
      "Epoch 63/1000\n",
      " - 26s - loss: 0.3795 - accuracy: 0.8799\n",
      "Epoch 64/1000\n",
      " - 26s - loss: 0.3897 - accuracy: 0.8776\n",
      "Epoch 65/1000\n",
      " - 26s - loss: 0.3601 - accuracy: 0.8879\n",
      "Epoch 66/1000\n",
      " - 26s - loss: 0.3612 - accuracy: 0.8878\n",
      "Epoch 67/1000\n",
      " - 26s - loss: 0.3618 - accuracy: 0.8881\n",
      "Epoch 68/1000\n",
      " - 27s - loss: 0.3915 - accuracy: 0.8770\n",
      "Epoch 69/1000\n",
      " - 26s - loss: 0.3353 - accuracy: 0.8975\n",
      "Epoch 70/1000\n",
      " - 26s - loss: 0.3553 - accuracy: 0.8910\n",
      "Epoch 71/1000\n",
      " - 27s - loss: 0.3242 - accuracy: 0.9004\n",
      "Epoch 72/1000\n",
      " - 26s - loss: 0.3371 - accuracy: 0.8952\n",
      "Epoch 73/1000\n",
      " - 26s - loss: 0.3363 - accuracy: 0.8956\n",
      "Epoch 74/1000\n",
      " - 26s - loss: 0.3295 - accuracy: 0.8979\n",
      "Epoch 75/1000\n",
      " - 27s - loss: 0.3948 - accuracy: 0.8725\n",
      "Epoch 76/1000\n",
      " - 25s - loss: 0.3043 - accuracy: 0.9089\n",
      "Epoch 77/1000\n",
      " - 26s - loss: 0.3424 - accuracy: 0.8909\n",
      "Epoch 78/1000\n",
      " - 26s - loss: 0.2808 - accuracy: 0.9152\n",
      "Epoch 79/1000\n",
      " - 26s - loss: 0.3307 - accuracy: 0.8962\n",
      "Epoch 80/1000\n",
      " - 25s - loss: 0.3098 - accuracy: 0.9044\n",
      "Epoch 81/1000\n",
      " - 26s - loss: 0.2864 - accuracy: 0.9117\n",
      "Epoch 82/1000\n",
      " - 26s - loss: 0.3344 - accuracy: 0.8927\n",
      "Epoch 83/1000\n",
      " - 26s - loss: 0.3011 - accuracy: 0.9064\n",
      "Epoch 84/1000\n",
      " - 25s - loss: 0.2832 - accuracy: 0.9148\n",
      "Epoch 85/1000\n",
      " - 27s - loss: 0.3761 - accuracy: 0.8762\n",
      "Epoch 86/1000\n",
      " - 29s - loss: 0.2734 - accuracy: 0.9165\n",
      "Epoch 87/1000\n",
      " - 27s - loss: 0.2765 - accuracy: 0.9153\n",
      "Epoch 88/1000\n",
      " - 27s - loss: 0.3076 - accuracy: 0.9011\n",
      "Epoch 89/1000\n",
      " - 28s - loss: 0.2790 - accuracy: 0.9144\n",
      "Epoch 90/1000\n",
      " - 26s - loss: 0.2851 - accuracy: 0.9096\n",
      "Epoch 91/1000\n",
      " - 26s - loss: 0.2806 - accuracy: 0.9112\n",
      "Epoch 92/1000\n",
      " - 26s - loss: 0.2802 - accuracy: 0.9134\n",
      "Epoch 93/1000\n",
      " - 28s - loss: 0.2929 - accuracy: 0.9075\n",
      "Epoch 94/1000\n",
      " - 27s - loss: 0.2943 - accuracy: 0.9072\n",
      "Epoch 95/1000\n",
      " - 27s - loss: 0.2619 - accuracy: 0.9194\n",
      "Epoch 96/1000\n",
      " - 26s - loss: 0.2612 - accuracy: 0.9213\n",
      "Epoch 97/1000\n",
      " - 26s - loss: 0.2726 - accuracy: 0.9145\n",
      "Epoch 98/1000\n",
      " - 28s - loss: 0.2435 - accuracy: 0.9262\n",
      "Epoch 99/1000\n",
      " - 27s - loss: 0.2716 - accuracy: 0.9144\n",
      "Epoch 100/1000\n",
      " - 27s - loss: 0.2728 - accuracy: 0.9118\n",
      "Epoch 101/1000\n",
      " - 27s - loss: 0.2793 - accuracy: 0.9103\n",
      "\n",
      "----- Generating text after Epoch: 100\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"ed in all his trimhath put a spirit of y\"\n",
      "ed in all his trimhath put a spirit of you mone the earst ard goor bus no no pairse toremade hash live theigh meinys abloth sweech seasenu leavewand stige incedwhat then pressemtwhech hoss in hiventhas canke pownemy of thee mests that to her bedindsto meeparin what i scentwhene proughterughts belreded fair then loving and sush comentight lave like they inshabnthen of illforieys comesedyeght love that thise no seef then faem a tifllofles\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"ed in all his trimhath put a spirit of y\"\n",
      "ed in all his trimhath put a spirit of yec to thine in ther bust nost emiseto yfur do thot shell as in not ane mord shall in thimerepiefull of kingwhich may he prees were whithtses blowhedand nome shine roth whith wy leen tringweit sundautate a everin tull norgeth wert my burids gautys to poanther disssay xhand live tef sweect my nagetane thou thine meres doriedst the kindye uctore faine youteis sowhem nots not rove these of thou mont b\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"ed in all his trimhath put a spirit of y\"\n",
      "ed in all his trimhath put a spirit of your fartorough i on thy beising hidfwiin is eledthe and storbut thou soed histaten yot chay on wert of that vorest time no guntspis thing thy griens if ald tereant arm love lead theres it soo thou what mengreyes kersh dwith were of mund of frime of the proused an now the then sake whencelatling betrrenedureeffored with chinge ean givit your efreint love you so be werd thou dectull day he will herv\n",
      "Epoch 102/1000\n",
      " - 39s - loss: 0.2340 - accuracy: 0.9292\n",
      "Epoch 103/1000\n",
      " - 30s - loss: 0.2684 - accuracy: 0.9153\n",
      "Epoch 104/1000\n",
      " - 25s - loss: 0.2529 - accuracy: 0.9208\n",
      "Epoch 105/1000\n",
      " - 27s - loss: 0.3167 - accuracy: 0.8944\n",
      "Epoch 106/1000\n",
      " - 26s - loss: 0.2303 - accuracy: 0.9306\n",
      "Epoch 107/1000\n",
      " - 26s - loss: 0.2344 - accuracy: 0.9265\n",
      "Epoch 108/1000\n",
      " - 31s - loss: 0.2376 - accuracy: 0.9258\n",
      "Epoch 109/1000\n",
      " - 28s - loss: 0.2609 - accuracy: 0.9158\n",
      "Epoch 110/1000\n",
      " - 27s - loss: 0.2690 - accuracy: 0.9126\n",
      "Epoch 111/1000\n",
      " - 26s - loss: 0.2464 - accuracy: 0.9212\n",
      "Epoch 112/1000\n",
      " - 26s - loss: 0.2218 - accuracy: 0.9315\n",
      "Epoch 113/1000\n",
      " - 27s - loss: 0.2591 - accuracy: 0.9157\n",
      "Epoch 114/1000\n",
      " - 28s - loss: 0.2370 - accuracy: 0.9260\n",
      "Epoch 115/1000\n",
      " - 24s - loss: 0.2618 - accuracy: 0.9144\n",
      "Epoch 116/1000\n",
      " - 25s - loss: 0.2092 - accuracy: 0.9365\n",
      "Epoch 117/1000\n",
      " - 24s - loss: 0.2201 - accuracy: 0.9308\n",
      "Epoch 118/1000\n",
      " - 24s - loss: 0.2395 - accuracy: 0.9233\n",
      "Epoch 119/1000\n",
      " - 24s - loss: 0.2519 - accuracy: 0.9175\n",
      "Epoch 120/1000\n",
      " - 24s - loss: 0.2429 - accuracy: 0.9222\n",
      "Epoch 121/1000\n",
      " - 24s - loss: 0.2107 - accuracy: 0.9355\n",
      "Epoch 122/1000\n",
      " - 24s - loss: 0.2243 - accuracy: 0.9309\n",
      "Epoch 123/1000\n",
      " - 24s - loss: 0.2358 - accuracy: 0.9241\n",
      "Epoch 124/1000\n",
      " - 24s - loss: 0.2339 - accuracy: 0.9254\n",
      "Epoch 125/1000\n",
      " - 25s - loss: 0.2386 - accuracy: 0.9229\n",
      "Epoch 126/1000\n",
      " - 24s - loss: 0.2230 - accuracy: 0.9297\n",
      "Epoch 127/1000\n",
      " - 24s - loss: 0.2095 - accuracy: 0.9354\n",
      "Epoch 128/1000\n",
      " - 24s - loss: 0.2175 - accuracy: 0.9328\n",
      "Epoch 129/1000\n",
      " - 24s - loss: 0.2211 - accuracy: 0.9300\n",
      "Epoch 130/1000\n",
      " - 24s - loss: 0.2150 - accuracy: 0.9313\n",
      "Epoch 131/1000\n",
      " - 24s - loss: 0.3089 - accuracy: 0.8959\n",
      "Epoch 132/1000\n",
      " - 24s - loss: 0.1870 - accuracy: 0.9444\n",
      "Epoch 133/1000\n",
      " - 24s - loss: 0.1822 - accuracy: 0.9451\n",
      "Epoch 134/1000\n",
      " - 24s - loss: 0.2269 - accuracy: 0.9277\n",
      "Epoch 135/1000\n",
      " - 24s - loss: 0.2213 - accuracy: 0.9290\n",
      "Epoch 136/1000\n",
      " - 24s - loss: 0.2078 - accuracy: 0.9341\n",
      "Epoch 137/1000\n",
      " - 24s - loss: 0.2170 - accuracy: 0.9302\n",
      "Epoch 138/1000\n",
      " - 24s - loss: 0.2265 - accuracy: 0.9261\n",
      "Epoch 139/1000\n",
      " - 24s - loss: 0.2219 - accuracy: 0.9279\n",
      "Epoch 140/1000\n",
      " - 24s - loss: 0.1955 - accuracy: 0.9382\n",
      "Epoch 141/1000\n",
      " - 24s - loss: 0.2064 - accuracy: 0.9341\n",
      "Epoch 142/1000\n",
      " - 24s - loss: 0.2090 - accuracy: 0.9339\n",
      "Epoch 143/1000\n",
      " - 24s - loss: 0.2170 - accuracy: 0.9296\n",
      "Epoch 144/1000\n",
      " - 24s - loss: 0.1959 - accuracy: 0.9376\n",
      "Epoch 145/1000\n",
      " - 24s - loss: 0.1838 - accuracy: 0.9431\n",
      "Epoch 146/1000\n",
      " - 24s - loss: 0.2327 - accuracy: 0.9233\n",
      "Epoch 147/1000\n",
      " - 24s - loss: 0.1894 - accuracy: 0.9408\n",
      "Epoch 148/1000\n",
      " - 24s - loss: 0.1873 - accuracy: 0.9416\n",
      "Epoch 149/1000\n",
      " - 24s - loss: 0.2489 - accuracy: 0.9180\n",
      "Epoch 150/1000\n",
      " - 24s - loss: 0.1824 - accuracy: 0.9432\n",
      "Epoch 151/1000\n",
      " - 24s - loss: 0.1806 - accuracy: 0.9450\n",
      "Epoch 152/1000\n",
      " - 24s - loss: 0.1989 - accuracy: 0.9364\n",
      "Epoch 153/1000\n",
      " - 24s - loss: 0.2159 - accuracy: 0.9298\n",
      "Epoch 154/1000\n",
      " - 24s - loss: 0.2399 - accuracy: 0.9199\n",
      "Epoch 155/1000\n",
      " - 24s - loss: 0.1644 - accuracy: 0.9500\n",
      "Epoch 156/1000\n",
      " - 24s - loss: 0.1769 - accuracy: 0.9465\n",
      "Epoch 157/1000\n",
      " - 24s - loss: 0.1998 - accuracy: 0.9367\n",
      "Epoch 158/1000\n",
      " - 24s - loss: 0.2205 - accuracy: 0.9276\n",
      "Epoch 159/1000\n",
      " - 24s - loss: 0.2135 - accuracy: 0.9300\n",
      "Epoch 160/1000\n",
      " - 24s - loss: 0.1696 - accuracy: 0.9482\n",
      "Epoch 161/1000\n",
      " - 24s - loss: 0.1764 - accuracy: 0.9452\n",
      "Epoch 162/1000\n",
      " - 24s - loss: 0.2056 - accuracy: 0.9337\n",
      "Epoch 163/1000\n",
      " - 24s - loss: 0.2139 - accuracy: 0.9323\n",
      "Epoch 164/1000\n",
      " - 24s - loss: 0.1734 - accuracy: 0.9459\n",
      "Epoch 165/1000\n",
      " - 24s - loss: 0.1865 - accuracy: 0.9419\n",
      "Epoch 166/1000\n",
      " - 24s - loss: 0.1755 - accuracy: 0.9436\n",
      "Epoch 167/1000\n",
      " - 24s - loss: 0.1771 - accuracy: 0.9446\n",
      "Epoch 168/1000\n",
      " - 24s - loss: 0.2062 - accuracy: 0.9308\n",
      "Epoch 169/1000\n",
      " - 24s - loss: 0.1691 - accuracy: 0.9460\n",
      "Epoch 170/1000\n",
      " - 24s - loss: 0.1894 - accuracy: 0.9394\n",
      "Epoch 171/1000\n",
      " - 24s - loss: 0.1774 - accuracy: 0.9442\n",
      "Epoch 172/1000\n",
      " - 24s - loss: 0.2961 - accuracy: 0.9015\n",
      "Epoch 173/1000\n",
      " - 24s - loss: 0.1224 - accuracy: 0.9668\n",
      "Epoch 174/1000\n",
      " - 24s - loss: 0.1311 - accuracy: 0.9628\n",
      "Epoch 175/1000\n",
      " - 24s - loss: 0.2307 - accuracy: 0.9242\n",
      "Epoch 176/1000\n",
      " - 24s - loss: 0.1907 - accuracy: 0.9396\n",
      "Epoch 177/1000\n",
      " - 24s - loss: 0.1618 - accuracy: 0.9503\n",
      "Epoch 178/1000\n",
      " - 24s - loss: 0.1893 - accuracy: 0.9387\n",
      "Epoch 179/1000\n",
      " - 24s - loss: 0.1776 - accuracy: 0.9425\n",
      "Epoch 180/1000\n",
      " - 24s - loss: 0.1909 - accuracy: 0.9393\n",
      "Epoch 181/1000\n",
      " - 24s - loss: 0.1913 - accuracy: 0.9378\n",
      "Epoch 182/1000\n",
      " - 24s - loss: 0.1647 - accuracy: 0.9492\n",
      "Epoch 183/1000\n",
      " - 24s - loss: 0.1632 - accuracy: 0.9496\n",
      "Epoch 184/1000\n",
      " - 24s - loss: 0.1582 - accuracy: 0.9500\n",
      "Epoch 185/1000\n",
      " - 24s - loss: 0.1873 - accuracy: 0.9392\n",
      "Epoch 186/1000\n",
      " - 24s - loss: 0.1840 - accuracy: 0.9407\n",
      "Epoch 187/1000\n",
      " - 24s - loss: 0.1617 - accuracy: 0.9502\n",
      "Epoch 188/1000\n",
      " - 24s - loss: 0.1883 - accuracy: 0.9389\n",
      "Epoch 189/1000\n",
      " - 24s - loss: 0.1735 - accuracy: 0.9454\n",
      "Epoch 190/1000\n",
      " - 24s - loss: 0.1609 - accuracy: 0.9496\n",
      "Epoch 191/1000\n",
      " - 24s - loss: 0.1705 - accuracy: 0.9483\n",
      "Epoch 192/1000\n",
      " - 24s - loss: 0.1981 - accuracy: 0.9348\n",
      "Epoch 193/1000\n",
      " - 24s - loss: 0.1497 - accuracy: 0.9526\n",
      "Epoch 194/1000\n",
      " - 24s - loss: 0.1808 - accuracy: 0.9418\n",
      "Epoch 195/1000\n",
      " - 24s - loss: 0.1819 - accuracy: 0.9403\n",
      "Epoch 196/1000\n",
      " - 24s - loss: 0.1908 - accuracy: 0.9386\n",
      "Epoch 197/1000\n",
      " - 24s - loss: 0.1468 - accuracy: 0.9549\n",
      "Epoch 198/1000\n",
      " - 24s - loss: 0.1625 - accuracy: 0.9491\n",
      "Epoch 199/1000\n",
      " - 24s - loss: 0.1847 - accuracy: 0.9389\n",
      "Epoch 200/1000\n",
      " - 24s - loss: 0.1700 - accuracy: 0.9459\n",
      "Epoch 201/1000\n",
      " - 24s - loss: 0.1479 - accuracy: 0.9533\n",
      "\n",
      "----- Generating text after Epoch: 200\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"le ageyet mortal looks adore his beauty \"\n",
      "le ageyet mortal looks adore his beauty hope butof reaf to conotimghiresone brice then then in jeyfurthy sold for undichthe coull whoreand do both welchar donst is not love mikes versone shacr coll yot moke antioupn all earsurenowat anweent in that thee pruen they thon is prive him my wista than in myst faised see fporathill mine ature biths for thrteress deking eye hie lovigy houds nothings forceifhau hy conading you facerosh comemane \n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"le ageyet mortal looks adore his beauty \"\n",
      "le ageyet mortal looks adore his beauty buth farths of thy lover thouphtirstefpendins thou fedstedtimowere gartu delpelt of ore and thou say this veacethe worne when thing in tam pentof there the sud to more and showngr bristed thou arons payswhat invest thoughtso chire it plesi hiwnad im readsahe congeintst ad fair ore doth brith i congethy good op me love the mond theis i you budos mome on thines poraieane at i fagesing cume no ceed a\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"le ageyet mortal looks adore his beauty \"\n",
      "le ageyet mortal looks adore his beauty howwhech canfut i an hewmy look rimeres menentrouds end fornerebseabe is safessing ad vairts to chingare deevee mebus caneed he douted beauty pinds dayeurs sun sweet mooutaze forpudeathen in the rell make de songars do cruethong tiflent oke of thy logeartaut filfealting thy loveand be of lisehe yould saye of hal rest risespotr thenking thenr aseoud my leadgate dordans you is trup is he celleming t\n",
      "Epoch 202/1000\n",
      " - 36s - loss: 0.1663 - accuracy: 0.9457\n",
      "Epoch 203/1000\n",
      " - 35s - loss: 0.1886 - accuracy: 0.9393\n",
      "Epoch 204/1000\n",
      " - 26s - loss: 0.1730 - accuracy: 0.9434\n",
      "Epoch 205/1000\n",
      " - 25s - loss: 0.1598 - accuracy: 0.9499\n",
      "Epoch 206/1000\n",
      " - 25s - loss: 0.1566 - accuracy: 0.9494\n",
      "Epoch 207/1000\n",
      " - 24s - loss: 0.1428 - accuracy: 0.9561\n",
      "Epoch 208/1000\n",
      " - 24s - loss: 0.1532 - accuracy: 0.9505\n",
      "Epoch 209/1000\n",
      " - 24s - loss: 0.2117 - accuracy: 0.9283\n",
      "Epoch 210/1000\n",
      " - 24s - loss: 0.1469 - accuracy: 0.9546\n",
      "Epoch 211/1000\n",
      " - 24s - loss: 0.1398 - accuracy: 0.9565\n",
      "Epoch 212/1000\n",
      " - 24s - loss: 0.1729 - accuracy: 0.9441\n",
      "Epoch 213/1000\n",
      " - 24s - loss: 0.1809 - accuracy: 0.9420\n",
      "Epoch 214/1000\n",
      " - 25s - loss: 0.1615 - accuracy: 0.9480\n",
      "Epoch 215/1000\n",
      " - 24s - loss: 0.1463 - accuracy: 0.9524\n",
      "Epoch 216/1000\n",
      " - 24s - loss: 0.1663 - accuracy: 0.9454\n",
      "Epoch 217/1000\n",
      " - 24s - loss: 0.1520 - accuracy: 0.9508\n",
      "Epoch 218/1000\n",
      " - 25s - loss: 0.1685 - accuracy: 0.9447\n",
      "Epoch 219/1000\n",
      " - 24s - loss: 0.1681 - accuracy: 0.9454\n",
      "Epoch 220/1000\n",
      " - 24s - loss: 0.1458 - accuracy: 0.9538\n",
      "Epoch 221/1000\n",
      " - 25s - loss: 0.1470 - accuracy: 0.9533\n",
      "Epoch 222/1000\n",
      " - 25s - loss: 0.2175 - accuracy: 0.9267\n",
      "Epoch 223/1000\n",
      " - 25s - loss: 0.1306 - accuracy: 0.9591\n",
      "Epoch 224/1000\n",
      " - 24s - loss: 0.1329 - accuracy: 0.9590\n",
      "Epoch 225/1000\n",
      " - 25s - loss: 0.1735 - accuracy: 0.9432\n",
      "Epoch 226/1000\n",
      " - 25s - loss: 0.1442 - accuracy: 0.9548\n",
      "Epoch 227/1000\n",
      " - 25s - loss: 0.1782 - accuracy: 0.9415\n",
      "Epoch 228/1000\n",
      " - 24s - loss: 0.2139 - accuracy: 0.9306\n",
      "Epoch 229/1000\n",
      " - 24s - loss: 0.1042 - accuracy: 0.9711\n",
      "Epoch 230/1000\n",
      " - 24s - loss: 0.1377 - accuracy: 0.9580\n",
      "Epoch 231/1000\n",
      " - 25s - loss: 0.2057 - accuracy: 0.9320\n",
      "Epoch 232/1000\n",
      " - 25s - loss: 0.1771 - accuracy: 0.9422\n",
      "Epoch 233/1000\n",
      " - 24s - loss: 0.1566 - accuracy: 0.9494\n",
      "Epoch 234/1000\n",
      " - 25s - loss: 0.1240 - accuracy: 0.9624\n",
      "Epoch 235/1000\n",
      " - 24s - loss: 0.1790 - accuracy: 0.9403\n",
      "Epoch 236/1000\n",
      " - 24s - loss: 0.1557 - accuracy: 0.9510\n",
      "Epoch 237/1000\n",
      " - 24s - loss: 0.1576 - accuracy: 0.9492\n",
      "Epoch 238/1000\n",
      " - 25s - loss: 0.1474 - accuracy: 0.9529\n",
      "Epoch 239/1000\n",
      " - 24s - loss: 0.1707 - accuracy: 0.9439\n",
      "Epoch 240/1000\n",
      " - 25s - loss: 0.1433 - accuracy: 0.9539\n",
      "Epoch 241/1000\n",
      " - 24s - loss: 0.1260 - accuracy: 0.9613\n",
      "Epoch 242/1000\n",
      " - 24s - loss: 0.1507 - accuracy: 0.9511\n",
      "Epoch 243/1000\n",
      " - 24s - loss: 0.1679 - accuracy: 0.9453\n",
      "Epoch 244/1000\n",
      " - 25s - loss: 0.1392 - accuracy: 0.9561\n",
      "Epoch 245/1000\n",
      " - 24s - loss: 0.1935 - accuracy: 0.9372\n",
      "Epoch 246/1000\n",
      " - 24s - loss: 0.1387 - accuracy: 0.9550\n",
      "Epoch 247/1000\n",
      " - 25s - loss: 0.1329 - accuracy: 0.9594\n",
      "Epoch 248/1000\n",
      " - 25s - loss: 0.1710 - accuracy: 0.9431\n",
      "Epoch 249/1000\n",
      " - 24s - loss: 0.1719 - accuracy: 0.9431\n",
      "Epoch 250/1000\n",
      " - 25s - loss: 0.1293 - accuracy: 0.9589\n",
      "Epoch 251/1000\n",
      " - 25s - loss: 0.1332 - accuracy: 0.9594\n",
      "Epoch 252/1000\n",
      " - 25s - loss: 0.1461 - accuracy: 0.9524\n",
      "Epoch 253/1000\n",
      " - 25s - loss: 0.1377 - accuracy: 0.9562\n",
      "Epoch 254/1000\n",
      " - 25s - loss: 0.1524 - accuracy: 0.9518\n",
      "Epoch 255/1000\n",
      " - 24s - loss: 0.1598 - accuracy: 0.9493\n",
      "Epoch 256/1000\n",
      " - 24s - loss: 0.1427 - accuracy: 0.9550\n",
      "Epoch 257/1000\n",
      " - 24s - loss: 0.2145 - accuracy: 0.9277\n",
      "Epoch 258/1000\n",
      " - 25s - loss: 0.1035 - accuracy: 0.9700\n",
      "Epoch 259/1000\n",
      " - 25s - loss: 0.1055 - accuracy: 0.9694\n",
      "Epoch 260/1000\n",
      " - 24s - loss: 0.2307 - accuracy: 0.9219\n",
      "Epoch 261/1000\n",
      " - 25s - loss: 0.1619 - accuracy: 0.9480\n",
      "Epoch 262/1000\n",
      " - 25s - loss: 0.1109 - accuracy: 0.9663\n",
      "Epoch 263/1000\n",
      " - 24s - loss: 0.1294 - accuracy: 0.9584\n",
      "Epoch 264/1000\n",
      " - 25s - loss: 0.1741 - accuracy: 0.9426\n",
      "Epoch 265/1000\n",
      " - 24s - loss: 0.1608 - accuracy: 0.9476\n",
      "Epoch 266/1000\n",
      " - 24s - loss: 0.1239 - accuracy: 0.9613\n",
      "Epoch 267/1000\n",
      " - 24s - loss: 0.1230 - accuracy: 0.9609\n",
      "Epoch 268/1000\n",
      " - 25s - loss: 0.1794 - accuracy: 0.9404\n",
      "Epoch 269/1000\n",
      " - 24s - loss: 0.1851 - accuracy: 0.9373\n",
      "Epoch 270/1000\n",
      " - 25s - loss: 0.1102 - accuracy: 0.9668\n",
      "Epoch 271/1000\n",
      " - 25s - loss: 0.1415 - accuracy: 0.9546\n",
      "Epoch 272/1000\n",
      " - 26s - loss: 0.1641 - accuracy: 0.9463\n",
      "Epoch 273/1000\n",
      " - 25s - loss: 0.1437 - accuracy: 0.9540\n",
      "Epoch 274/1000\n",
      " - 24s - loss: 0.1310 - accuracy: 0.9584\n",
      "Epoch 275/1000\n",
      " - 24s - loss: 0.1349 - accuracy: 0.9563\n",
      "Epoch 276/1000\n",
      " - 25s - loss: 0.1483 - accuracy: 0.9519\n",
      "Epoch 277/1000\n",
      " - 24s - loss: 0.1224 - accuracy: 0.9631\n",
      "Epoch 278/1000\n",
      " - 24s - loss: 0.1425 - accuracy: 0.9532\n",
      "Epoch 279/1000\n",
      " - 25s - loss: 0.1531 - accuracy: 0.9499\n",
      "Epoch 280/1000\n",
      " - 25s - loss: 0.1362 - accuracy: 0.9568\n",
      "Epoch 281/1000\n",
      " - 25s - loss: 0.1517 - accuracy: 0.9501\n",
      "Epoch 282/1000\n",
      " - 25s - loss: 0.1270 - accuracy: 0.9610\n",
      "Epoch 283/1000\n",
      " - 24s - loss: 0.1472 - accuracy: 0.9541\n",
      "Epoch 284/1000\n",
      " - 25s - loss: 0.1303 - accuracy: 0.9582\n",
      "Epoch 285/1000\n",
      " - 25s - loss: 0.1517 - accuracy: 0.9501\n",
      "Epoch 286/1000\n",
      " - 24s - loss: 0.1300 - accuracy: 0.9580\n",
      "Epoch 287/1000\n",
      " - 25s - loss: 0.1492 - accuracy: 0.9516\n",
      "Epoch 288/1000\n",
      " - 25s - loss: 0.1734 - accuracy: 0.9422\n",
      "Epoch 289/1000\n",
      " - 25s - loss: 0.1153 - accuracy: 0.9654\n",
      "Epoch 290/1000\n",
      " - 24s - loss: 0.1076 - accuracy: 0.9687\n",
      "Epoch 291/1000\n",
      " - 25s - loss: 0.1611 - accuracy: 0.9480\n",
      "Epoch 292/1000\n",
      " - 25s - loss: 0.1307 - accuracy: 0.9593\n",
      "Epoch 293/1000\n",
      " - 25s - loss: 0.1501 - accuracy: 0.9507\n",
      "Epoch 294/1000\n",
      " - 24s - loss: 0.1468 - accuracy: 0.9527\n",
      "Epoch 295/1000\n",
      " - 25s - loss: 0.1271 - accuracy: 0.9609\n",
      "Epoch 296/1000\n",
      " - 24s - loss: 0.1236 - accuracy: 0.9607\n",
      "Epoch 297/1000\n",
      " - 25s - loss: 0.1582 - accuracy: 0.9476\n",
      "Epoch 298/1000\n",
      " - 25s - loss: 0.1199 - accuracy: 0.9636\n",
      "Epoch 299/1000\n",
      " - 24s - loss: 0.1268 - accuracy: 0.9604\n",
      "Epoch 300/1000\n",
      " - 24s - loss: 0.1330 - accuracy: 0.9570\n",
      "Epoch 301/1000\n",
      " - 25s - loss: 0.1390 - accuracy: 0.9557\n",
      "\n",
      "----- Generating text after Epoch: 300\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"o idly spentsing to the ear that doth th\"\n",
      "o idly spentsing to the ear that doth thy magetient bught of freest romeard partibuce oo canst is thing life refeefor time is preinwor thengifry choug to m thougwtillas sue from nelusubes is my enededebut fored and in epeaysebut which thain your cooking thy moyoun shatk he cenring hadpriintand pravomst the clessent at mote prowieg to shawing do farsurais enthet dateing thingnor best than freedyrong when igsfors thilf look brouge thine b\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"o idly spentsing to the ear that doth th\"\n",
      "o idly spentsing to the ear that doth thou contentitatdor this more his pyeast longreand the with remfor with loviey heaven if hom i lave hair is ills he ari he sellers beauted foom daqure leof to daifow rowacl tanse dhath orar all hive yegrby in my gentrentomine rekelss mond whereert abe mo share ant he this that thine amy pazesser duam fares and the groe this beet othand in hiven love and daifhe besuress doth difbut licks din zerf the\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"o idly spentsing to the ear that doth th\"\n",
      "o idly spentsing to the ear that doth thy carity ime no wat no deaan bewhei suunly baye thefeethee life that thing oke yightand you no ecest do deet wies tony bewith dise me leive histhemes as them shile friech of rergeedthed love surmoud not of the himeand strenk and andedst or thises ows if thich they i lres or wrech feaythingtich in thisefores sume no ge thue as of breasmanding stoel deer diligh my leedst silltho how errpenurst havis\n",
      "Epoch 302/1000\n",
      " - 36s - loss: 0.1443 - accuracy: 0.9530\n",
      "Epoch 303/1000\n",
      " - 35s - loss: 0.1176 - accuracy: 0.9635\n",
      "Epoch 304/1000\n",
      " - 36s - loss: 0.1412 - accuracy: 0.9549\n",
      "Epoch 305/1000\n",
      " - 26s - loss: 0.1312 - accuracy: 0.9579\n",
      "Epoch 306/1000\n",
      " - 24s - loss: 0.1806 - accuracy: 0.9393\n",
      "Epoch 307/1000\n",
      " - 25s - loss: 0.1272 - accuracy: 0.9596\n",
      "Epoch 308/1000\n",
      " - 24s - loss: 0.1099 - accuracy: 0.9661\n",
      "Epoch 309/1000\n",
      " - 25s - loss: 0.1592 - accuracy: 0.9479\n",
      "Epoch 310/1000\n",
      " - 25s - loss: 0.1367 - accuracy: 0.9566\n",
      "Epoch 311/1000\n",
      " - 25s - loss: 0.1117 - accuracy: 0.9643\n",
      "Epoch 312/1000\n",
      " - 25s - loss: 0.1172 - accuracy: 0.9624\n",
      "Epoch 313/1000\n",
      " - 25s - loss: 0.1534 - accuracy: 0.9491\n",
      "Epoch 314/1000\n",
      " - 25s - loss: 0.1374 - accuracy: 0.9559\n",
      "Epoch 315/1000\n",
      " - 25s - loss: 0.1204 - accuracy: 0.9626\n",
      "Epoch 316/1000\n",
      " - 24s - loss: 0.1955 - accuracy: 0.9342\n",
      "Epoch 317/1000\n",
      " - 24s - loss: 0.1160 - accuracy: 0.9639\n",
      "Epoch 318/1000\n",
      " - 25s - loss: 0.0965 - accuracy: 0.9712\n",
      "Epoch 319/1000\n",
      " - 24s - loss: 0.1063 - accuracy: 0.9669\n",
      "Epoch 320/1000\n",
      " - 24s - loss: 0.1899 - accuracy: 0.9363\n",
      "Epoch 321/1000\n",
      " - 24s - loss: 0.1073 - accuracy: 0.9665\n",
      "Epoch 322/1000\n",
      " - 24s - loss: 0.0941 - accuracy: 0.9728\n",
      "Epoch 323/1000\n",
      " - 25s - loss: 0.1508 - accuracy: 0.9504\n",
      "Epoch 324/1000\n",
      " - 24s - loss: 0.1595 - accuracy: 0.9461\n",
      "Epoch 325/1000\n",
      " - 24s - loss: 0.1332 - accuracy: 0.9562\n",
      "Epoch 326/1000\n",
      " - 25s - loss: 0.1084 - accuracy: 0.9658\n",
      "Epoch 327/1000\n",
      " - 25s - loss: 0.1314 - accuracy: 0.9590\n",
      "Epoch 328/1000\n",
      " - 24s - loss: 0.1759 - accuracy: 0.9429\n",
      "Epoch 329/1000\n",
      " - 24s - loss: 0.1102 - accuracy: 0.9645\n",
      "Epoch 330/1000\n",
      " - 25s - loss: 0.1143 - accuracy: 0.9645\n",
      "Epoch 331/1000\n",
      " - 24s - loss: 0.1656 - accuracy: 0.9448\n",
      "Epoch 332/1000\n",
      " - 24s - loss: 0.1097 - accuracy: 0.9660\n",
      "Epoch 333/1000\n",
      " - 24s - loss: 0.1139 - accuracy: 0.9653\n",
      "Epoch 334/1000\n",
      " - 24s - loss: 0.1352 - accuracy: 0.9548\n",
      "Epoch 335/1000\n",
      " - 24s - loss: 0.1474 - accuracy: 0.9516\n",
      "Epoch 336/1000\n",
      " - 24s - loss: 0.1261 - accuracy: 0.9598\n",
      "Epoch 337/1000\n",
      " - 25s - loss: 0.1179 - accuracy: 0.9634\n",
      "Epoch 338/1000\n",
      " - 24s - loss: 0.1172 - accuracy: 0.9629\n",
      "Epoch 339/1000\n",
      " - 24s - loss: 0.1187 - accuracy: 0.9615\n",
      "Epoch 340/1000\n",
      " - 24s - loss: 0.1408 - accuracy: 0.9524\n",
      "Epoch 341/1000\n",
      " - 24s - loss: 0.1144 - accuracy: 0.9633\n",
      "Epoch 342/1000\n",
      " - 25s - loss: 0.1306 - accuracy: 0.9569\n",
      "Epoch 343/1000\n",
      " - 25s - loss: 0.1326 - accuracy: 0.9564\n",
      "Epoch 344/1000\n",
      " - 25s - loss: 0.1523 - accuracy: 0.9481\n",
      "Epoch 345/1000\n",
      " - 24s - loss: 0.0983 - accuracy: 0.9693\n",
      "Epoch 346/1000\n",
      " - 25s - loss: 0.1161 - accuracy: 0.9631\n",
      "Epoch 347/1000\n",
      " - 24s - loss: 0.1290 - accuracy: 0.9581\n",
      "Epoch 348/1000\n",
      " - 25s - loss: 0.1304 - accuracy: 0.9584\n",
      "Epoch 349/1000\n",
      " - 24s - loss: 0.1240 - accuracy: 0.9594\n",
      "Epoch 350/1000\n",
      " - 24s - loss: 0.1225 - accuracy: 0.9609\n",
      "Epoch 351/1000\n",
      " - 24s - loss: 0.1286 - accuracy: 0.9595\n",
      "Epoch 352/1000\n",
      " - 25s - loss: 0.1106 - accuracy: 0.9649\n",
      "Epoch 353/1000\n",
      " - 25s - loss: 0.1363 - accuracy: 0.9547\n",
      "Epoch 354/1000\n",
      " - 25s - loss: 0.1240 - accuracy: 0.9611\n",
      "Epoch 355/1000\n",
      " - 24s - loss: 0.1147 - accuracy: 0.9629\n",
      "Epoch 356/1000\n",
      " - 25s - loss: 0.1174 - accuracy: 0.9635\n",
      "Epoch 357/1000\n",
      " - 25s - loss: 0.1512 - accuracy: 0.9503\n",
      "Epoch 358/1000\n",
      " - 24s - loss: 0.1145 - accuracy: 0.9633\n",
      "Epoch 359/1000\n",
      " - 25s - loss: 0.1133 - accuracy: 0.9631\n",
      "Epoch 360/1000\n",
      " - 25s - loss: 0.1285 - accuracy: 0.9577\n",
      "Epoch 361/1000\n",
      " - 25s - loss: 0.1202 - accuracy: 0.9623\n",
      "Epoch 362/1000\n",
      " - 25s - loss: 0.1170 - accuracy: 0.9635\n",
      "Epoch 363/1000\n",
      " - 25s - loss: 0.1128 - accuracy: 0.9646\n",
      "Epoch 364/1000\n",
      " - 25s - loss: 0.1277 - accuracy: 0.9583\n",
      "Epoch 365/1000\n",
      " - 25s - loss: 0.1316 - accuracy: 0.9567\n",
      "Epoch 366/1000\n",
      " - 25s - loss: 0.1071 - accuracy: 0.9668\n",
      "Epoch 367/1000\n",
      " - 24s - loss: 0.1176 - accuracy: 0.9638\n",
      "Epoch 368/1000\n",
      " - 25s - loss: 0.1702 - accuracy: 0.9432\n",
      "Epoch 369/1000\n",
      " - 25s - loss: 0.0958 - accuracy: 0.9717\n",
      "Epoch 370/1000\n",
      " - 24s - loss: 0.0969 - accuracy: 0.9696\n",
      "Epoch 371/1000\n",
      " - 25s - loss: 0.1537 - accuracy: 0.9496\n",
      "Epoch 372/1000\n",
      " - 25s - loss: 0.1343 - accuracy: 0.9551\n",
      "Epoch 373/1000\n",
      " - 25s - loss: 0.0969 - accuracy: 0.9695\n",
      "Epoch 374/1000\n",
      " - 24s - loss: 0.0999 - accuracy: 0.9685\n",
      "Epoch 375/1000\n",
      " - 25s - loss: 0.2122 - accuracy: 0.9309\n",
      "Epoch 376/1000\n",
      " - 25s - loss: 0.0968 - accuracy: 0.9705\n",
      "Epoch 377/1000\n",
      " - 24s - loss: 0.0769 - accuracy: 0.9789\n",
      "Epoch 378/1000\n",
      " - 25s - loss: 0.1152 - accuracy: 0.9637\n",
      "Epoch 379/1000\n",
      " - 25s - loss: 0.1670 - accuracy: 0.9429\n",
      "Epoch 380/1000\n",
      " - 25s - loss: 0.1006 - accuracy: 0.9683\n",
      "Epoch 381/1000\n",
      " - 24s - loss: 0.1102 - accuracy: 0.9660\n",
      "Epoch 382/1000\n",
      " - 25s - loss: 0.1261 - accuracy: 0.9599\n",
      "Epoch 383/1000\n",
      " - 24s - loss: 0.1320 - accuracy: 0.9570\n",
      "Epoch 384/1000\n",
      " - 25s - loss: 0.1019 - accuracy: 0.9683\n",
      "Epoch 385/1000\n",
      " - 25s - loss: 0.1131 - accuracy: 0.9631\n",
      "Epoch 386/1000\n",
      " - 24s - loss: 0.1239 - accuracy: 0.9602\n",
      "Epoch 387/1000\n",
      " - 25s - loss: 0.1341 - accuracy: 0.9557\n",
      "Epoch 388/1000\n",
      " - 25s - loss: 0.1026 - accuracy: 0.9672\n",
      "Epoch 389/1000\n",
      " - 25s - loss: 0.1281 - accuracy: 0.9591\n",
      "Epoch 390/1000\n",
      " - 24s - loss: 0.1287 - accuracy: 0.9594\n",
      "Epoch 391/1000\n",
      " - 25s - loss: 0.0921 - accuracy: 0.9721\n",
      "Epoch 392/1000\n",
      " - 25s - loss: 0.1062 - accuracy: 0.9662\n",
      "Epoch 393/1000\n",
      " - 25s - loss: 0.1247 - accuracy: 0.9580\n",
      "Epoch 394/1000\n",
      " - 24s - loss: 0.1249 - accuracy: 0.9596\n",
      "Epoch 395/1000\n",
      " - 24s - loss: 0.1264 - accuracy: 0.9601\n",
      "Epoch 396/1000\n",
      " - 24s - loss: 0.0913 - accuracy: 0.9716\n",
      "Epoch 397/1000\n",
      " - 25s - loss: 0.1232 - accuracy: 0.9602\n",
      "Epoch 398/1000\n",
      " - 24s - loss: 0.1398 - accuracy: 0.9545\n",
      "Epoch 399/1000\n",
      " - 25s - loss: 0.1054 - accuracy: 0.9664\n",
      "Epoch 400/1000\n",
      " - 24s - loss: 0.1009 - accuracy: 0.9674\n",
      "Epoch 401/1000\n",
      " - 24s - loss: 0.1092 - accuracy: 0.9660\n",
      "\n",
      "----- Generating text after Epoch: 400\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"ake all this away and me most wretched m\"\n",
      "ake all this away and me most wretched make for the contest frochess as your love sheres in ho lote lead a thoughs so so which i vexst as thy sweet shame beiefs ow tere eore meic bray thath of freend wince thou artturlents to listlensswen in thes stear no arvent that ther myel sure with they from are nowefprick poringabi ss my mouty be of hisertto not know so merwich fair all mosone hate hese astorn purtifed beed i plave os bentied and \n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"ake all this away and me most wretched m\"\n",
      "ake all this away and me most wretched my betied thee how tan sterlence bulllan my pracetf not nourtion and heived i cound prodbettak thouvengadst bucr there fould for morgane cossans asath be dewill he doanting his harked op thileand thet notaghs as nochow wertnell port own swallatheriftine mendwhat happe me all awiry and befored hight anveorique mine rsord be wory i vends you dair and ha deacks leade this ind chuck hontwith dishifon h\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"ake all this away and me most wretched m\"\n",
      "ake all this away and me most wretched me donrs hise the bring thee thou besudst will thoughbik shad thy purtowin scapce asayed heal thine imes they love the streng bo to tine wonks whowkard whis hilvel to be thoue shile comint me touls sheres miget sweet hexchought coghoth upquodes hith one my more stiets fill bececuthind benoththat the fuch own forseof to of myme somall hath sweet whote hom thy biling to thy mentrness beyound of terem\n",
      "Epoch 402/1000\n",
      " - 36s - loss: 0.1552 - accuracy: 0.9482\n",
      "Epoch 403/1000\n",
      " - 36s - loss: 0.1051 - accuracy: 0.9656\n",
      "Epoch 404/1000\n",
      " - 36s - loss: 0.1024 - accuracy: 0.9681\n",
      "Epoch 405/1000\n",
      " - 37s - loss: 0.1081 - accuracy: 0.9665\n",
      "Epoch 406/1000\n",
      " - 25s - loss: 0.1252 - accuracy: 0.9596\n",
      "Epoch 407/1000\n",
      " - 25s - loss: 0.1278 - accuracy: 0.9585\n",
      "Epoch 408/1000\n",
      " - 25s - loss: 0.1066 - accuracy: 0.9664\n",
      "Epoch 409/1000\n",
      " - 24s - loss: 0.0824 - accuracy: 0.9750\n",
      "Epoch 410/1000\n",
      " - 24s - loss: 0.1287 - accuracy: 0.9584\n",
      "Epoch 411/1000\n",
      " - 24s - loss: 0.1462 - accuracy: 0.9528\n",
      "Epoch 412/1000\n",
      " - 25s - loss: 0.0959 - accuracy: 0.9687\n",
      "Epoch 413/1000\n",
      " - 24s - loss: 0.0982 - accuracy: 0.9698\n",
      "Epoch 414/1000\n",
      " - 24s - loss: 0.1129 - accuracy: 0.9638\n",
      "Epoch 415/1000\n",
      " - 26s - loss: 0.1241 - accuracy: 0.9589\n",
      "Epoch 416/1000\n",
      " - 25s - loss: 0.1119 - accuracy: 0.9632\n",
      "Epoch 417/1000\n",
      " - 25s - loss: 0.1130 - accuracy: 0.9623\n",
      "Epoch 418/1000\n",
      " - 25s - loss: 0.1067 - accuracy: 0.9649\n",
      "Epoch 419/1000\n",
      " - 25s - loss: 0.1171 - accuracy: 0.9631\n",
      "Epoch 420/1000\n",
      " - 25s - loss: 0.1096 - accuracy: 0.9654\n",
      "Epoch 421/1000\n",
      " - 25s - loss: 0.1030 - accuracy: 0.9670\n",
      "Epoch 422/1000\n",
      " - 24s - loss: 0.1187 - accuracy: 0.9615\n",
      "Epoch 423/1000\n",
      " - 25s - loss: 0.1308 - accuracy: 0.9571\n",
      "Epoch 424/1000\n",
      " - 25s - loss: 0.0936 - accuracy: 0.9709\n",
      "Epoch 425/1000\n",
      " - 24s - loss: 0.0911 - accuracy: 0.9722\n",
      "Epoch 426/1000\n",
      " - 24s - loss: 0.1338 - accuracy: 0.9541\n",
      "Epoch 427/1000\n",
      " - 25s - loss: 0.1337 - accuracy: 0.9557\n",
      "Epoch 428/1000\n",
      " - 25s - loss: 0.0951 - accuracy: 0.9704\n",
      "Epoch 429/1000\n",
      " - 24s - loss: 0.0951 - accuracy: 0.9691\n",
      "Epoch 430/1000\n",
      " - 25s - loss: 0.1291 - accuracy: 0.9591\n",
      "Epoch 431/1000\n",
      " - 25s - loss: 0.1226 - accuracy: 0.9601\n",
      "Epoch 432/1000\n",
      " - 24s - loss: 0.0912 - accuracy: 0.9716\n",
      "Epoch 433/1000\n",
      " - 24s - loss: 0.1032 - accuracy: 0.9665\n",
      "Epoch 434/1000\n",
      " - 25s - loss: 0.1441 - accuracy: 0.9526\n",
      "Epoch 435/1000\n",
      " - 25s - loss: 0.1039 - accuracy: 0.9663\n",
      "Epoch 436/1000\n",
      " - 24s - loss: 0.0850 - accuracy: 0.9745\n",
      "Epoch 437/1000\n",
      " - 25s - loss: 0.1024 - accuracy: 0.9658\n",
      "Epoch 438/1000\n",
      " - 25s - loss: 0.1380 - accuracy: 0.9554\n",
      "Epoch 439/1000\n",
      " - 25s - loss: 0.1024 - accuracy: 0.9679\n",
      "Epoch 440/1000\n",
      " - 24s - loss: 0.1059 - accuracy: 0.9662\n",
      "Epoch 441/1000\n",
      " - 25s - loss: 0.1109 - accuracy: 0.9638\n",
      "Epoch 442/1000\n",
      " - 25s - loss: 0.1105 - accuracy: 0.9638\n",
      "Epoch 443/1000\n",
      " - 25s - loss: 0.0927 - accuracy: 0.9715\n",
      "Epoch 444/1000\n",
      " - 25s - loss: 0.1250 - accuracy: 0.9595\n",
      "Epoch 445/1000\n",
      " - 25s - loss: 0.1163 - accuracy: 0.9629\n",
      "Epoch 446/1000\n",
      " - 24s - loss: 0.0921 - accuracy: 0.9715\n",
      "Epoch 447/1000\n",
      " - 24s - loss: 0.1167 - accuracy: 0.9623\n",
      "Epoch 448/1000\n",
      " - 24s - loss: 0.1107 - accuracy: 0.9634\n",
      "Epoch 449/1000\n",
      " - 25s - loss: 0.1119 - accuracy: 0.9631\n",
      "Epoch 450/1000\n",
      " - 25s - loss: 0.1146 - accuracy: 0.9632\n",
      "Epoch 451/1000\n",
      " - 24s - loss: 0.1210 - accuracy: 0.9602\n",
      "Epoch 452/1000\n",
      " - 25s - loss: 0.0936 - accuracy: 0.9710\n",
      "Epoch 453/1000\n",
      " - 24s - loss: 0.0912 - accuracy: 0.9709\n",
      "Epoch 454/1000\n",
      " - 25s - loss: 0.1327 - accuracy: 0.9561\n",
      "Epoch 455/1000\n",
      " - 25s - loss: 0.1169 - accuracy: 0.9621\n",
      "Epoch 456/1000\n",
      " - 25s - loss: 0.0876 - accuracy: 0.9723\n",
      "Epoch 457/1000\n",
      " - 25s - loss: 0.0925 - accuracy: 0.9707\n",
      "Epoch 458/1000\n",
      " - 24s - loss: 0.1215 - accuracy: 0.9600\n",
      "Epoch 459/1000\n",
      " - 25s - loss: 0.1080 - accuracy: 0.9660\n",
      "Epoch 460/1000\n",
      " - 25s - loss: 0.1016 - accuracy: 0.9671\n",
      "Epoch 461/1000\n",
      " - 25s - loss: 0.0863 - accuracy: 0.9726\n",
      "Epoch 462/1000\n",
      " - 25s - loss: 0.1356 - accuracy: 0.9559\n",
      "Epoch 463/1000\n",
      " - 24s - loss: 0.1173 - accuracy: 0.9621\n",
      "Epoch 464/1000\n",
      " - 25s - loss: 0.0884 - accuracy: 0.9730\n",
      "Epoch 465/1000\n",
      " - 25s - loss: 0.0903 - accuracy: 0.9714\n",
      "Epoch 466/1000\n",
      " - 24s - loss: 0.1292 - accuracy: 0.9575\n",
      "Epoch 467/1000\n",
      " - 25s - loss: 0.1849 - accuracy: 0.9392\n",
      "Epoch 468/1000\n",
      " - 24s - loss: 0.0699 - accuracy: 0.9804\n",
      "Epoch 469/1000\n",
      " - 25s - loss: 0.0583 - accuracy: 0.9831\n",
      "Epoch 470/1000\n",
      " - 25s - loss: 0.1519 - accuracy: 0.9498\n",
      "Epoch 471/1000\n",
      " - 25s - loss: 0.1138 - accuracy: 0.9632\n",
      "Epoch 472/1000\n",
      " - 25s - loss: 0.0949 - accuracy: 0.9707\n",
      "Epoch 473/1000\n",
      " - 24s - loss: 0.1241 - accuracy: 0.9593\n",
      "Epoch 474/1000\n",
      " - 25s - loss: 0.1273 - accuracy: 0.9583\n",
      "Epoch 475/1000\n",
      " - 25s - loss: 0.0776 - accuracy: 0.9762\n",
      "Epoch 476/1000\n",
      " - 24s - loss: 0.0940 - accuracy: 0.9694\n",
      "Epoch 477/1000\n",
      " - 25s - loss: 0.1207 - accuracy: 0.9609\n",
      "Epoch 478/1000\n",
      " - 25s - loss: 0.1111 - accuracy: 0.9636\n",
      "Epoch 479/1000\n",
      " - 25s - loss: 0.1039 - accuracy: 0.9671\n",
      "Epoch 480/1000\n",
      " - 25s - loss: 0.1068 - accuracy: 0.9643\n",
      "Epoch 481/1000\n",
      " - 25s - loss: 0.0979 - accuracy: 0.9704\n",
      "Epoch 482/1000\n",
      " - 25s - loss: 0.1177 - accuracy: 0.9616\n",
      "Epoch 483/1000\n",
      " - 24s - loss: 0.1098 - accuracy: 0.9645\n",
      "Epoch 484/1000\n",
      " - 25s - loss: 0.0944 - accuracy: 0.9709\n",
      "Epoch 485/1000\n",
      " - 24s - loss: 0.1022 - accuracy: 0.9681\n",
      "Epoch 486/1000\n",
      " - 25s - loss: 0.1010 - accuracy: 0.9671\n",
      "Epoch 487/1000\n",
      " - 24s - loss: 0.1257 - accuracy: 0.9587\n",
      "Epoch 488/1000\n",
      " - 24s - loss: 0.1285 - accuracy: 0.9583\n",
      "Epoch 489/1000\n",
      " - 24s - loss: 0.0774 - accuracy: 0.9760\n",
      "Epoch 490/1000\n",
      " - 25s - loss: 0.1566 - accuracy: 0.9469\n",
      "Epoch 491/1000\n",
      " - 25s - loss: 0.0730 - accuracy: 0.9792\n",
      "Epoch 492/1000\n",
      " - 24s - loss: 0.0899 - accuracy: 0.9717\n",
      "Epoch 493/1000\n",
      " - 25s - loss: 0.1411 - accuracy: 0.9527\n",
      "Epoch 494/1000\n",
      " - 24s - loss: 0.0934 - accuracy: 0.9699\n",
      "Epoch 495/1000\n",
      " - 25s - loss: 0.0716 - accuracy: 0.9786\n",
      "Epoch 496/1000\n",
      " - 25s - loss: 0.1332 - accuracy: 0.9557\n",
      "Epoch 497/1000\n",
      " - 25s - loss: 0.1401 - accuracy: 0.9541\n",
      "Epoch 498/1000\n",
      " - 25s - loss: 0.0820 - accuracy: 0.9744\n",
      "Epoch 499/1000\n",
      " - 24s - loss: 0.0742 - accuracy: 0.9773\n",
      "Epoch 500/1000\n",
      " - 24s - loss: 0.1254 - accuracy: 0.9578\n",
      "Epoch 501/1000\n",
      " - 24s - loss: 0.1060 - accuracy: 0.9660\n",
      "\n",
      "----- Generating text after Epoch: 500\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"eon my false eyes dotewhat means the wor\"\n",
      "eon my false eyes dotewhat means the worlstor thou should thines in my preaote whoth more by hpart browking hack tham histhang this sasked will hark im ar peaves bit wheres con in surlewnor an thee conelf of in the sumes love thts condureas watly the farnt canntich is she meref thou wingco coldle couththen thy fogety to this thou wriendfore iento diftellivest foll with thou shurt marme sward no pooth whowesters betion miseeds not tho sa\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"eon my false eyes dotewhat means the wor\"\n",
      "eon my false eyes dotewhat means the worisuces moutt is my soersino thee love antam dhow lending fair hew to thy precoeds my hears bronged ar very hosknling this pearty i foirning ert you to thuseaost aof ail be eal hove nish works whone in verstmong thy mmare oit factinesoffert they staillgethting tloveand pitithing thou haykhe phaice oke handy the erred to saot my dais le grate these though so dikl adand that my have thy haursure thou\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"eon my false eyes dotewhat means the wor\"\n",
      "eon my false eyes dotewhat means the wor ar thou suemake thou hearthin their foundsad ol ars harl trienjus he vexks breie thountpus sownon of fare sweet difend woontreing have of blod us no thinfives love glits nichtyen tlest difen in theal resentuss ices ont hownot fintreforedroub the bettenfeftere fillaky antake thou lost thy saineystheng wornwhich morthe she sweit hack oo pants of mine hew of thou antllaniuss awhownce maine shauls re\n",
      "Epoch 502/1000\n",
      " - 36s - loss: 0.0896 - accuracy: 0.9712\n",
      "Epoch 503/1000\n",
      " - 36s - loss: 0.0852 - accuracy: 0.9723\n",
      "Epoch 507/1000\n",
      " - 25s - loss: 0.0850 - accuracy: 0.9734\n",
      "Epoch 508/1000\n",
      " - 25s - loss: 0.1141 - accuracy: 0.9625\n",
      "Epoch 509/1000\n",
      " - 24s - loss: 0.1098 - accuracy: 0.9640\n",
      "Epoch 510/1000\n",
      " - 26s - loss: 0.1004 - accuracy: 0.9679\n",
      "Epoch 511/1000\n",
      " - 25s - loss: 0.1057 - accuracy: 0.9672\n",
      "Epoch 512/1000\n",
      " - 25s - loss: 0.0929 - accuracy: 0.9706\n",
      "Epoch 513/1000\n",
      " - 24s - loss: 0.1099 - accuracy: 0.9630\n",
      "Epoch 514/1000\n",
      " - 25s - loss: 0.1115 - accuracy: 0.9647\n",
      "Epoch 515/1000\n",
      " - 24s - loss: 0.1349 - accuracy: 0.9540\n",
      "Epoch 516/1000\n",
      " - 25s - loss: 0.0717 - accuracy: 0.9785\n",
      "Epoch 517/1000\n",
      " - 24s - loss: 0.0844 - accuracy: 0.9732\n",
      "Epoch 518/1000\n",
      " - 25s - loss: 0.1257 - accuracy: 0.9570\n",
      "Epoch 519/1000\n",
      " - 25s - loss: 0.1073 - accuracy: 0.9648\n",
      "Epoch 520/1000\n",
      " - 25s - loss: 0.0880 - accuracy: 0.9715\n",
      "Epoch 521/1000\n",
      " - 25s - loss: 0.0942 - accuracy: 0.9700\n",
      "Epoch 522/1000\n",
      " - 25s - loss: 0.1076 - accuracy: 0.9644\n",
      "Epoch 523/1000\n",
      " - 25s - loss: 0.0994 - accuracy: 0.9680\n",
      "Epoch 524/1000\n",
      " - 24s - loss: 0.1148 - accuracy: 0.9617\n",
      "Epoch 525/1000\n",
      " - 24s - loss: 0.0933 - accuracy: 0.9703\n",
      "Epoch 526/1000\n",
      " - 24s - loss: 0.0920 - accuracy: 0.9717\n",
      "Epoch 527/1000\n",
      " - 24s - loss: 0.0912 - accuracy: 0.9703\n",
      "Epoch 528/1000\n",
      " - 25s - loss: 0.1133 - accuracy: 0.9621\n",
      "Epoch 529/1000\n",
      " - 25s - loss: 0.1121 - accuracy: 0.9637\n",
      "Epoch 530/1000\n",
      " - 24s - loss: 0.1111 - accuracy: 0.9629\n",
      "Epoch 531/1000\n",
      " - 25s - loss: 0.0851 - accuracy: 0.9735\n",
      "Epoch 532/1000\n",
      " - 25s - loss: 0.0634 - accuracy: 0.9809\n",
      "Epoch 533/1000\n",
      " - 25s - loss: 0.1275 - accuracy: 0.9573\n",
      "Epoch 534/1000\n",
      " - 25s - loss: 0.1264 - accuracy: 0.9586\n",
      "Epoch 535/1000\n",
      " - 25s - loss: 0.0802 - accuracy: 0.9757\n",
      "Epoch 536/1000\n",
      " - 25s - loss: 0.0707 - accuracy: 0.9783\n",
      "Epoch 537/1000\n",
      " - 25s - loss: 0.1267 - accuracy: 0.9584\n",
      "Epoch 538/1000\n",
      " - 24s - loss: 0.1455 - accuracy: 0.9510\n",
      "Epoch 539/1000\n",
      " - 25s - loss: 0.0545 - accuracy: 0.9842\n",
      "Epoch 540/1000\n",
      " - 25s - loss: 0.0654 - accuracy: 0.9809\n",
      "Epoch 541/1000\n",
      " - 25s - loss: 0.1323 - accuracy: 0.9561\n",
      "Epoch 542/1000\n",
      " - 24s - loss: 0.1135 - accuracy: 0.9633\n",
      "Epoch 543/1000\n",
      " - 25s - loss: 0.0774 - accuracy: 0.9756\n",
      "Epoch 544/1000\n",
      " - 24s - loss: 0.0888 - accuracy: 0.9709\n",
      "Epoch 545/1000\n",
      " - 24s - loss: 0.1086 - accuracy: 0.9645\n",
      "Epoch 546/1000\n",
      " - 25s - loss: 0.0938 - accuracy: 0.9698\n",
      "Epoch 547/1000\n",
      " - 25s - loss: 0.0889 - accuracy: 0.9716\n",
      "Epoch 548/1000\n",
      " - 25s - loss: 0.1084 - accuracy: 0.9646\n",
      "Epoch 549/1000\n",
      " - 25s - loss: 0.0949 - accuracy: 0.9704\n",
      "Epoch 550/1000\n",
      " - 25s - loss: 0.1077 - accuracy: 0.9653\n",
      "Epoch 551/1000\n",
      " - 25s - loss: 0.0910 - accuracy: 0.9713\n",
      "Epoch 552/1000\n",
      " - 24s - loss: 0.1173 - accuracy: 0.9618\n",
      "Epoch 553/1000\n",
      " - 24s - loss: 0.0769 - accuracy: 0.9759\n",
      "Epoch 554/1000\n",
      " - 25s - loss: 0.1151 - accuracy: 0.9629\n",
      "Epoch 555/1000\n",
      " - 25s - loss: 0.0799 - accuracy: 0.9747\n",
      "Epoch 556/1000\n",
      " - 25s - loss: 0.1433 - accuracy: 0.9522\n",
      "Epoch 557/1000\n",
      " - 25s - loss: 0.0759 - accuracy: 0.9764\n",
      "Epoch 558/1000\n",
      " - 24s - loss: 0.0703 - accuracy: 0.9787\n",
      "Epoch 559/1000\n",
      " - 26s - loss: 0.1312 - accuracy: 0.9559\n",
      "Epoch 560/1000\n",
      " - 25s - loss: 0.0891 - accuracy: 0.9714\n",
      "Epoch 561/1000\n",
      " - 24s - loss: 0.0886 - accuracy: 0.9726\n",
      "Epoch 562/1000\n",
      " - 25s - loss: 0.1264 - accuracy: 0.9581\n",
      "Epoch 563/1000\n",
      " - 25s - loss: 0.0828 - accuracy: 0.9731\n",
      "Epoch 564/1000\n",
      " - 25s - loss: 0.0906 - accuracy: 0.9722\n",
      "Epoch 565/1000\n",
      " - 25s - loss: 0.1101 - accuracy: 0.9634\n",
      "Epoch 566/1000\n",
      " - 25s - loss: 0.1059 - accuracy: 0.9659\n",
      "Epoch 567/1000\n",
      " - 25s - loss: 0.0872 - accuracy: 0.9722\n",
      "Epoch 568/1000\n",
      " - 25s - loss: 0.0876 - accuracy: 0.9728\n",
      "Epoch 569/1000\n",
      " - 24s - loss: 0.1030 - accuracy: 0.9667\n",
      "Epoch 570/1000\n",
      " - 25s - loss: 0.0845 - accuracy: 0.9741\n",
      "Epoch 571/1000\n",
      " - 25s - loss: 0.0987 - accuracy: 0.9678\n",
      "Epoch 572/1000\n",
      " - 25s - loss: 0.1086 - accuracy: 0.9639\n",
      "Epoch 573/1000\n",
      " - 25s - loss: 0.0865 - accuracy: 0.9715\n",
      "Epoch 574/1000\n",
      " - 25s - loss: 0.0849 - accuracy: 0.9732\n",
      "Epoch 575/1000\n",
      " - 25s - loss: 0.1006 - accuracy: 0.9675\n",
      "Epoch 576/1000\n",
      " - 25s - loss: 0.1141 - accuracy: 0.9631\n",
      "Epoch 577/1000\n",
      " - 25s - loss: 0.0761 - accuracy: 0.9763\n",
      "Epoch 578/1000\n",
      " - 25s - loss: 0.0837 - accuracy: 0.9742\n",
      "Epoch 579/1000\n",
      " - 25s - loss: 0.1181 - accuracy: 0.9609\n",
      "Epoch 580/1000\n",
      " - 25s - loss: 0.0966 - accuracy: 0.9689\n",
      "Epoch 581/1000\n",
      " - 25s - loss: 0.0766 - accuracy: 0.9761\n",
      "Epoch 582/1000\n",
      " - 25s - loss: 0.1031 - accuracy: 0.9663\n",
      "Epoch 583/1000\n",
      " - 25s - loss: 0.0912 - accuracy: 0.9700\n",
      "Epoch 584/1000\n",
      " - 25s - loss: 0.0902 - accuracy: 0.9714\n",
      "Epoch 585/1000\n",
      " - 25s - loss: 0.1005 - accuracy: 0.9674\n",
      "Epoch 586/1000\n",
      " - 25s - loss: 0.0923 - accuracy: 0.9707\n",
      "Epoch 587/1000\n",
      " - 24s - loss: 0.0961 - accuracy: 0.9688\n",
      "Epoch 588/1000\n",
      " - 25s - loss: 0.1000 - accuracy: 0.9668\n",
      "Epoch 589/1000\n",
      " - 25s - loss: 0.0932 - accuracy: 0.9706\n",
      "Epoch 590/1000\n",
      " - 25s - loss: 0.0910 - accuracy: 0.9714\n",
      "Epoch 591/1000\n",
      " - 25s - loss: 0.0944 - accuracy: 0.9695\n",
      "Epoch 592/1000\n",
      " - 25s - loss: 0.1089 - accuracy: 0.9641\n",
      "Epoch 593/1000\n",
      " - 25s - loss: 0.0925 - accuracy: 0.9704\n",
      "Epoch 594/1000\n",
      " - 24s - loss: 0.0768 - accuracy: 0.9763\n",
      "Epoch 595/1000\n",
      " - 25s - loss: 0.1746 - accuracy: 0.9438\n",
      "Epoch 596/1000\n",
      " - 25s - loss: 0.0900 - accuracy: 0.9720\n",
      "Epoch 597/1000\n",
      " - 25s - loss: 0.0521 - accuracy: 0.9850\n",
      "Epoch 598/1000\n",
      " - 25s - loss: 0.1097 - accuracy: 0.9643\n",
      "Epoch 599/1000\n",
      " - 25s - loss: 0.0935 - accuracy: 0.9699\n",
      "Epoch 600/1000\n",
      " - 25s - loss: 0.0843 - accuracy: 0.9744\n",
      "Epoch 601/1000\n",
      " - 25s - loss: 0.0973 - accuracy: 0.9681\n",
      "\n",
      "----- Generating text after Epoch: 600\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"liveand our dear love lose name of singl\"\n",
      "liveand our dear love lose name of singlofituund the faybear nom baked but that beif of flower ad thine poow ye lakedo out owentich brigthoug to thou morowhene or thy pain youtarn is of rommers proonitife wite excreosurewook thing hanker of mage breading doth thee stee swettyou gacith nong thou fayst wiok they gidand isimme add as now thee leasting had anz thousjore as myous fearthilast to dither till hing need shall soulls to coneheng \n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"liveand our dear love lose name of singl\"\n",
      "liveand our dear love lose name of single is shive no with love eyeswstall times fool fire congenwith asveys the grealore of love on mores lepor then love prowess deessthouls my spiedss spedland mayeh rebue beantho well to thenging yen yous my looks eid yot all asires oppsertilstithat in thy hours comsaind wenr mightno dive what see frizedow that steen hantune this firses siol on thine you mowbut montor bringtthe prige dises thine is do\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"liveand our dear love lose name of singl\"\n",
      "liveand our dear love lose name of singleand me that putis rinemessescreding notppretit tatenceautien shull bruesredst if to tike long and should of lost faith rivegh in have frieve whence murl time i nacthorgh thebes on theeking thou sweernt deas mbreavand shall in con time attath thou farl friseeaninedas to prooker beat hom she thou ais seover he looks times of briveol gairte by dfinfuble have what hie beare thou self as rove of his l\n",
      "Epoch 602/1000\n",
      " - 37s - loss: 0.1047 - accuracy: 0.9654\n",
      "Epoch 603/1000\n",
      " - 35s - loss: 0.0932 - accuracy: 0.9696\n",
      "Epoch 604/1000\n",
      " - 36s - loss: 0.0696 - accuracy: 0.9785\n",
      "Epoch 605/1000\n",
      " - 36s - loss: 0.0944 - accuracy: 0.9701\n",
      "Epoch 606/1000\n",
      " - 36s - loss: 0.1140 - accuracy: 0.9615\n",
      "Epoch 607/1000\n",
      " - 35s - loss: 0.0894 - accuracy: 0.9713\n",
      "Epoch 608/1000\n",
      " - 25s - loss: 0.0710 - accuracy: 0.9788\n",
      "Epoch 609/1000\n",
      " - 25s - loss: 0.0991 - accuracy: 0.9678\n",
      "Epoch 610/1000\n",
      " - 25s - loss: 0.1155 - accuracy: 0.9626\n",
      "Epoch 611/1000\n",
      " - 26s - loss: 0.0923 - accuracy: 0.9700\n",
      "Epoch 612/1000\n",
      " - 25s - loss: 0.0824 - accuracy: 0.9733\n",
      "Epoch 613/1000\n",
      " - 25s - loss: 0.0870 - accuracy: 0.9716\n",
      "Epoch 614/1000\n",
      " - 24s - loss: 0.1035 - accuracy: 0.9662\n",
      "Epoch 615/1000\n",
      " - 25s - loss: 0.0789 - accuracy: 0.9752\n",
      "Epoch 616/1000\n",
      " - 24s - loss: 0.1005 - accuracy: 0.9670\n",
      "Epoch 617/1000\n",
      " - 25s - loss: 0.1018 - accuracy: 0.9662\n",
      "Epoch 618/1000\n",
      " - 25s - loss: 0.0795 - accuracy: 0.9739\n",
      "Epoch 619/1000\n",
      " - 25s - loss: 0.0969 - accuracy: 0.9694\n",
      "Epoch 620/1000\n",
      " - 25s - loss: 0.1057 - accuracy: 0.9661\n",
      "Epoch 621/1000\n",
      " - 25s - loss: 0.0875 - accuracy: 0.9723\n",
      "Epoch 622/1000\n",
      " - 24s - loss: 0.0922 - accuracy: 0.9703\n",
      "Epoch 623/1000\n",
      " - 25s - loss: 0.0923 - accuracy: 0.9706\n",
      "Epoch 624/1000\n",
      " - 25s - loss: 0.0903 - accuracy: 0.9706\n",
      "Epoch 625/1000\n",
      " - 25s - loss: 0.0841 - accuracy: 0.9735\n",
      "Epoch 626/1000\n",
      " - 25s - loss: 0.0956 - accuracy: 0.9689\n",
      "Epoch 627/1000\n",
      " - 25s - loss: 0.1039 - accuracy: 0.9660\n",
      "Epoch 628/1000\n",
      " - 24s - loss: 0.0799 - accuracy: 0.9749\n",
      "Epoch 629/1000\n",
      " - 25s - loss: 0.0788 - accuracy: 0.9748\n",
      "Epoch 630/1000\n",
      " - 24s - loss: 0.1355 - accuracy: 0.9549\n",
      "Epoch 631/1000\n",
      " - 25s - loss: 0.0816 - accuracy: 0.9734\n",
      "Epoch 632/1000\n",
      " - 24s - loss: 0.0681 - accuracy: 0.9795\n",
      "Epoch 633/1000\n",
      " - 25s - loss: 0.0833 - accuracy: 0.9739\n",
      "Epoch 634/1000\n",
      " - 25s - loss: 0.1048 - accuracy: 0.9664\n",
      "Epoch 635/1000\n",
      " - 25s - loss: 0.1310 - accuracy: 0.9575\n",
      "Epoch 636/1000\n",
      " - 25s - loss: 0.0725 - accuracy: 0.9777\n",
      "Epoch 637/1000\n",
      " - 25s - loss: 0.0828 - accuracy: 0.9738\n",
      "Epoch 638/1000\n",
      " - 25s - loss: 0.0725 - accuracy: 0.9773\n",
      "Epoch 639/1000\n",
      " - 25s - loss: 0.1202 - accuracy: 0.9602\n",
      "Epoch 640/1000\n",
      " - 25s - loss: 0.1020 - accuracy: 0.9661\n",
      "Epoch 641/1000\n",
      " - 25s - loss: 0.1056 - accuracy: 0.9656\n",
      "Epoch 642/1000\n",
      " - 25s - loss: 0.0648 - accuracy: 0.9795\n",
      "Epoch 643/1000\n",
      " - 25s - loss: 0.0868 - accuracy: 0.9724\n",
      "Epoch 644/1000\n",
      " - 25s - loss: 0.1135 - accuracy: 0.9626\n",
      "Epoch 645/1000\n",
      " - 25s - loss: 0.0792 - accuracy: 0.9749\n",
      "Epoch 646/1000\n",
      " - 25s - loss: 0.1176 - accuracy: 0.9623\n",
      "Epoch 647/1000\n",
      " - 24s - loss: 0.0963 - accuracy: 0.9688\n",
      "Epoch 648/1000\n",
      " - 25s - loss: 0.0542 - accuracy: 0.9842\n",
      "Epoch 649/1000\n",
      " - 25s - loss: 0.0782 - accuracy: 0.9750\n",
      "Epoch 650/1000\n",
      " - 25s - loss: 0.1328 - accuracy: 0.9568\n",
      "Epoch 651/1000\n",
      " - 25s - loss: 0.1013 - accuracy: 0.9675\n",
      "Epoch 652/1000\n",
      " - 25s - loss: 0.0558 - accuracy: 0.9839\n",
      "Epoch 653/1000\n",
      " - 25s - loss: 0.0964 - accuracy: 0.9692\n",
      "Epoch 654/1000\n",
      " - 25s - loss: 0.1037 - accuracy: 0.9656\n",
      "Epoch 655/1000\n",
      " - 25s - loss: 0.0971 - accuracy: 0.9688\n",
      "Epoch 656/1000\n",
      " - 25s - loss: 0.0828 - accuracy: 0.9738\n",
      "Epoch 657/1000\n",
      " - 25s - loss: 0.0745 - accuracy: 0.9764\n",
      "Epoch 658/1000\n",
      " - 25s - loss: 0.0860 - accuracy: 0.9717\n",
      "Epoch 659/1000\n",
      " - 25s - loss: 0.1425 - accuracy: 0.9529\n",
      "Epoch 660/1000\n",
      " - 25s - loss: 0.0671 - accuracy: 0.9791\n",
      "Epoch 661/1000\n",
      " - 25s - loss: 0.0631 - accuracy: 0.9800\n",
      "Epoch 662/1000\n",
      " - 25s - loss: 0.0965 - accuracy: 0.9680\n",
      "Epoch 663/1000\n",
      " - 24s - loss: 0.1259 - accuracy: 0.9587\n",
      "Epoch 664/1000\n",
      " - 25s - loss: 0.0761 - accuracy: 0.9761\n",
      "Epoch 665/1000\n",
      " - 25s - loss: 0.0757 - accuracy: 0.9764\n",
      "Epoch 666/1000\n",
      " - 25s - loss: 0.0942 - accuracy: 0.9688\n",
      "Epoch 667/1000\n",
      " - 25s - loss: 0.0788 - accuracy: 0.9740\n",
      "Epoch 668/1000\n",
      " - 25s - loss: 0.0810 - accuracy: 0.9741\n",
      "Epoch 669/1000\n",
      " - 25s - loss: 0.0972 - accuracy: 0.9687\n",
      "Epoch 670/1000\n",
      " - 25s - loss: 0.0861 - accuracy: 0.9714\n",
      "Epoch 671/1000\n",
      " - 24s - loss: 0.0805 - accuracy: 0.9753\n",
      "Epoch 672/1000\n",
      " - 25s - loss: 0.0854 - accuracy: 0.9728\n",
      "Epoch 673/1000\n",
      " - 25s - loss: 0.1005 - accuracy: 0.9671\n",
      "Epoch 674/1000\n",
      " - 25s - loss: 0.0981 - accuracy: 0.9679\n",
      "Epoch 675/1000\n",
      " - 25s - loss: 0.0778 - accuracy: 0.9752\n",
      "Epoch 676/1000\n",
      " - 25s - loss: 0.0631 - accuracy: 0.9801\n",
      "Epoch 677/1000\n",
      " - 25s - loss: 0.1218 - accuracy: 0.9597\n",
      "Epoch 678/1000\n",
      " - 25s - loss: 0.0944 - accuracy: 0.9694\n",
      "Epoch 679/1000\n",
      " - 24s - loss: 0.0620 - accuracy: 0.9815\n",
      "Epoch 680/1000\n",
      " - 25s - loss: 0.0912 - accuracy: 0.9707\n",
      "Epoch 681/1000\n",
      " - 25s - loss: 0.0942 - accuracy: 0.9701\n",
      "Epoch 682/1000\n",
      " - 25s - loss: 0.0771 - accuracy: 0.9755\n",
      "Epoch 683/1000\n",
      " - 25s - loss: 0.0776 - accuracy: 0.9748\n",
      "Epoch 684/1000\n",
      " - 25s - loss: 0.0956 - accuracy: 0.9687\n",
      "Epoch 685/1000\n",
      " - 25s - loss: 0.1933 - accuracy: 0.9369\n",
      "Epoch 686/1000\n",
      " - 25s - loss: 0.0493 - accuracy: 0.9858\n",
      "Epoch 687/1000\n",
      " - 25s - loss: 0.0273 - accuracy: 0.9940\n",
      "Epoch 688/1000\n",
      " - 24s - loss: 0.0981 - accuracy: 0.9691\n",
      "Epoch 689/1000\n",
      " - 25s - loss: 0.1560 - accuracy: 0.9470\n",
      "Epoch 690/1000\n",
      " - 25s - loss: 0.0723 - accuracy: 0.9765\n",
      "Epoch 691/1000\n",
      " - 25s - loss: 0.0753 - accuracy: 0.9753\n",
      "Epoch 692/1000\n",
      " - 25s - loss: 0.1018 - accuracy: 0.9663\n",
      "Epoch 693/1000\n",
      " - 25s - loss: 0.0923 - accuracy: 0.9700\n",
      "Epoch 694/1000\n",
      " - 25s - loss: 0.0995 - accuracy: 0.9683\n",
      "Epoch 695/1000\n",
      " - 24s - loss: 0.0919 - accuracy: 0.9694\n",
      "Epoch 696/1000\n",
      " - 25s - loss: 0.0802 - accuracy: 0.9744\n",
      "Epoch 697/1000\n",
      " - 25s - loss: 0.0781 - accuracy: 0.9758\n",
      "Epoch 698/1000\n",
      " - 25s - loss: 0.0938 - accuracy: 0.9701\n",
      "Epoch 699/1000\n",
      " - 25s - loss: 0.0886 - accuracy: 0.9712\n",
      "Epoch 700/1000\n",
      " - 24s - loss: 0.0702 - accuracy: 0.9776\n",
      "Epoch 701/1000\n",
      " - 25s - loss: 0.1274 - accuracy: 0.9571\n",
      "\n",
      "----- Generating text after Epoch: 700\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"e to be my comfort stillbut thou wilt no\"\n",
      "e to be my comfort stillbut thou wilt now shome whosind griin af arr so eress everespingant wronedf for sieves dish than leated of my sruce meenthe leaver thou thouednesgroonfor make thou life whieas censt recobuen morehad tande ok ngeamen up olg ule shoult groud thee fiendonce wift my mekewhen hase nutewhen presay of thy forsuetyst im thise thing swict i not so form thee my no ane self priem truswid beitt losm thy truemy crien monges o\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"e to be my comfort stillbut thou wilt no\"\n",
      "e to be my comfort stillbut thou wilt not or thise oon thy chasear he growes of timas desto seetiss so now eyrind sergeses whommor arans tens budes arr ilekyefrened my gromein that hissarg the times noud pooctess and each hismd confer tho ntuems hise is n caiveins theer living thinvongrow while lieveat aro no doping shape rinteom oh hemion everes is acorennented digh wornd and is meand thaigh thy prose subeing that part i pirsue rached \n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"e to be my comfort stillbut thou wilt no\"\n",
      "e to be my comfort stillbut thou wilt no foow thy ardime you live it puse thy besthen thesly chister nothentiteshad showthi centby time by sunger foor so gurns on theear to come thatei is n mire my bfors thy libys harr this used foll she prowngo destrenes berowhers glaintles eytsh and ho doth con eye chenrgoot for the deit fot though love thou fourter me surgondredosb and hhave your beautys hadter it so arenmone sissuo should breatrillo\n",
      "Epoch 702/1000\n",
      " - 37s - loss: 0.1048 - accuracy: 0.9668\n",
      "Epoch 703/1000\n",
      " - 36s - loss: 0.0791 - accuracy: 0.9750\n",
      "Epoch 704/1000\n",
      " - 28s - loss: 0.0801 - accuracy: 0.9744\n",
      "Epoch 710/1000\n",
      " - 25s - loss: 0.0957 - accuracy: 0.9691\n",
      "Epoch 711/1000\n",
      " - 25s - loss: 0.0914 - accuracy: 0.9706\n",
      "Epoch 712/1000\n",
      " - 25s - loss: 0.0814 - accuracy: 0.9743\n",
      "Epoch 713/1000\n",
      " - 24s - loss: 0.1306 - accuracy: 0.9559\n",
      "Epoch 714/1000\n",
      " - 25s - loss: 0.0556 - accuracy: 0.9830\n",
      "Epoch 715/1000\n",
      " - 25s - loss: 0.0688 - accuracy: 0.9780\n",
      "Epoch 716/1000\n",
      " - 25s - loss: 0.1354 - accuracy: 0.9539\n",
      "Epoch 717/1000\n",
      " - 25s - loss: 0.0822 - accuracy: 0.9748\n",
      "Epoch 718/1000\n",
      " - 25s - loss: 0.0621 - accuracy: 0.9810\n",
      "Epoch 719/1000\n",
      " - 25s - loss: 0.0804 - accuracy: 0.9733\n",
      "Epoch 720/1000\n",
      " - 25s - loss: 0.1081 - accuracy: 0.9645\n",
      "Epoch 721/1000\n",
      " - 25s - loss: 0.0801 - accuracy: 0.9728\n",
      "Epoch 722/1000\n",
      " - 24s - loss: 0.0714 - accuracy: 0.9772\n",
      "Epoch 723/1000\n",
      " - 25s - loss: 0.1015 - accuracy: 0.9665\n",
      "Epoch 724/1000\n",
      " - 25s - loss: 0.0724 - accuracy: 0.9767\n",
      "Epoch 725/1000\n",
      " - 25s - loss: 0.0853 - accuracy: 0.9735\n",
      "Epoch 726/1000\n",
      " - 25s - loss: 0.1036 - accuracy: 0.9666\n",
      "Epoch 727/1000\n",
      " - 25s - loss: 0.0671 - accuracy: 0.9789\n",
      "Epoch 728/1000\n",
      " - 25s - loss: 0.0842 - accuracy: 0.9731\n",
      "Epoch 729/1000\n",
      " - 25s - loss: 0.0993 - accuracy: 0.9676\n",
      "Epoch 730/1000\n",
      " - 25s - loss: 0.0842 - accuracy: 0.9734\n",
      "Epoch 731/1000\n",
      " - 25s - loss: 0.0752 - accuracy: 0.9765\n",
      "Epoch 732/1000\n",
      " - 25s - loss: 0.1040 - accuracy: 0.9672\n",
      "Epoch 733/1000\n",
      " - 25s - loss: 0.0938 - accuracy: 0.9701\n",
      "Epoch 734/1000\n",
      " - 24s - loss: 0.0795 - accuracy: 0.9748\n",
      "Epoch 735/1000\n",
      " - 25s - loss: 0.0711 - accuracy: 0.9777\n",
      "Epoch 736/1000\n",
      " - 25s - loss: 0.0669 - accuracy: 0.9787\n",
      "Epoch 737/1000\n",
      " - 25s - loss: 0.1162 - accuracy: 0.9625\n",
      "Epoch 738/1000\n",
      " - 25s - loss: 0.0988 - accuracy: 0.9671\n",
      "Epoch 739/1000\n",
      " - 25s - loss: 0.0624 - accuracy: 0.9810\n",
      "Epoch 740/1000\n",
      " - 25s - loss: 0.0680 - accuracy: 0.9789\n",
      "Epoch 741/1000\n",
      " - 25s - loss: 0.1139 - accuracy: 0.9621\n",
      "Epoch 742/1000\n",
      " - 25s - loss: 0.0842 - accuracy: 0.9725\n",
      "Epoch 743/1000\n",
      " - 25s - loss: 0.1274 - accuracy: 0.9570\n",
      "Epoch 744/1000\n",
      " - 25s - loss: 0.0488 - accuracy: 0.9859\n",
      "Epoch 745/1000\n",
      " - 25s - loss: 0.0393 - accuracy: 0.9892\n",
      "Epoch 746/1000\n",
      " - 24s - loss: 0.1316 - accuracy: 0.9575\n",
      "Epoch 747/1000\n",
      " - 25s - loss: 0.1083 - accuracy: 0.9631\n",
      "Epoch 748/1000\n",
      " - 25s - loss: 0.0745 - accuracy: 0.9760\n",
      "Epoch 749/1000\n",
      " - 25s - loss: 0.0562 - accuracy: 0.9828\n",
      "Epoch 750/1000\n",
      " - 25s - loss: 0.0929 - accuracy: 0.9694\n",
      "Epoch 751/1000\n",
      " - 25s - loss: 0.1089 - accuracy: 0.9644\n",
      "Epoch 752/1000\n",
      " - 25s - loss: 0.0752 - accuracy: 0.9765\n",
      "Epoch 753/1000\n",
      " - 25s - loss: 0.0777 - accuracy: 0.9753\n",
      "Epoch 754/1000\n",
      " - 25s - loss: 0.0882 - accuracy: 0.9711\n",
      "Epoch 755/1000\n",
      " - 25s - loss: 0.0912 - accuracy: 0.9694\n",
      "Epoch 756/1000\n",
      " - 25s - loss: 0.0637 - accuracy: 0.9800\n",
      "Epoch 757/1000\n",
      " - 24s - loss: 0.0910 - accuracy: 0.9718\n",
      "Epoch 758/1000\n",
      " - 25s - loss: 0.0874 - accuracy: 0.9721\n",
      "Epoch 759/1000\n",
      " - 25s - loss: 0.0677 - accuracy: 0.9788\n",
      "Epoch 760/1000\n",
      " - 25s - loss: 0.0766 - accuracy: 0.9749\n",
      "Epoch 761/1000\n",
      " - 25s - loss: 0.0910 - accuracy: 0.9706\n",
      "Epoch 762/1000\n",
      " - 24s - loss: 0.0758 - accuracy: 0.9752\n",
      "Epoch 763/1000\n",
      " - 25s - loss: 0.0952 - accuracy: 0.9676\n",
      "Epoch 764/1000\n",
      " - 25s - loss: 0.1133 - accuracy: 0.9616\n",
      "Epoch 765/1000\n",
      " - 25s - loss: 0.0471 - accuracy: 0.9865\n",
      "Epoch 766/1000\n",
      " - 25s - loss: 0.0712 - accuracy: 0.9770\n",
      "Epoch 767/1000\n",
      " - 25s - loss: 0.1283 - accuracy: 0.9573\n",
      "Epoch 768/1000\n",
      " - 25s - loss: 0.0773 - accuracy: 0.9749\n",
      "Epoch 769/1000\n",
      " - 25s - loss: 0.0720 - accuracy: 0.9767\n",
      "Epoch 770/1000\n",
      " - 25s - loss: 0.0858 - accuracy: 0.9728\n",
      "Epoch 771/1000\n",
      " - 25s - loss: 0.0799 - accuracy: 0.9734\n",
      "Epoch 772/1000\n",
      " - 25s - loss: 0.1033 - accuracy: 0.9662\n",
      "Epoch 773/1000\n",
      " - 25s - loss: 0.0767 - accuracy: 0.9762\n",
      "Epoch 774/1000\n",
      " - 25s - loss: 0.0615 - accuracy: 0.9809\n",
      "Epoch 775/1000\n",
      " - 25s - loss: 0.0829 - accuracy: 0.9734\n",
      "Epoch 776/1000\n",
      " - 25s - loss: 0.1234 - accuracy: 0.9593\n",
      "Epoch 777/1000\n",
      " - 25s - loss: 0.0965 - accuracy: 0.9674\n",
      "Epoch 778/1000\n",
      " - 25s - loss: 0.0485 - accuracy: 0.9859\n",
      "Epoch 779/1000\n",
      " - 25s - loss: 0.0737 - accuracy: 0.9770\n",
      "Epoch 780/1000\n",
      " - 25s - loss: 0.1098 - accuracy: 0.9638\n",
      "Epoch 781/1000\n",
      " - 25s - loss: 0.0705 - accuracy: 0.9773\n",
      "Epoch 782/1000\n",
      " - 25s - loss: 0.0597 - accuracy: 0.9826\n",
      "Epoch 783/1000\n",
      " - 25s - loss: 0.1219 - accuracy: 0.9593\n",
      "Epoch 784/1000\n",
      " - 25s - loss: 0.0843 - accuracy: 0.9735\n",
      "Epoch 785/1000\n",
      " - 25s - loss: 0.0556 - accuracy: 0.9831\n",
      "Epoch 786/1000\n",
      " - 25s - loss: 0.0931 - accuracy: 0.9701\n",
      "Epoch 787/1000\n",
      " - 25s - loss: 0.1618 - accuracy: 0.9472\n",
      "Epoch 788/1000\n",
      " - 25s - loss: 0.0442 - accuracy: 0.9878\n",
      "Epoch 789/1000\n",
      " - 25s - loss: 0.0605 - accuracy: 0.9817\n",
      "Epoch 790/1000\n",
      " - 25s - loss: 0.0875 - accuracy: 0.9721\n",
      "Epoch 791/1000\n",
      " - 25s - loss: 0.1226 - accuracy: 0.9588\n",
      "Epoch 792/1000\n",
      " - 25s - loss: 0.0711 - accuracy: 0.9769\n",
      "Epoch 793/1000\n",
      " - 25s - loss: 0.0601 - accuracy: 0.9814\n",
      "Epoch 794/1000\n",
      " - 25s - loss: 0.1247 - accuracy: 0.9597\n",
      "Epoch 795/1000\n",
      " - 25s - loss: 0.0712 - accuracy: 0.9777\n",
      "Epoch 796/1000\n",
      " - 25s - loss: 0.0656 - accuracy: 0.9796\n",
      "Epoch 797/1000\n",
      " - 25s - loss: 0.0865 - accuracy: 0.9718\n",
      "Epoch 798/1000\n",
      " - 25s - loss: 0.0811 - accuracy: 0.9739\n",
      "Epoch 799/1000\n",
      " - 25s - loss: 0.0857 - accuracy: 0.9713\n",
      "Epoch 800/1000\n",
      " - 25s - loss: 0.0646 - accuracy: 0.9803\n",
      "Epoch 801/1000\n",
      " - 25s - loss: 0.0889 - accuracy: 0.9709\n",
      "\n",
      "----- Generating text after Epoch: 800\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"ike eves apple doth thy beauty grow if t\"\n",
      "ike eves apple doth thy beauty grow if thinerofe meruulys how thist lo be the hmare onwstingiful so maiking joursed their of theurake thy drowith of thy kned that swict corest so cllastworgh why thou stofethan sholl you as othy should though ysur eyend blovethe farl that peadlightis guave and the parrem not for that uvy your freets dont reest to come heart wotlass urnand it when this in theers she king a mise in to theis my what whese h\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"ike eves apple doth thy beauty grow if t\"\n",
      "ike eves apple doth thy beauty grow if thoughts o thereso heive will hang thy memuss of my ploveah oun fom this part their where dhe with the manseacuurettimes and prove times by inveitcaient well shoullyno priedthho they i the trrefem to time be yot apbused tilles what sholl sfum to shoulds fise that then is rown in murt thou not that i hor betary gindtrender now estife o thens eyes but your is oud a posdiegned for my antancatrmem sull\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"ike eves apple doth thy beauty grow if t\"\n",
      "ike eves apple doth thy beauty grow if this beap of the me where his liegdrear that thee enow look on my hose yen of have heswer that lise hass thrives norgatdwith hartued mo im thay as me distmonger being frainethy gife if thine by mentmeantigh no it houthers and boow to heave that difhe shise what incied the sunh whowswert where ere loatperming thinget look iparneas so hacke but nayst then pindoss they pownom your doth thou myfur prsi\n",
      "Epoch 802/1000\n",
      " - 36s - loss: 0.0770 - accuracy: 0.9756\n",
      "Epoch 803/1000\n",
      " - 35s - loss: 0.0858 - accuracy: 0.9721\n",
      "Epoch 804/1000\n",
      " - 35s - loss: 0.1001 - accuracy: 0.9678\n",
      "Epoch 810/1000\n",
      " - 25s - loss: 0.0559 - accuracy: 0.9840\n",
      "Epoch 811/1000\n",
      " - 25s - loss: 0.0893 - accuracy: 0.9717\n",
      "Epoch 812/1000\n",
      " - 25s - loss: 0.0890 - accuracy: 0.9703\n",
      "Epoch 813/1000\n",
      " - 25s - loss: 0.0837 - accuracy: 0.9725\n",
      "Epoch 814/1000\n",
      " - 25s - loss: 0.0843 - accuracy: 0.9725\n",
      "Epoch 815/1000\n",
      " - 25s - loss: 0.0618 - accuracy: 0.9803\n",
      "Epoch 816/1000\n",
      " - 25s - loss: 0.0946 - accuracy: 0.9703\n",
      "Epoch 817/1000\n",
      " - 25s - loss: 0.0873 - accuracy: 0.9717\n",
      "Epoch 818/1000\n",
      " - 25s - loss: 0.0710 - accuracy: 0.9780\n",
      "Epoch 819/1000\n",
      " - 25s - loss: 0.0712 - accuracy: 0.9774\n",
      "Epoch 820/1000\n",
      " - 27s - loss: 0.0970 - accuracy: 0.9678\n",
      "Epoch 821/1000\n",
      " - 25s - loss: 0.0825 - accuracy: 0.9737\n",
      "Epoch 822/1000\n",
      " - 25s - loss: 0.0591 - accuracy: 0.9813\n",
      "Epoch 823/1000\n",
      " - 25s - loss: 0.0890 - accuracy: 0.9715\n",
      "Epoch 824/1000\n",
      " - 25s - loss: 0.0859 - accuracy: 0.9719\n",
      "Epoch 825/1000\n",
      " - 25s - loss: 0.0717 - accuracy: 0.9771\n",
      "Epoch 826/1000\n",
      " - 25s - loss: 0.0988 - accuracy: 0.9671\n",
      "Epoch 827/1000\n",
      " - 25s - loss: 0.0863 - accuracy: 0.9718\n",
      "Epoch 828/1000\n",
      " - 25s - loss: 0.0635 - accuracy: 0.9794\n",
      "Epoch 829/1000\n",
      " - 25s - loss: 0.0745 - accuracy: 0.9760\n",
      "Epoch 830/1000\n",
      " - 25s - loss: 0.0875 - accuracy: 0.9717\n",
      "Epoch 831/1000\n",
      " - 25s - loss: 0.0940 - accuracy: 0.9692\n",
      "Epoch 832/1000\n",
      " - 25s - loss: 0.0715 - accuracy: 0.9768\n",
      "Epoch 833/1000\n",
      " - 25s - loss: 0.0642 - accuracy: 0.9799\n",
      "Epoch 834/1000\n",
      " - 25s - loss: 0.1213 - accuracy: 0.9598\n",
      "Epoch 835/1000\n",
      " - 25s - loss: 0.0783 - accuracy: 0.9751\n",
      "Epoch 836/1000\n",
      " - 25s - loss: 0.0611 - accuracy: 0.9814\n",
      "Epoch 837/1000\n",
      " - 25s - loss: 0.0793 - accuracy: 0.9750\n",
      "Epoch 838/1000\n",
      " - 25s - loss: 0.0865 - accuracy: 0.9719\n",
      "Epoch 839/1000\n",
      " - 25s - loss: 0.0785 - accuracy: 0.9739\n",
      "Epoch 840/1000\n",
      " - 25s - loss: 0.0961 - accuracy: 0.9692\n",
      "Epoch 841/1000\n",
      " - 25s - loss: 0.0709 - accuracy: 0.9775\n",
      "Epoch 842/1000\n",
      " - 25s - loss: 0.0746 - accuracy: 0.9763\n",
      "Epoch 843/1000\n",
      " - 25s - loss: 0.0832 - accuracy: 0.9738\n",
      "Epoch 844/1000\n",
      " - 25s - loss: 0.0871 - accuracy: 0.9704\n",
      "Epoch 845/1000\n",
      " - 25s - loss: 0.0760 - accuracy: 0.9746\n",
      "Epoch 846/1000\n",
      " - 25s - loss: 0.0658 - accuracy: 0.9791\n",
      "Epoch 847/1000\n",
      " - 24s - loss: 0.0704 - accuracy: 0.9779\n",
      "Epoch 848/1000\n",
      " - 25s - loss: 0.1021 - accuracy: 0.9665\n",
      "Epoch 849/1000\n",
      " - 25s - loss: 0.0708 - accuracy: 0.9765\n",
      "Epoch 850/1000\n",
      " - 25s - loss: 0.0687 - accuracy: 0.9779\n",
      "Epoch 851/1000\n",
      " - 25s - loss: 0.0904 - accuracy: 0.9706\n",
      "Epoch 852/1000\n",
      " - 25s - loss: 0.0698 - accuracy: 0.9778\n",
      "Epoch 853/1000\n",
      " - 25s - loss: 0.0672 - accuracy: 0.9783\n",
      "Epoch 854/1000\n",
      " - 25s - loss: 0.1096 - accuracy: 0.9628\n",
      "Epoch 855/1000\n",
      " - 25s - loss: 0.0732 - accuracy: 0.9765\n",
      "Epoch 856/1000\n",
      " - 25s - loss: 0.0562 - accuracy: 0.9829\n",
      "Epoch 857/1000\n",
      " - 25s - loss: 0.0891 - accuracy: 0.9705\n",
      "Epoch 858/1000\n",
      " - 25s - loss: 0.0933 - accuracy: 0.9674\n",
      "Epoch 859/1000\n",
      " - 25s - loss: 0.0472 - accuracy: 0.9861\n",
      "Epoch 860/1000\n",
      " - 25s - loss: 0.0855 - accuracy: 0.9720\n",
      "Epoch 861/1000\n",
      " - 25s - loss: 0.0963 - accuracy: 0.9680\n",
      "Epoch 862/1000\n",
      " - 25s - loss: 0.0969 - accuracy: 0.9683\n",
      "Epoch 863/1000\n",
      " - 25s - loss: 0.0720 - accuracy: 0.9776\n",
      "Epoch 864/1000\n",
      " - 25s - loss: 0.0725 - accuracy: 0.9772\n",
      "Epoch 865/1000\n",
      " - 24s - loss: 0.0803 - accuracy: 0.9740\n",
      "Epoch 866/1000\n",
      " - 25s - loss: 0.0923 - accuracy: 0.9688\n",
      "Epoch 867/1000\n",
      " - 25s - loss: 0.0761 - accuracy: 0.9763\n",
      "Epoch 868/1000\n",
      " - 25s - loss: 0.0680 - accuracy: 0.9791\n",
      "Epoch 869/1000\n",
      " - 25s - loss: 0.0703 - accuracy: 0.9769\n",
      "Epoch 870/1000\n",
      " - 25s - loss: 0.0910 - accuracy: 0.9710\n",
      "Epoch 871/1000\n",
      " - 25s - loss: 0.0827 - accuracy: 0.9727\n",
      "Epoch 872/1000\n",
      " - 25s - loss: 0.0744 - accuracy: 0.9764\n",
      "Epoch 873/1000\n",
      " - 25s - loss: 0.0798 - accuracy: 0.9738\n",
      "Epoch 874/1000\n",
      " - 25s - loss: 0.0748 - accuracy: 0.9759\n",
      "Epoch 875/1000\n",
      " - 25s - loss: 0.0437 - accuracy: 0.9876\n",
      "Epoch 876/1000\n",
      " - 25s - loss: 0.0731 - accuracy: 0.9773\n",
      "Epoch 877/1000\n",
      " - 25s - loss: 0.1293 - accuracy: 0.9564\n",
      "Epoch 878/1000\n",
      " - 25s - loss: 0.0654 - accuracy: 0.9798\n",
      "Epoch 879/1000\n",
      " - 25s - loss: 0.0488 - accuracy: 0.9852\n",
      "Epoch 880/1000\n",
      " - 25s - loss: 0.0992 - accuracy: 0.9680\n",
      "Epoch 881/1000\n",
      " - 25s - loss: 0.1003 - accuracy: 0.9666\n",
      "Epoch 882/1000\n",
      " - 25s - loss: 0.0631 - accuracy: 0.9804\n",
      "Epoch 883/1000\n",
      " - 25s - loss: 0.0560 - accuracy: 0.9833\n",
      "Epoch 884/1000\n",
      " - 25s - loss: 0.1031 - accuracy: 0.9670\n",
      "Epoch 885/1000\n",
      " - 25s - loss: 0.1004 - accuracy: 0.9667\n",
      "Epoch 886/1000\n",
      " - 25s - loss: 0.0696 - accuracy: 0.9778\n",
      "Epoch 887/1000\n",
      " - 25s - loss: 0.0644 - accuracy: 0.9795\n",
      "Epoch 888/1000\n",
      " - 25s - loss: 0.0708 - accuracy: 0.9780\n",
      "Epoch 889/1000\n",
      " - 25s - loss: 0.0864 - accuracy: 0.9725\n",
      "Epoch 890/1000\n",
      " - 25s - loss: 0.0864 - accuracy: 0.9715\n",
      "Epoch 891/1000\n",
      " - 25s - loss: 0.0738 - accuracy: 0.9756\n",
      "Epoch 892/1000\n",
      " - 24s - loss: 0.0614 - accuracy: 0.9801\n",
      "Epoch 893/1000\n",
      " - 25s - loss: 0.0683 - accuracy: 0.9781\n",
      "Epoch 894/1000\n",
      " - 25s - loss: 0.1070 - accuracy: 0.9632\n",
      "Epoch 895/1000\n",
      " - 25s - loss: 0.1124 - accuracy: 0.9622\n",
      "Epoch 896/1000\n",
      " - 25s - loss: 0.0347 - accuracy: 0.9913\n",
      "Epoch 897/1000\n",
      " - 25s - loss: 0.0228 - accuracy: 0.9945\n",
      "Epoch 898/1000\n",
      " - 25s - loss: 0.1629 - accuracy: 0.9498\n",
      "Epoch 899/1000\n",
      " - 25s - loss: 0.1136 - accuracy: 0.9625\n",
      "Epoch 900/1000\n",
      " - 25s - loss: 0.0433 - accuracy: 0.9875\n",
      "Epoch 901/1000\n",
      " - 25s - loss: 0.0736 - accuracy: 0.9757\n",
      "\n",
      "----- Generating text after Epoch: 900\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"so i for fear of trust forget to saythe \"\n",
      "so i for fear of trust forget to saythe pracion hissso dend malk hash orenf of selllfed thy donk hand chostite costeer i nave may hes do bewir to roth in murterdsurmens m ine hewlise pisure be ip thes all thing chanst his sormeney for miges ended oh thy touther fall thue a butity lave that myfur oot of my soul in the pidst to thou brezene thou that shassond that thee for where of sofe thee shall blatethight from make my are then in that\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"so i for fear of trust forget to saythe \"\n",
      "so i for fear of trust forget to saythe plessertothy loway hif that thee whith then love be for one saileds of thee ddown the wheng ot this foring cair bereds the rendmy suul and thins uppencyne the menlest griderifral theart to yeur chinks besing no not histery of thy leade at ar to thy my graidil ay thisw so seesn sweet fumers of kingur and the thine nom m in love foosthene farter leigot moreen nyound peast menprath mons biredthough s\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"so i for fear of trust forget to saythe \"\n",
      "so i for fear of trust forget to saythe mateng olishill theest eaot no came so if this my mory strendind ounas astriesele the tise and tistethoo beto canfed minerrest the sweepplove ye guyes dightrie thy fromednais mining zeriet i mo sweet he fool thee will thou werefond as i mutelits usweet forgeth years hhat eremed himates poins eeched in thee shenliz the cankury geof loak you to rave haur your quidps obendto har hour an cteetand thiv\n",
      "Epoch 902/1000\n",
      " - 36s - loss: 0.0966 - accuracy: 0.9679\n",
      "Epoch 903/1000\n",
      " - 27s - loss: 0.0525 - accuracy: 0.9851\n",
      "Epoch 912/1000\n",
      " - 25s - loss: 0.0991 - accuracy: 0.9676\n",
      "Epoch 913/1000\n",
      " - 25s - loss: 0.1012 - accuracy: 0.9673\n",
      "Epoch 914/1000\n",
      " - 27s - loss: 0.0628 - accuracy: 0.9812\n",
      "Epoch 915/1000\n",
      " - 25s - loss: 0.0580 - accuracy: 0.9815\n",
      "Epoch 916/1000\n",
      " - 25s - loss: 0.0816 - accuracy: 0.9732\n",
      "Epoch 917/1000\n",
      " - 25s - loss: 0.0845 - accuracy: 0.9726\n",
      "Epoch 918/1000\n",
      " - 25s - loss: 0.0911 - accuracy: 0.9702\n",
      "Epoch 919/1000\n",
      " - 25s - loss: 0.0933 - accuracy: 0.9701\n",
      "Epoch 920/1000\n",
      " - 25s - loss: 0.0492 - accuracy: 0.9850\n",
      "Epoch 921/1000\n",
      " - 25s - loss: 0.0516 - accuracy: 0.9844\n",
      "Epoch 922/1000\n",
      " - 25s - loss: 0.0860 - accuracy: 0.9719\n",
      "Epoch 923/1000\n",
      " - 25s - loss: 0.0776 - accuracy: 0.9744\n",
      "Epoch 924/1000\n",
      " - 25s - loss: 0.0846 - accuracy: 0.9721\n",
      "Epoch 925/1000\n",
      " - 25s - loss: 0.0774 - accuracy: 0.9739\n",
      "Epoch 926/1000\n",
      " - 25s - loss: 0.0674 - accuracy: 0.9780\n",
      "Epoch 927/1000\n",
      " - 25s - loss: 0.0692 - accuracy: 0.9772\n",
      "Epoch 928/1000\n",
      " - 25s - loss: 0.1138 - accuracy: 0.9632\n",
      "Epoch 929/1000\n",
      " - 25s - loss: 0.0450 - accuracy: 0.9870\n",
      "Epoch 930/1000\n",
      " - 25s - loss: 0.0716 - accuracy: 0.9773\n",
      "Epoch 931/1000\n",
      " - 25s - loss: 0.0919 - accuracy: 0.9701\n",
      "Epoch 932/1000\n",
      " - 25s - loss: 0.0730 - accuracy: 0.9770\n",
      "Epoch 933/1000\n",
      " - 25s - loss: 0.0789 - accuracy: 0.9751\n",
      "Epoch 934/1000\n",
      " - 25s - loss: 0.0845 - accuracy: 0.9726\n",
      "Epoch 935/1000\n",
      " - 25s - loss: 0.0626 - accuracy: 0.9800\n",
      "Epoch 936/1000\n",
      " - 25s - loss: 0.0534 - accuracy: 0.9832\n",
      "Epoch 937/1000\n",
      " - 25s - loss: 0.0855 - accuracy: 0.9722\n",
      "Epoch 938/1000\n",
      " - 25s - loss: 0.1131 - accuracy: 0.9625\n",
      "Epoch 939/1000\n",
      " - 25s - loss: 0.1364 - accuracy: 0.9564\n",
      "Epoch 940/1000\n",
      " - 25s - loss: 0.0340 - accuracy: 0.9912\n",
      "Epoch 941/1000\n",
      " - 25s - loss: 0.0204 - accuracy: 0.9959\n",
      "Epoch 942/1000\n",
      " - 25s - loss: 0.1093 - accuracy: 0.9644\n",
      "Epoch 943/1000\n",
      " - 25s - loss: 0.1194 - accuracy: 0.9604\n",
      "Epoch 944/1000\n",
      " - 25s - loss: 0.0840 - accuracy: 0.9734\n",
      "Epoch 945/1000\n",
      " - 25s - loss: 0.0509 - accuracy: 0.9842\n",
      "Epoch 946/1000\n",
      " - 25s - loss: 0.0503 - accuracy: 0.9855\n",
      "Epoch 947/1000\n",
      " - 25s - loss: 0.0987 - accuracy: 0.9670\n",
      "Epoch 948/1000\n",
      " - 25s - loss: 0.0893 - accuracy: 0.9705\n",
      "Epoch 949/1000\n",
      " - 25s - loss: 0.0673 - accuracy: 0.9791\n",
      "Epoch 950/1000\n",
      " - 25s - loss: 0.0695 - accuracy: 0.9777\n",
      "Epoch 951/1000\n",
      " - 25s - loss: 0.0837 - accuracy: 0.9739\n",
      "Epoch 952/1000\n",
      " - 25s - loss: 0.0823 - accuracy: 0.9738\n",
      "Epoch 953/1000\n",
      " - 25s - loss: 0.0789 - accuracy: 0.9747\n",
      "Epoch 954/1000\n",
      " - 25s - loss: 0.0631 - accuracy: 0.9804\n",
      "Epoch 955/1000\n",
      " - 24s - loss: 0.0727 - accuracy: 0.9763\n",
      "Epoch 956/1000\n",
      " - 25s - loss: 0.0686 - accuracy: 0.9773\n",
      "Epoch 957/1000\n",
      " - 25s - loss: 0.0873 - accuracy: 0.9709\n",
      "Epoch 958/1000\n",
      " - 25s - loss: 0.0855 - accuracy: 0.9718\n",
      "Epoch 959/1000\n",
      " - 25s - loss: 0.0537 - accuracy: 0.9834\n",
      "Epoch 960/1000\n",
      " - 25s - loss: 0.0628 - accuracy: 0.9800\n",
      "Epoch 961/1000\n",
      " - 25s - loss: 0.0913 - accuracy: 0.9694\n",
      "Epoch 962/1000\n",
      " - 25s - loss: 0.1138 - accuracy: 0.9624\n",
      "Epoch 963/1000\n",
      " - 25s - loss: 0.0513 - accuracy: 0.9849\n",
      "Epoch 964/1000\n",
      " - 25s - loss: 0.0445 - accuracy: 0.9876\n",
      "Epoch 965/1000\n",
      " - 25s - loss: 0.0882 - accuracy: 0.9718\n",
      "Epoch 966/1000\n",
      " - 25s - loss: 0.0869 - accuracy: 0.9717\n",
      "Epoch 967/1000\n",
      " - 25s - loss: 0.0606 - accuracy: 0.9814\n",
      "Epoch 968/1000\n",
      " - 24s - loss: 0.0639 - accuracy: 0.9803\n",
      "Epoch 969/1000\n",
      " - 25s - loss: 0.0847 - accuracy: 0.9731\n",
      "Epoch 970/1000\n",
      " - 25s - loss: 0.0844 - accuracy: 0.9720\n",
      "Epoch 971/1000\n",
      " - 25s - loss: 0.0719 - accuracy: 0.9764\n",
      "Epoch 972/1000\n",
      " - 25s - loss: 0.0532 - accuracy: 0.9839\n",
      "Epoch 973/1000\n",
      " - 25s - loss: 0.0741 - accuracy: 0.9755\n",
      "Epoch 974/1000\n",
      " - 25s - loss: 0.1005 - accuracy: 0.9662\n",
      "Epoch 975/1000\n",
      " - 25s - loss: 0.0787 - accuracy: 0.9743\n",
      "Epoch 976/1000\n",
      " - 25s - loss: 0.0602 - accuracy: 0.9810\n",
      "Epoch 977/1000\n",
      " - 25s - loss: 0.0688 - accuracy: 0.9786\n",
      "Epoch 978/1000\n",
      " - 25s - loss: 0.0799 - accuracy: 0.9742\n",
      "Epoch 979/1000\n",
      " - 25s - loss: 0.0558 - accuracy: 0.9820\n",
      "Epoch 980/1000\n",
      " - 25s - loss: 0.0817 - accuracy: 0.9725\n",
      "Epoch 981/1000\n",
      " - 25s - loss: 0.0808 - accuracy: 0.9737\n",
      "Epoch 982/1000\n",
      " - 25s - loss: 0.0674 - accuracy: 0.9776\n",
      "Epoch 983/1000\n",
      " - 27s - loss: 0.0717 - accuracy: 0.9772\n",
      "Epoch 984/1000\n",
      " - 25s - loss: 0.0692 - accuracy: 0.9785\n",
      "Epoch 985/1000\n",
      " - 25s - loss: 0.0729 - accuracy: 0.9764\n",
      "Epoch 986/1000\n",
      " - 25s - loss: 0.0731 - accuracy: 0.9763\n",
      "Epoch 987/1000\n",
      " - 25s - loss: 0.0986 - accuracy: 0.9685\n",
      "Epoch 988/1000\n",
      " - 25s - loss: 0.0497 - accuracy: 0.9847\n",
      "Epoch 989/1000\n",
      " - 25s - loss: 0.1444 - accuracy: 0.9539\n",
      "Epoch 990/1000\n",
      " - 25s - loss: 0.0454 - accuracy: 0.9862\n",
      "Epoch 991/1000\n",
      " - 25s - loss: 0.0305 - accuracy: 0.9925\n",
      "Epoch 992/1000\n",
      " - 25s - loss: 0.0768 - accuracy: 0.9758\n",
      "Epoch 993/1000\n",
      " - 25s - loss: 0.1310 - accuracy: 0.9581\n",
      "Epoch 994/1000\n",
      " - 25s - loss: 0.0763 - accuracy: 0.9757\n",
      "Epoch 995/1000\n",
      " - 25s - loss: 0.0512 - accuracy: 0.9846\n",
      "Epoch 996/1000\n",
      " - 25s - loss: 0.0597 - accuracy: 0.9812\n",
      "Epoch 997/1000\n",
      " - 25s - loss: 0.1002 - accuracy: 0.9666\n",
      "Epoch 998/1000\n",
      " - 25s - loss: 0.0684 - accuracy: 0.9778\n",
      "Epoch 999/1000\n",
      " - 24s - loss: 0.0607 - accuracy: 0.9815\n",
      "Epoch 1000/1000\n",
      " - 25s - loss: 0.0608 - accuracy: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x638aa23d0>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model_1000 = Sequential()\n",
    "model_1000.add(LSTM(125, input_shape=(x.shape[1], x.shape[2])))\n",
    "model_1000.add(Dense(len(chars), activation='softmax'))\n",
    "model_1000.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_1000.fit(x, y, batch_size=32, epochs=1000, verbose=2, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- temperature: 0.25\n",
      "----- Generating with seed: \"weet flattery then she loves but me alon\"\n",
      "\n",
      "weet flattery then she loves but me alon\n",
      "e whencome passy hamb hath which should \n",
      "doth doth fingt the forthard toon thy se\n",
      "lf amlover and stateore the fauls if tho\n",
      "u tobl stormenthy but timns bears see no\n",
      "th when thou fearst mate night me and si\n",
      "ngs well fauris in his tilefil him grace\n",
      "but not to heattnor all the worrs fortha\n",
      "t this i crull love cans this barrer thr\n",
      "is despition or thy self amownrs dother \n",
      "well me unorners you ale me worthan will\n",
      " is do ineror canst mow ox love than as \n",
      "are not love assealss and so surthise th\n",
      "ou form wo shers you not in love bearsy \n",
      "\n",
      " ----- temperature: 0.75\n",
      "----- Generating with seed: \"weet flattery then she loves but me alon\"\n",
      "\n",
      "weet flattery then she loves but me alon\n",
      "e whencorce bedow of their recofebeiteol\n",
      " chend he sing of soms age withbor un on\n",
      "e all you preed the bay than in lesse ga\n",
      "zed af a my loods is old our all from hi\n",
      "m ofrsing so sweety new in some in their\n",
      " rebeotbeder what the humsthan in then b\n",
      "ulle crosklike well broun loves fairnand\n",
      " part of my praiseand worss eccainging t\n",
      "hy fair to plessed so beared with shill \n",
      "thee yet lines of like on my crilled wit\n",
      "hinat eye so loves encused to wilth moca\n",
      "bue hankealsh he will no for that makes \n",
      "fiegtite fol jumbs being his love referb\n",
      "\n",
      " ----- temperature: 1.5\n",
      "----- Generating with seed: \"weet flattery then she loves but me alon\"\n",
      "\n",
      "weet flattery then she loves but me alon\n",
      "e what werist long stareand worth for fi\n",
      "rs moti being him lights me sinks fild t\n",
      "hee being tongues to pet there war is bo\n",
      "th punty of thy deeps canted kelp i reco\n",
      "uld of blacted me sinks hel that withand\n",
      " wherein that wintwhereforbefore that i \n",
      "way creathand it kingall then my vexcasc\n",
      "rames frol her pepireess shayst with my \n",
      "again and how can and gracebe breat migh\n",
      "t deeplest the beautys diechish i sounce\n",
      " it their fremmistince earmenthou dost t\n",
      "hy self of eyes to shell broun ont he wo\n",
      "rld for as of may seekpert be barr the h\n"
     ]
    }
   ],
   "source": [
    "gen_sonnet_(model_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- temperature: 0.25\n",
      "----- Generating with seed: \" and me he pays the whole and yet am i n\"\n",
      "\n",
      " and me he pays the whole and yet am i n\n",
      "o way arrand dase thy self amlover all t\n",
      "henflless still thy fatees the streagain\n",
      "sand placewithe did fors on mares are fo\n",
      "r that makes full and yet i anoth weseat\n",
      " that wintyor my sun your fass indand vi\n",
      "ll and my ear alt thou alone and all the\n",
      "y to than thou dost but me and this boot\n",
      " respectwhich be unfiedoff times be fols\n",
      " moth donce sach to stell did griest on \n",
      "so sorvey fauldand play thee and sell wo\n",
      "rth i soul live and sook that my sweet b\n",
      "ring losis kidd and therefore thou mise \n",
      "by his side and so true my crush and the\n",
      "\n",
      " ----- temperature: 0.75\n",
      "----- Generating with seed: \" and me he pays the whole and yet am i n\"\n",
      "\n",
      " and me he pays the whole and yet am i n\n",
      "o warthing lack keach worbd of you mayst\n",
      " and eresh of the resefarcoon comined no\n",
      "t thou art the mand stresting to me then\n",
      " grouses ede no say of more race should \n",
      "do more dithat the form weseand untiteil\n",
      " of thine and not the soul of some with \n",
      "me and selfaie this foldes fle ni have i\n",
      "n thing my verse autiof beauty lome that\n",
      " my not of my in the cenceill of my his \n",
      "with sife in own fillootherefore thou al\n",
      "th me as the wrreas in my mind proofide \n",
      "han and from thee in contence may me dee\n",
      "ing sweet share thou anter then times ha\n",
      "\n",
      " ----- temperature: 1.5\n",
      "----- Generating with seed: \" and me he pays the whole and yet am i n\"\n",
      "\n",
      " and me he pays the whole and yet am i n\n",
      "o laystand dist fors nonge that makes wi\n",
      "tk our all you proof they not to love th\n",
      "ou altorbeh not love where both world di\n",
      "shing a well well i ant complessed with \n",
      "lookertequity gains of life an ass thine\n",
      " me nor abawerbeauty shame to matter and\n",
      " steals thy loves in the darrer absest c\n",
      "omposed do tate his grace weth invers no\n",
      "t to shall stunsall bress and then thee \n",
      "so bre dor corsting at bare now hald i m\n",
      "ornal race they moures happy lot out fut\n",
      "h your soms and being contledto pass tho\n",
      "u better feef reseabdive me abubni deed \n"
     ]
    }
   ],
   "source": [
    "gen_sonnet_(model_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sonnet_(model):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for temperature in [0.25, 0.75, 1.5]:\n",
    "        print('\\n ----- temperature:', temperature)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"\\n')\n",
    "\n",
    "        entire_seq = generated\n",
    "        for i in range(520):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "          \n",
    "            entire_seq = entire_seq + next_char\n",
    "        \n",
    "        \n",
    "        for ind, char in enumerate(entire_seq):\n",
    "            if ind%40==0:\n",
    "                print(entire_seq[ind:ind+40])\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- temperature: 0.25\n",
      "----- Generating with seed: \"ll give thee memorythou by thy dials sha\"\n",
      "\n",
      "ll give thee memorythou by thy dials sha\n",
      "dthup inkryeprtot whole dants with shefr\n",
      "e mise ake should ifethendss thine ary s\n",
      "heethou doth this fire thou wainut hewon\n",
      "d thinost whet trall fubct noowon suelye\n",
      "d for tha ghouland not this pyounds whit\n",
      "bgencecryoun though but by thing ingrise\n",
      "sthy fay age this boring by shuli lowh c\n",
      "anturren my mare shay thou theee and far\n",
      "tellone egeny whinedut shomlst in love h\n",
      "and you he wool to peaniestind thy cante\n",
      "ance for tise enfendso poindseefile make\n",
      " prideshes with thou porale wo chond thy\n",
      " comare or peetendtyald dispestreno faie\n",
      "\n",
      " ----- temperature: 0.75\n",
      "----- Generating with seed: \"ll give thee memorythou by thy dials sha\"\n",
      "\n",
      "ll give thee memorythou by thy dials sha\n",
      "rlle thing home norceard thee a disbired\n",
      " in seidane no eyare of deefts life at e\n",
      "vembrefinder of this sawnos bith ho shaj\n",
      "gity loef and love your and the will no \n",
      "sunoth nei hewith oe chay from didear te\n",
      "sclethil fourdand pinoteres eveive shang\n",
      "ht the make shime thy sweet no ghose pro\n",
      "ofseet stien thinkind whend whote inod s\n",
      "hintar in thee booned difebyfreit love t\n",
      "houptries nop conhems eacufer dealdhs ma\n",
      "ge as raiven diferrough vietway that hea\n",
      "sth to what yout info derite thye purse \n",
      "chime ow thimsi whand exrend of live tho\n",
      "\n",
      " ----- temperature: 1.5\n",
      "----- Generating with seed: \"ll give thee memorythou by thy dials sha\"\n",
      "\n",
      "ll give thee memorythou by thy dials sha\n",
      "ps wish mineer noth were hen vere thow i\n",
      "s voornd of frought how my me betreredit\n",
      "twhoult muss priques chibe thee thus now\n",
      " ours wistach anjoreds of love an ore si\n",
      "ghtsh wiln i love no encandnow breest ac\n",
      "e couving brating proased love whoth chu\n",
      "se verven i mond mokeace as illeth surms\n",
      "byot trees no verrer dawhid ant thy sers\n",
      " antersad to haves live diss fort soss o\n",
      "r my seadthe ney shouls pointyous if thi\n",
      "s tinl biliss to my froinces it illly of\n",
      " the moue thoushsein then doth sowears s\n",
      "tall as my leves to ar abust froveant he\n"
     ]
    }
   ],
   "source": [
    "gen_sonnet_(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_sonnet_seed_ind(model, start_ind, end_ind):\n",
    "#     # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "\n",
    "# #     start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "#     for temperature in [0.25, 0.75, 1.5]:\n",
    "#         print('\\n ----- temperature:', temperature)\n",
    "\n",
    "#         generated = ''\n",
    "#         sentence = text[start_ind: end_ind]\n",
    "#         generated += sentence\n",
    "#         print('----- Generating with seed: \"' + sentence + '\"\\n')\n",
    "\n",
    "#         entire_seq = generated\n",
    "#         for i in range(520):\n",
    "#             x_pred = np.zeros((1, len(generated), len(chars)))\n",
    "#             for t, char in enumerate(sentence):\n",
    "#                 x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "#             preds = model.predict(x_pred, verbose=0)[0]\n",
    "#             next_index = sample(preds, temperature)\n",
    "#             next_char = indices_char[next_index]\n",
    "\n",
    "#             sentence = sentence[1:] + next_char\n",
    "          \n",
    "#             entire_seq = entire_seq + next_char\n",
    "        \n",
    "        \n",
    "#         for ind, char in enumerate(entire_seq):\n",
    "#             if ind%40==0:\n",
    "#                 print(entire_seq[ind:ind+40])\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sonnet_seed(model, seed):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "\n",
    "#     start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for temperature in [0.25, 0.75, 1.5]:\n",
    "        print('\\n ----- temperature:', temperature)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = seed\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"\\n')\n",
    "\n",
    "        entire_seq = generated\n",
    "        for i in range(520):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "          \n",
    "            entire_seq = entire_seq + next_char\n",
    "        \n",
    "        \n",
    "        for ind, char in enumerate(entire_seq):\n",
    "            if ind%40==0:\n",
    "                print(entire_seq[ind:ind+40])\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_seed = \"  shall i compare thee to a summers day \"\n",
    "len(char_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- temperature: 0.25\n",
      "----- Generating with seed: \"  shall i compare thee to a summers day \"\n",
      "\n",
      "  shall i compare thee to a summers day \n",
      "heave eresh of for thy self a fore as al\n",
      "l yet well or deedmored whom all dessedm\n",
      "y can berot i have hen ereshill to she t\n",
      "ruth to crearand my priget doth sabean t\n",
      "hat a feers for as tyer perfects to sere\n",
      " fair redie which thrisered brounpessech\n",
      " my plaise and if no my names succeds wo\n",
      "rsbe to carthand trou placks or some so \n",
      "be some and then mourds hoact reseal his\n",
      " graise hear bring can cansebethe conse \n",
      "let yet i to nor whence whose hath usent\n",
      " the eterneftrof ear kingand well i chou\n",
      "ld i anothereffreities huppy if the penc\n",
      "\n",
      " ----- temperature: 0.75\n",
      "----- Generating with seed: \"  shall i compare thee to a summers day \"\n",
      "\n",
      "  shall i compare thee to a summers day \n",
      "of how to sich fase inuty nowwern when t\n",
      "hou astindsto so nor or as onerminedand \n",
      "then my beauty grow latery up not enchor\n",
      "e thrises frieht he ay true more pride i\n",
      "n my bring hand should dee not love that\n",
      " to mountle know can and good fiedd were\n",
      " for that waiter thou nightsomy sweet br\n",
      "oupp and terrage finthet his grace weth \n",
      "in your mearts in should be tome all tho\n",
      "u art say my reseflethat i tannat frower\n",
      "nowithing hulds the world strangeth upou\n",
      "rmane may ste life age ran thy maysce mo\n",
      "re desian was is daysthat the bedo your \n",
      "\n",
      " ----- temperature: 1.5\n",
      "----- Generating with seed: \"  shall i compare thee to a summers day \"\n",
      "\n",
      "  shall i compare thee to a summers day \n",
      "heave eresh o clear dave rigtle doth wro\n",
      "th histelong hath mays mightand me in th\n",
      "eer aprueshout when i sansill thy brcord\n",
      " of thee histell recounty tombaids and c\n",
      "orstained good fite thee thy love and th\n",
      "en my bring losing like thin as ince sha\n",
      "me be ramm thou pacestrainterf to with t\n",
      "rue im sooprand eye nothane mine my scue\n",
      " in hath my age wise more she to liveity\n",
      " to thy self amliveh in the receaven ere\n",
      "what have no fair of him id own kightdet\n",
      "hougat the selemitingthoughts so sporaut\n",
      "boon or thy self and argeasthe eyes fore\n"
     ]
    }
   ],
   "source": [
    "gen_sonnet_seed(model_1000, char_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
