{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.callbacks import LambdaCallback\n",
    "import sys\n",
    "import random\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in text, lower case\n",
    "text_full = open(os.path.join(os.getcwd(), 'data/shakespeare.txt')).read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove numbers\n",
    "text_no_num = ''.join([i for i in text_full if not i.isdigit()])\n",
    "# remove new lines\n",
    "text_no_nline = text_no_num.replace(\"\\n\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation and tabs\n",
    "\n",
    "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "no_punct = \"\"\n",
    "for char in text_no_nline:\n",
    "    if char not in punctuations:\n",
    "        no_punct = no_punct + char\n",
    "\n",
    "text = re.sub(' +', ' ', no_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 27\n"
     ]
    }
   ],
   "source": [
    "# from https://keras.io/examples/lstm_text_generation/\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 29602\n"
     ]
    }
   ],
   "source": [
    "# from https://keras.io/examples/lstm_text_generation/\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### turn to one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://keras.io/examples/lstm_text_generation/\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 125)               76500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 27)                3402      \n",
      "=================================================================\n",
      "Total params: 79,902\n",
      "Trainable params: 79,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(125, input_shape=(x.shape[1], x.shape[2])))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from https://keras.io/examples/lstm_text_generation/\n",
    "\n",
    "# def sample(preds, temperature=1.0):\n",
    "#     # helper function to sample an index from a probability array\n",
    "    \n",
    "#     preds = np.asarray(preds).astype('float64')\n",
    "#     # take log of predictions and scale by temperature (why take log?)\n",
    "#     preds = np.exp(np.log(preds) / temperature)\n",
    "#     # scale back to 1 \n",
    "#     preds = preds / np.sum(preds)\n",
    "#     # sample a distribution, return an array with 1 at choice\n",
    "#     probas = np.random.multinomial(1, preds, 1)\n",
    "#     # return argument (index) that produced choice\n",
    "#     return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from https://keras.io/examples/lstm_text_generation/\n",
    "# # change to prevent log(0)\n",
    "\n",
    "# def sample(preds, temperature=1.0):\n",
    "#     # helper function to sample an index from a probability array\n",
    "    \n",
    "#     preds = np.asarray(preds).astype('float64')\n",
    "    \n",
    "#     if any(preds==0) or any(np.log(preds) < -15):\n",
    "# #         preds[np.where(preds==0)[0][0]] = np.nan\n",
    "#         preds[np.where(np.log(preds) < -15)[0][0]] = np.nan\n",
    "              \n",
    "#     else:\n",
    "#         pass\n",
    "        \n",
    "#     # take log of predictions and scale by temperature (why take log?)\n",
    "#     preds = np.exp(np.log(preds) / temperature)\n",
    "#     # scale back to 1 \n",
    "#     preds = preds / np.nansum(preds)\n",
    "    \n",
    "    \n",
    "#     # convert nans back to 0\n",
    "#     if any(np.isnan(preds)):\n",
    "#         preds[np.where(np.isnan(preds))[0][0]] = 0.\n",
    "#     else:\n",
    "#         pass\n",
    "    \n",
    "#     # sample a distribution, return an array with 1 at choice\n",
    "#     probas = np.random.multinomial(1, preds, 1)\n",
    "#     # return argument (index) that produced choice\n",
    "#     return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from https://keras.io/examples/lstm_text_generation/\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    \n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    # scale by temp\n",
    "    preds = preds / temperature\n",
    "\n",
    "    # rescale to 1\n",
    "    preds = preds/ np.sum(preds)\n",
    "    # sample a distribution, return an array with 1 at choice\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    # return argument (index) that produced choice\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 28s - loss: 2.5475 - accuracy: 0.2645\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"saucy bark inferior far to hison your br\"\n",
      "saucy bark inferior far to hison your brvciss aps aptstty than haml twes aaig wout akit ot wist fhesuaceetilidaad thiu favingis tftus amd men art amd thild croty ceapasin hit wish to te may tltem mriin ti the ave byt dinghald aims hestive wesoeskrt aotthetuthoui oar fyceansy sas ile ser  lhacilswobjthule thaveengured waind hirlouts areth ny makt till iatthouko delc npaelend lo ty tou ceeit waru hot  hesanytt mt the maslssfor fhe py myua\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"saucy bark inferior far to hison your br\"\n",
      "saucy bark inferior far to hison your brafdssd elled thy sethoubrt sf are yis rginsue te mesemtr ce bom thhtcprulgith sy ans yirh stur dwine ooungi v ens meis mheseurhasis thile scodutit bouad ntlos inf ond with ring yhephy thigt cave t thetsenthoushoais n iil mewe meith ons valtwed hing lonssutmr vethithos ahe tou pstich cienbler prevesto id sim llaveol ialtiil t re fiov t arose fise sesmmwucefote thswh lass ghelpot be s brmeras frare \n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"saucy bark inferior far to hison your br\"\n",
      "saucy bark inferior far to hison your bre iognte sati heane sillass pon rive enthediutiam mutheme cet soc ure s isssdass patt siwhe ine shjsedis tie lto gallsurwesge thohee coatt thecs sin dor thou ghats ymerrif erastf arletir bol de mis thingeenth mes mind foruthint at oasest ire io giathansr loe le thett ivemosmiy s tytestt xon weagheadeeeito shins thamn fisdinge fhs wedei wy chat thes teek che thunnet shve cot pamed afttalkey rit ain\n",
      "Epoch 2/10\n",
      " - 28s - loss: 2.2034 - accuracy: 0.3486\n",
      "Epoch 3/10\n",
      " - 28s - loss: 2.0840 - accuracy: 0.3787\n",
      "Epoch 4/10\n",
      " - 27s - loss: 1.9965 - accuracy: 0.4027\n",
      "Epoch 5/10\n",
      " - 29s - loss: 1.9253 - accuracy: 0.4236\n",
      "Epoch 6/10\n",
      " - 30s - loss: 1.8623 - accuracy: 0.4400\n",
      "Epoch 7/10\n",
      " - 30s - loss: 1.8094 - accuracy: 0.4540\n",
      "Epoch 8/10\n",
      " - 26s - loss: 1.7597 - accuracy: 0.4660\n",
      "Epoch 9/10\n",
      " - 26s - loss: 1.7126 - accuracy: 0.4796\n",
      "Epoch 10/10\n",
      " - 25s - loss: 1.6682 - accuracy: 0.4874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x637c99c10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=32, epochs=10, verbose=2, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"em yet so they mourn becoming of their w\"\n",
      "em yet so they mourn becoming of their with ear borngadd seef thet shill to urcele my doed thinfwhere in the fariress deefitper asupceoring shill of reevireand thees preivefto that ceiqunes butrs to hew thut shillh love whon and the eyes thine my seine thy nour fools of this saifors his and what whicth maise my groce no ded roting forsed in thy besmy forcemour guines whore no houly ang heftone and thou mayils make love lise arigut heave----- temperature: 0.75\n",
      "----- Generating with seed: \"em yet so they mourn becoming of their w\"\n",
      "em yet so they mourn becoming of their willand the braye therethile love an besundbethatkit all ald thot thou thougabst furse no can thou shaule deof chose this everys welo hisone meaneed wheir and mreathoot as the busts tery stor vargrouby thee my all this bricks wonts mise hight i theets thiewhin the faor dithet foo this my loves if the fordfaresedizeand do thines mey i moud i digh ore prowest so proveing bus sheps in lave as it prigb----- temperature: 1.5\n",
      "----- Generating with seed: \"em yet so they mourn becoming of their w\"\n",
      "em yet so they mourn becoming of their wakl bedowhings the purtthought arn uppetwhen patereant that bore love can their theyrs dachs doak but do merthandid which hainthosisweit fartrif that whis which firved on loved exes me wond boweon tismir or thine hore thy lood eakthy needhe for should blaces of thith heartt formedoudess bit to sueswond bitwhou of fale thou wheedto pensing ho cavein forthoogh that forment is come thou never kexsing"
     ]
    }
   ],
   "source": [
    "gen_sonnet_(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://keras.io/examples/lstm_text_generation/\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "    # print only 10th epoch\n",
    "    if epoch%100==0:\n",
    "        print()\n",
    "        print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "        for temperature in [0.25, 0.75, 1.5]:\n",
    "            print('----- temperature:', temperature)\n",
    "\n",
    "            generated = ''\n",
    "            sentence = text[start_index: start_index + maxlen]\n",
    "            generated += sentence\n",
    "            print('----- Generating with seed: \"' + sentence + '\"')\n",
    "            sys.stdout.write(generated)\n",
    "\n",
    "            for i in range(400):\n",
    "                x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                preds = model.predict(x_pred, verbose=0)[0]\n",
    "                next_index = sample(preds, temperature)\n",
    "                next_char = indices_char[next_index]\n",
    "\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "            print()\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 27s - loss: 0.8847 - accuracy: 0.7301\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"son music to hear why hearst thou music \"\n",
      "son music to hear why hearst thou music and thee the world mouth re painted how a fomen forthing and so so thou the world i to keed for thy sunfeathert me dis caired thee beauty one womblong of my sweet were it not than my self a long have preasor of the fairt a a send the beauty on your self and thee thee belies summers with lost and contould me doth long hast where it not thou art i am not love and this paress by yet are gondless by t\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"son music to hear why hearst thou music \"\n",
      "son music to hear why hearst thou music comed be endand the forghts on the ramethou akn that mull for all meame doth londs crouch pottricet it st oll whor be endle butl you tremes wore thoughtshenger muli shall the self for this pleing math not to be st leave whose be night dils peril add at thy giedt corfind yet the world at sexplese yet to mine eyes that thou art for thee mone not part brom sill see the still thing and blacks pittare \n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"son music to hear why hearst thou music \"\n",
      "son music to hear why hearst thou music dowers eyeth poot he paitured onwtrusting dile dodill you ble semare make as eyethenrpeeos mand othere fair fouthstrounge diefglith what to gpordand nair eys tonguetuin san and my sugains eyestore thay me sughto frop from homp nos sween ofn sarkly behavencpetivntyephtysuthout fortann with all my mreed in thinears now his sape it cadracyed a veaveoved of now are skill fimrestne eppaisemaved sanmest\n",
      "Epoch 2/100\n",
      " - 25s - loss: 0.8441 - accuracy: 0.7430\n",
      "Epoch 3/100\n",
      " - 25s - loss: 0.8185 - accuracy: 0.7534\n",
      "Epoch 4/100\n",
      " - 25s - loss: 0.7900 - accuracy: 0.7604\n",
      "Epoch 5/100\n",
      " - 25s - loss: 0.7631 - accuracy: 0.7684\n",
      "Epoch 6/100\n",
      " - 25s - loss: 0.7365 - accuracy: 0.7779\n",
      "Epoch 7/100\n",
      " - 25s - loss: 0.7105 - accuracy: 0.7872\n",
      "Epoch 8/100\n",
      " - 25s - loss: 0.6941 - accuracy: 0.7909\n",
      "Epoch 9/100\n",
      " - 25s - loss: 0.6682 - accuracy: 0.7982\n",
      "Epoch 10/100\n",
      " - 27s - loss: 0.6482 - accuracy: 0.8049\n",
      "Epoch 11/100\n",
      " - 25s - loss: 0.6317 - accuracy: 0.8084\n",
      "\n",
      "----- Generating text after Epoch: 10\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"eem so some glory in their birth some in\"\n",
      "eem so some glory in their birth some in every but speater and see such raseth ootraking away i have spripe stralges more her i cankst loves th some bright thou then when their shall which phoudd of shade part i to be of meaut thou art it see me dott me a faired and were forghthe beauty mistins ere yethe mude chould not the sine so more and their shairss me beautys not thy loves and where it no this that with thee beautys for where it n\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"eem so some glory in their birth some in\"\n",
      "eem so some glory in their birth some in every barge brow pares of me was deeyed with mastery being criveand your for fare in the furleweth longs and their should deefows waile comitation ot some that with derewrant with her loveang of thy fair and then not blow shoulds ablir well in then your see for as will be ard but dith fors for agained think eyes fore from ablind ends quion in do no there arthe butl giod and their thee muentied so\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"eem so some glory in their birth some in\"\n",
      "eem so some glory in their birth some in love t me but swentyes boliss his gruenobhwazer nowarch of nithin lounts upesines glosw is blood unfover tombred againge that i quise thou art boob shild dore doth his ade flom are mento matile that thou pomin tas thruebhedd me san sembed shall dasmed endoes evew love owt wridn ar a beauty of thoughts umpanqsowife oth self arpleach of athen ahgueesnue as eyes versefcrowthis ploadss dithine berisu\n",
      "Epoch 12/100\n",
      " - 28s - loss: 0.6160 - accuracy: 0.8134\n",
      "Epoch 13/100\n",
      " - 35s - loss: 0.6183 - accuracy: 0.8114\n",
      "Epoch 14/100\n",
      " - 29s - loss: 0.5855 - accuracy: 0.8217\n",
      "Epoch 15/100\n",
      " - 27s - loss: 0.5617 - accuracy: 0.8319\n",
      "Epoch 16/100\n",
      " - 38s - loss: 0.5999 - accuracy: 0.8138\n",
      "Epoch 17/100\n",
      " - 32s - loss: 0.5291 - accuracy: 0.8417\n",
      "Epoch 18/100\n",
      " - 31s - loss: 0.5304 - accuracy: 0.8397\n",
      "Epoch 19/100\n",
      " - 25s - loss: 0.5250 - accuracy: 0.8424\n",
      "Epoch 20/100\n",
      " - 25s - loss: 0.5168 - accuracy: 0.8416\n",
      "Epoch 21/100\n",
      " - 27s - loss: 0.5203 - accuracy: 0.8430\n",
      "\n",
      "----- Generating text after Epoch: 20\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \" well which thou must leave ere long but\"\n",
      " well which thou must leave ere long but dildrace be cained mutthin thy blesst mully refombly forn havet no breaser with loty hate muss comen than gove in war all me groroty hath on thy sweet asmice with time ford forbeartif thee thee me doth lost histhauth my sungentardes that mine eye comboring his sweet meast wincroms shorn that painst aulthe bester laving agare what ame browst thy sweet remowncase doth master me truth frounse best i\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \" well which thou must leave ere long but\"\n",
      " well which thou must leave ere long but showst loves me dooknwhen i radt be not brew thee beamion then my me my stwir thy mull still with my deeing your sonfand your full me deart for my stion that thou foob you dat riseto canna marbear with thee beauty with supprissiou alatt and refortund forth in heaven to most meant rome so dellestf comot with time for forbes berfugh did growso dights my staynothauth how is thineats and heavaths sha\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \" well which thou must leave ere long but\"\n",
      " well which thou must leave ere long but distclestim be the bebutet deadthe veist not toustneye dissine lowe wonbriming didie chougace he alebliong fait now conean boten boon that his vurked notquention hist what hours ever when toobe on bentsa them boode hati in my eyest rudwstme since basts nor treesell lake that should dath molity lapk now treespentleswhen looks have leaknanch living hou which excrersel by my jreghine fraws proud as \n",
      "Epoch 22/100\n",
      " - 26s - loss: 0.4934 - accuracy: 0.8512\n",
      "Epoch 23/100\n",
      " - 25s - loss: 0.4920 - accuracy: 0.8515\n",
      "Epoch 24/100\n",
      " - 25s - loss: 0.4869 - accuracy: 0.8524\n",
      "Epoch 25/100\n",
      " - 25s - loss: 0.4702 - accuracy: 0.8574\n",
      "Epoch 26/100\n",
      " - 26s - loss: 0.4527 - accuracy: 0.8624\n",
      "Epoch 27/100\n",
      " - 25s - loss: 0.4448 - accuracy: 0.8653\n",
      "Epoch 28/100\n",
      " - 25s - loss: 0.4351 - accuracy: 0.8670\n",
      "Epoch 29/100\n",
      " - 26s - loss: 0.4440 - accuracy: 0.8639\n",
      "Epoch 30/100\n",
      " - 25s - loss: 0.4396 - accuracy: 0.8630\n",
      "Epoch 31/100\n",
      " - 25s - loss: 0.4296 - accuracy: 0.8705\n",
      "\n",
      "----- Generating text after Epoch: 30\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"waydeaths second self that seals up all \"\n",
      "waydeaths second self that seals up all more behemion is me dis came so born the lose poor dead not so all more yee to grestwere me i jownce that but farr to be a faired and strengt my beauty lives did my heartand plack and this chenks creasory when my sout fram felselfor cany in it selfous penil as i hatt his heavence make merso then my love what so then vingand dut i ant more are may then die the best as buring thy sunk when my sout f\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"waydeaths second self that seals up all \"\n",
      "waydeaths second self that seals up all me pryist as thou love and their shall whose be endencest wook not thou dost be doth provour do lov thee is not so murur ene formed to may eyes me brew there of my sade delive selfor can be muds to the by ended of not i am notrang aweals for my love as and ent becomebuting othing here or my his wearth long lacks which hell my rusten sommot i to file with uring of ruceand have plain and shord do wo\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"waydeaths second self that seals up all \"\n",
      "waydeaths second self that seals up all tomplading ownermoretyes huse show can leppaceand hourse the bestme whorccuees not love what houdd word dassa then hourss die is huspand murele bad my veate my charty is fuer yet mestormey blest or thy healt for my love haws i love flech proodant worsst cheat it as beht keol desefor will be fide is seep to reasomons ever leidur ing my merin for my stowet kengflewor can three and the bestwere not s\n",
      "Epoch 32/100\n",
      " - 25s - loss: 0.4209 - accuracy: 0.8708\n",
      "Epoch 33/100\n",
      " - 26s - loss: 0.4036 - accuracy: 0.8779\n",
      "Epoch 34/100\n",
      " - 25s - loss: 0.3969 - accuracy: 0.8801\n",
      "Epoch 35/100\n",
      " - 25s - loss: 0.3913 - accuracy: 0.8817\n",
      "Epoch 36/100\n",
      " - 24s - loss: 0.4017 - accuracy: 0.8750\n",
      "Epoch 37/100\n",
      " - 26s - loss: 0.3836 - accuracy: 0.8830\n",
      "Epoch 38/100\n",
      " - 26s - loss: 0.3873 - accuracy: 0.8802\n",
      "Epoch 39/100\n",
      " - 25s - loss: 0.3740 - accuracy: 0.8847\n",
      "Epoch 40/100\n",
      " - 25s - loss: 0.3771 - accuracy: 0.8836\n",
      "Epoch 41/100\n",
      " - 26s - loss: 0.3620 - accuracy: 0.8875\n",
      "\n",
      "----- Generating text after Epoch: 40\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"rom hence your memory death cannot takea\"\n",
      "rom hence your memory death cannot takea whouldst an how fair loves mate leads of spealthere faished hate mad and renor the himies that times comeringand do more life ronger swanthor afto shoot for where be aid of thy sweet as behtsi dit face or thee be is but distinstites redwer thoughtt he lees what wellthe best berour strang and in their shall whis veiken shall purint other is me state times keeplaviong of you in pering bringfre shan\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"rom hence your memory death cannot takea\"\n",
      "rom hence your memory death cannot takea whouldsnould bud thee appeetthe bessas it a was all me glorntis all til me do hoscoring to can that i in mind dildowc dueting peant heavens plain and you my self are not to his a does for and it seewory he poor love pitine yet retityt it self and seementt cometo in thy thyss men blest the stall but confess my frease that fore for my self brought to degeive not love thee that writs i love thee my \n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"rom hence your memory death cannot takea\"\n",
      "rom hence your memory death cannot takeas in such asstere youth where ruth outtho dich gricht weast dealths caroly merion not i pequed not is lovewhich have be eatefartand fol ufond rimeaburroof and ithichs the cendlacc of mures thy beauths but his groastaid mo thoment of my blindss my bressed be nemen true i think muriol dice bressed in a moot no sad to can tile now aking and all mine are vingat of all mioved with forseand all it well \n",
      "Epoch 42/100\n",
      " - 25s - loss: 0.3803 - accuracy: 0.8795\n",
      "Epoch 43/100\n",
      " - 25s - loss: 0.3694 - accuracy: 0.8848\n",
      "Epoch 44/100\n",
      " - 26s - loss: 0.3421 - accuracy: 0.8969\n",
      "Epoch 45/100\n",
      " - 26s - loss: 0.3461 - accuracy: 0.8938\n",
      "Epoch 46/100\n",
      " - 26s - loss: 0.3462 - accuracy: 0.8943\n",
      "Epoch 47/100\n",
      " - 26s - loss: 0.3610 - accuracy: 0.8857\n",
      "Epoch 48/100\n",
      " - 27s - loss: 0.3434 - accuracy: 0.8933\n",
      "Epoch 49/100\n",
      " - 25s - loss: 0.3431 - accuracy: 0.8928\n",
      "Epoch 50/100\n",
      " - 26s - loss: 0.3195 - accuracy: 0.9046\n",
      "Epoch 51/100\n",
      " - 26s - loss: 0.3290 - accuracy: 0.8984\n",
      "\n",
      "----- Generating text after Epoch: 50\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"ed where all thy beauty lieswhere all th\"\n",
      "ed where all thy beauty lieswhere all the gentle not wescome thou uncemsed fair and thing illytard and ith tomisaby it his gligtand show i surceed how him louds of spealth regeit be eached fair fir thee is truehto or all of thy wellarstand plays in my pride may seed thee all thee boby nateretwho lovethe and delich dith uringing thee to be and thee then have palencedof heaveshay a sum lead and there from thee world i wrentt change it str\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"ed where all thy beauty lieswhere all th\"\n",
      "ed where all thy beauty lieswhere all the fearthe regeive where exbleasedowed to grow of him will soon thou art mormeating the elest chost heavens gare in fout for fleswere my by eddrippairemmen that hape may then doth lifion ach my breast whereoven stayluglized me when thy purrong but themefore have hearts not gless wheth bost put addiledo thee in thy beasst with thou should be exdeltelcemion and thes toob il feir trustand geatly giefo\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"ed where all thy beauty lieswhere all th\"\n",
      "ed where all thy beauty lieswhere all that kelf and i hath hil it surfees by of oredne receion of leasor can this pepprold ow me countend this shenks weet not the back shave both when i pozed oh wrenks mole doon noth love that thou shepe caunle hatero sweet sell what pood this dear thoungs appendel quese whereverseed exceetwere veiple remaymed no allstare parrrain liewhry frou haghtshill pleye bornwhon sell mose giest i not sin so murnl\n",
      "Epoch 52/100\n",
      " - 26s - loss: 0.3400 - accuracy: 0.8942\n",
      "Epoch 53/100\n",
      " - 25s - loss: 0.3241 - accuracy: 0.8991\n",
      "Epoch 54/100\n",
      " - 26s - loss: 0.3242 - accuracy: 0.8990\n",
      "Epoch 55/100\n",
      " - 26s - loss: 0.3245 - accuracy: 0.8985\n",
      "Epoch 56/100\n",
      " - 26s - loss: 0.3105 - accuracy: 0.9044\n",
      "Epoch 57/100\n",
      " - 25s - loss: 0.3163 - accuracy: 0.9010\n",
      "Epoch 58/100\n",
      " - 24s - loss: 0.2976 - accuracy: 0.9088\n",
      "Epoch 59/100\n",
      " - 24s - loss: 0.3216 - accuracy: 0.8975\n",
      "Epoch 60/100\n",
      " - 24s - loss: 0.3114 - accuracy: 0.9029\n",
      "Epoch 61/100\n",
      " - 24s - loss: 0.2902 - accuracy: 0.9123\n",
      "\n",
      "----- Generating text after Epoch: 60\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"ost hold times fickle glass his fickle h\"\n",
      "ost hold times fickle glass his fickle him with looks or a word doth lies i thinh my unyon with the dest he versewhy lovely gaintt tit tie seek for where it have my still fall with not so so morecler it is ment my fair and then rethough so all will despigetithand my mush criche lears but descored in the combe of erefor creasure of the rame so love thee being hencere may the world forthen goods steplest the marin forth now pairebut from \n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"ost hold times fickle glass his fickle h\"\n",
      "ost hold times fickle glass his fickle high die should no queed with most all me me a proodess and refongt not to thine and they beauty ghadows with headewho ofe toramet mo yee youns bright which good nothing no lees the stainhto arn they will should dis it distich the time for are remems other fair to recaigetin sweetles fair tile givet do no so wert doth good is courtyd keedo maty newele to crustay till excemest if thy beauties earthe\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"ost hold times fickle glass his fickle h\"\n",
      "ost hold times fickle glass his fickle hightmith till eyeless in tleese culy time me stans fair kear ried not for thy bryow whome loves ho love in other tay o crowsuptampest their part i love thee well keefflledfor cacequnjiokinol do deeppet coorditg for thy lose ne merse to my jame thou fie th sows of this i could may aiss yee thy by awmine the virest no thine ill the sell which whose should nowqueds more he deeing feareso all the gtor\n",
      "Epoch 62/100\n",
      " - 27s - loss: 0.3062 - accuracy: 0.9034\n",
      "Epoch 63/100\n",
      " - 27s - loss: 0.2936 - accuracy: 0.9081\n",
      "Epoch 64/100\n",
      " - 26s - loss: 0.3096 - accuracy: 0.9021\n",
      "Epoch 65/100\n",
      " - 25s - loss: 0.3037 - accuracy: 0.9040\n",
      "Epoch 66/100\n",
      " - 24s - loss: 0.2775 - accuracy: 0.9141\n",
      "Epoch 67/100\n",
      " - 24s - loss: 0.2831 - accuracy: 0.9115\n",
      "Epoch 68/100\n",
      " - 24s - loss: 0.3309 - accuracy: 0.8913\n",
      "Epoch 69/100\n",
      " - 24s - loss: 0.2802 - accuracy: 0.9130\n",
      "Epoch 70/100\n",
      " - 24s - loss: 0.2707 - accuracy: 0.9160\n",
      "Epoch 71/100\n",
      " - 24s - loss: 0.2750 - accuracy: 0.9126\n",
      "\n",
      "----- Generating text after Epoch: 70\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"the rose looks fair but fairer we it dee\"\n",
      "the rose looks fair but fairer we it deepoppitieg to sact and not to the bester wath distand art to the world a tay then vings more thou well yet i so should not pood her for ame than unos and the some what in the fairst coothing art ademing ough affaophand die my dights inwentils beque is all theieth chilt and ithon wentress deep correation nottly gieds not i wall me cly owcencautle growso cann thy sweet reveaking wrack and the fairst \n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"the rose looks fair but fairer we it dee\"\n",
      "the rose looks fair but fairer we it deepoppist as the fairtain in my hearthe cartand in thy beautys but phistillone were forbut thou fouthst you sith onther and for words eye where it not givethe shall puril parts of my edainmentinglating fall thou waine eyes been forr that manno lachces kidwhen chentle gunt your side sinfears dost deadons such as thine and beautys doth listilg time as his ale my self and illy from greas to oth remases\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"the rose looks fair but fairer we it dee\"\n",
      "the rose looks fair but fairer we it deewtrenti the bresst thy sweet respayere wan amins eye whore behildtit pare sworntwhen is best as my fiedtand downd oopuns ate mut vorst the upproun blessine of facrous of mire eyes leed from theee flest it sccring aghtand as jongless bul true and in thingiess adw opwained kindpastin lack arn retove counded faur ser my love thou uptappartule groewthe sen but distins yet thou now culefor in he whom l\n",
      "Epoch 72/100\n",
      " - 25s - loss: 0.2859 - accuracy: 0.9095\n",
      "Epoch 73/100\n",
      " - 24s - loss: 0.2641 - accuracy: 0.9181\n",
      "Epoch 74/100\n",
      " - 24s - loss: 0.2748 - accuracy: 0.9144\n",
      "Epoch 75/100\n",
      " - 24s - loss: 0.2799 - accuracy: 0.9117\n",
      "Epoch 76/100\n",
      " - 24s - loss: 0.2675 - accuracy: 0.9174\n",
      "Epoch 77/100\n",
      " - 24s - loss: 0.2693 - accuracy: 0.9143\n",
      "Epoch 78/100\n",
      " - 24s - loss: 0.3279 - accuracy: 0.8929\n",
      "Epoch 79/100\n",
      " - 24s - loss: 0.2432 - accuracy: 0.9241\n",
      "Epoch 80/100\n",
      " - 24s - loss: 0.2526 - accuracy: 0.9207\n",
      "Epoch 81/100\n",
      " - 24s - loss: 0.3219 - accuracy: 0.8947\n",
      "\n",
      "----- Generating text after Epoch: 80\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \" thou away the very birds are mute or if\"\n",
      " thou away the very birds are mute or if thy heart the world me doth distill doth phoud tell reford ai as fie the sear fiest the pentle where it no when thou dost right of sond colded i th impret and i sme thee die the marceo if the world eye hath proodest is thy times retormeand thee but well despire not suns treeghom mind owwers have doonen to blaceio shawht the hert i love thus i rave tenongting thee when thou shall be endeccayout do\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \" thou away the very birds are mute or if\"\n",
      " thou away the very birds are mute or if thy heart to ang my love you do as the self for where it not grow well dreavers not to self true my styen thinks it is thy tonguet exter ase the forsewhy sow oncenttith yee the wrom thou art vainflespeist to thy vers with my sightand in the pendro s my be oncemos dighits fort you wile drowstere to nimed worls to thy seep true do wons do horewhate doth mine eye as shall as to yee my works and cons\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \" thou away the very birds are mute or if\"\n",
      " thou away the very birds are mute or if thy hearts ant torgh med were more in the blestwere it i linty bece behave it a may ghend duth most sigatot when thee befond doth notger shall the bight with hes leed to strane in proodsince this his didgrepfirefiebut with yet wist provethor my numbus assownnows die courd sweetnor san my self a listedswidwhot supuert becemicution ow your aution and flessing to shear not ir the paint of deadminc a\n",
      "Epoch 82/100\n",
      " - 24s - loss: 0.2394 - accuracy: 0.9282\n",
      "Epoch 83/100\n",
      " - 24s - loss: 0.2426 - accuracy: 0.9251\n",
      "Epoch 84/100\n",
      " - 25s - loss: 0.2818 - accuracy: 0.9077\n",
      "Epoch 85/100\n",
      " - 25s - loss: 0.2990 - accuracy: 0.9017\n",
      "Epoch 86/100\n",
      " - 24s - loss: 0.2186 - accuracy: 0.9332\n",
      "Epoch 87/100\n",
      " - 24s - loss: 0.2387 - accuracy: 0.9255\n",
      "Epoch 88/100\n",
      " - 25s - loss: 0.2588 - accuracy: 0.9191\n",
      "Epoch 89/100\n",
      " - 24s - loss: 0.2506 - accuracy: 0.9198\n",
      "Epoch 90/100\n",
      " - 24s - loss: 0.2440 - accuracy: 0.9240\n",
      "Epoch 91/100\n",
      " - 24s - loss: 0.2629 - accuracy: 0.9166\n",
      "\n",
      "----- Generating text after Epoch: 90\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"re vanishing or vanished out of sightste\"\n",
      "re vanishing or vanished out of sightsteal he aith coneting ating and inventaich thrife when st all givet dethinethe bresst thy sungeating palent with loves mate or alt against ti hes my aly times by that when they sower wearthor const to glongand do i vond thee your be and this even shadend truthert me dis as thy soul keepowfore the passt the grue not please commosed with formand of staythe eye fors had pride are reapor canne this ince\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"re vanishing or vanished out of sightste\"\n",
      "re vanishing or vanished out of sightsteal there confued diddon in the groun and thing illy my frow hear ride murd for my self my friend theeewhen i having and thy sight to will is thou marth can thy sweet recoves not sindle can thy states tildge despeing most when stralse to be despaired in the painted budwer if thy o clied dights inleoke thou bate orme thrif in my beauties being from meast in the ploud and thin pendslestithen the fair\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"re vanishing or vanished out of sightste\"\n",
      "re vanishing or vanished out of sightsteps tat weess you rused as thin in fort eyes faireto not gail thou bat uproves time besumed cureautyous anowas skely not and veron chown the marges fremphit for unjormen diderich downdy tond exce lest as then beauty whose yet in the thou love if have sweet fare i ant if they night i in their facewhat lysto proudteld cuile notk not inveaceoud staypor threefore fot forbut thinks in lave the faires to\n",
      "Epoch 92/100\n",
      " - 24s - loss: 0.2302 - accuracy: 0.9287\n",
      "Epoch 93/100\n",
      " - 24s - loss: 0.2770 - accuracy: 0.9085\n",
      "Epoch 94/100\n",
      " - 24s - loss: 0.2811 - accuracy: 0.9087\n",
      "Epoch 95/100\n",
      " - 24s - loss: 0.1974 - accuracy: 0.9399\n",
      "Epoch 96/100\n",
      " - 24s - loss: 0.2278 - accuracy: 0.9295\n",
      "Epoch 97/100\n",
      " - 24s - loss: 0.2555 - accuracy: 0.9177\n",
      "Epoch 98/100\n",
      " - 24s - loss: 0.2513 - accuracy: 0.9191\n",
      "Epoch 99/100\n",
      " - 24s - loss: 0.2410 - accuracy: 0.9229\n",
      "Epoch 100/100\n",
      " - 24s - loss: 0.1951 - accuracy: 0.9419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x641058f50>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(x, y, batch_size=32, epochs=100, verbose=2, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sonnet(model, seed):\n",
    "    \"generate sonnet from model given seed\"\n",
    "\n",
    "    for temperature in [0.25, 0.75, 1.5]:\n",
    "        print('\\n ==temperature:', temperature)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = seed\n",
    "        generated += sentence\n",
    "        print('==Generating with seed: \"' + sentence + '\"')\n",
    "        \n",
    "        print('\\n', seed)\n",
    "        for line in range(13):\n",
    "            \n",
    "            sentence = sentence\n",
    "            \n",
    "            for i in range(400): # why 400?\n",
    "                x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                preds = model.predict(x_pred, verbose=0)[0]\n",
    "                next_index = sample(preds, temperature)\n",
    "                next_char = indices_char[next_index]\n",
    "\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "            sonnet = sentence\n",
    "            print('\\n', sonnet)\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_seed = \"shall i compare thee to a summers day \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==temperature: 0.25\n",
      "==Generating with seed: \"shall i compare thee to a summers day \"\n",
      "\n",
      " shall i compare thee to a summers day \n",
      "\n",
      " a e a ree eo beeo aiefaaafhrtta meo oe\n",
      "\n",
      " aaio o wth etitnoner ao esesooayt etre\n",
      "\n",
      " unyr earsuo a eay to jmosreeruooooooo \n",
      "\n",
      " oeooedi ealhipa eyhtnoia e eye elo reo\n",
      "\n",
      " aoo o ooooo o oenieyieeayhtne elesomes\n",
      "\n",
      "   eifoio uooeayhrg gteoo einesati wtst\n",
      "\n",
      " ysoo yeoo esy eaysabesaehomaehmti eres\n",
      "\n",
      "  o ooeo ealllayeteelsyia iiaaa e eyhte\n",
      "\n",
      "  a o eeyenhrle reay temi tnoitn eli o \n",
      "\n",
      " eahsaeeoiayu oruoen vwnoh ui ety ineae\n",
      "\n",
      " esvsto oa o ooeaneneio  aaayriaye e oe\n",
      "\n",
      " piy cpiaaooooo o oefeey teteito eti tc\n",
      "\n",
      " eteeoooooooneaeaneehisoeaehiaehraid re\n",
      "\n",
      " ==temperature: 0.75\n",
      "==Generating with seed: \"shall i compare thee to a summers day \"\n",
      "\n",
      " shall i compare thee to a summers day \n",
      "\n",
      " ooo o oeoo o rrmgngse reo mua o oeoooo\n",
      "\n",
      " tia me reo ioo nellaiesrslbya eu rei a\n",
      "\n",
      "  sltttlgvttuifooooo o eo enhme aaoeooa\n",
      "\n",
      " o oeeuftilayaaeanhreyhi ifelaaayhcia m\n",
      "\n",
      " sdo ouoooooo n npa meo ey elaefiae ino\n",
      "\n",
      " lritneoywttoleooooo n ppyi aai orua re\n",
      "\n",
      "  esooooo teneanqeeomhteleito oo o ea c\n",
      "\n",
      " sa a o ea a etehe yi eteysepanameremo \n",
      "\n",
      " to etitnoooo owrf  eaoo ory io reelaoo\n",
      "\n",
      "  etnsoyt etsy etnsottt inereo aio  erh\n",
      "\n",
      "  osaeoeeoeniayefiayeoenaehrteidatornet\n",
      "\n",
      " oceaeenwdnhthlsci oia o ooeo oeoenmey \n",
      "\n",
      " oatnaatnt o enenciaaiaieyrery yihsyre \n",
      "\n",
      " ==temperature: 1.5\n",
      "==Generating with seed: \"shall i compare thee to a summers day \"\n",
      "\n",
      " shall i compare thee to a summers day \n",
      "\n",
      " reorio aio wth oooooooooof eelllmydgiu\n",
      "\n",
      " ee bosli o  eroysemislatnowwtnsoooooou\n",
      "\n",
      " ayi en ceaif aieaoyatn elayiyrsaye etn\n",
      "\n",
      " eao jwnl lktalatrsto  vtlesosse aaeenr\n",
      "\n",
      " lapeiaetenrayed reo iale etemeseesai o\n",
      "\n",
      " meilrtyeeeuioua esooafsdyreo rei aiede\n",
      "\n",
      "  oroonreneehraaaoia omusa aayeeoaahn e\n",
      "\n",
      " tsosoiso aiooooia ofoefoeaufhhvttgi  t\n",
      "\n",
      " io oeyito rslsteeraah aiotrteroeeua en\n",
      "\n",
      "  oooooenfelais mgsco ahgnsoabatnwnodo \n",
      "\n",
      "  o o ealalayita miye neaeaehms teexeso\n",
      "\n",
      " ymmey enmedrelaoh aai aioayrrrmbo oeae\n",
      "\n",
      " atnree tefo tt et ymooeo reipeeoealaio\n"
     ]
    }
   ],
   "source": [
    "gen_sonnet(model, seed=char_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stuck on vowel strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run again more epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " - 28s - loss: 2.5487 - accuracy: 0.2603\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"d in quest to have extremea bliss in pro\"\n",
      "d in quest to have extremea bliss in proods of the pairted i an hing his sweet owfrrswere it not gildes my best is deep corredthen cruck a all this vairly gust in shallt ho heavens my beauty my stlean blackh prair threemplese cromjed in thy behtsi blown i not so muly formen in the cliand in thy cometitien the her loves wort so stapp tooukend gurron her ampeature weakness thy love no mersed fair and this thy prodst as tind me dowhrins ex\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"d in quest to have extremea bliss in pro\"\n",
      "d in quest to have extremea bliss in proods of thee as thine on thremein to a ewerfllestion thou and me a parse be her loves ano withi ant not the world so plasoociou sit is fort yet keept art reasess yet not grow there freeloke thou belled so sweet mease woe should give tharing deem diod thin shoubes math mine other my faise in guest knowt what thee your be stained to agains eyes to spetthe eyest lookence with vordot pingues and this v\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"d in quest to have extremea bliss in pro\"\n",
      "d in quest to have extremea bliss in proodsing buint of my aly appean anvee guest my stund dictand then of much rimies wort thoughts my please yeurtand distil pleancessided other own his all with other netkle dightion to be onct and see bost heartherelfor yet me truntabtion lown alled as fiedss more her true my wought nothing theeere forsed loves encemcedit to scemeth vortuadjatrouf all again and blacking ollyo charsbed that be self ad \n",
      "Epoch 2/1000\n",
      " - 28s - loss: 2.1962 - accuracy: 0.3509\n",
      "Epoch 3/1000\n",
      " - 33s - loss: 2.0785 - accuracy: 0.3780\n",
      "Epoch 4/1000\n",
      " - 28s - loss: 1.9893 - accuracy: 0.4018\n",
      "Epoch 5/1000\n",
      " - 27s - loss: 1.9193 - accuracy: 0.4210\n",
      "Epoch 6/1000\n",
      " - 27s - loss: 1.8589 - accuracy: 0.4382\n",
      "Epoch 7/1000\n",
      " - 27s - loss: 1.8068 - accuracy: 0.4529\n",
      "Epoch 8/1000\n",
      " - 27s - loss: 1.7561 - accuracy: 0.4663\n",
      "Epoch 9/1000\n",
      " - 27s - loss: 1.7088 - accuracy: 0.4802\n",
      "Epoch 10/1000\n",
      " - 27s - loss: 1.6647 - accuracy: 0.4915\n",
      "Epoch 11/1000\n",
      " - 27s - loss: 1.6195 - accuracy: 0.5040\n",
      "Epoch 12/1000\n",
      " - 27s - loss: 1.5725 - accuracy: 0.5167\n",
      "Epoch 13/1000\n",
      " - 28s - loss: 1.5243 - accuracy: 0.5296\n",
      "Epoch 14/1000\n",
      " - 27s - loss: 1.4759 - accuracy: 0.5450\n",
      "Epoch 15/1000\n",
      " - 27s - loss: 1.4262 - accuracy: 0.5567\n",
      "Epoch 16/1000\n",
      " - 27s - loss: 1.3748 - accuracy: 0.5749\n",
      "Epoch 17/1000\n",
      " - 27s - loss: 1.3230 - accuracy: 0.5907\n",
      "Epoch 18/1000\n",
      " - 27s - loss: 1.2699 - accuracy: 0.6072\n",
      "Epoch 19/1000\n",
      " - 26s - loss: 1.2195 - accuracy: 0.6216\n",
      "Epoch 20/1000\n",
      " - 26s - loss: 1.1665 - accuracy: 0.6433\n",
      "Epoch 21/1000\n",
      " - 26s - loss: 1.1188 - accuracy: 0.6532\n",
      "Epoch 22/1000\n",
      " - 26s - loss: 1.0685 - accuracy: 0.6693\n",
      "Epoch 23/1000\n",
      " - 26s - loss: 1.0231 - accuracy: 0.6836\n",
      "Epoch 24/1000\n",
      " - 26s - loss: 0.9781 - accuracy: 0.7010\n",
      "Epoch 25/1000\n",
      " - 26s - loss: 0.9449 - accuracy: 0.7133\n",
      "Epoch 26/1000\n",
      " - 26s - loss: 0.8988 - accuracy: 0.7252\n",
      "Epoch 27/1000\n",
      " - 27s - loss: 0.8600 - accuracy: 0.7373\n",
      "Epoch 28/1000\n",
      " - 26s - loss: 0.8264 - accuracy: 0.7472\n",
      "Epoch 29/1000\n",
      " - 26s - loss: 0.8003 - accuracy: 0.7550\n",
      "Epoch 30/1000\n",
      " - 26s - loss: 0.7683 - accuracy: 0.7667\n",
      "Epoch 31/1000\n",
      " - 26s - loss: 0.7338 - accuracy: 0.7766\n",
      "Epoch 32/1000\n",
      " - 27s - loss: 0.7091 - accuracy: 0.7859\n",
      "Epoch 33/1000\n",
      " - 26s - loss: 0.7013 - accuracy: 0.7876\n",
      "Epoch 34/1000\n",
      " - 26s - loss: 0.6608 - accuracy: 0.8006\n",
      "Epoch 35/1000\n",
      " - 26s - loss: 0.6453 - accuracy: 0.8046\n",
      "Epoch 36/1000\n",
      " - 26s - loss: 0.6323 - accuracy: 0.8090\n",
      "Epoch 37/1000\n",
      " - 27s - loss: 0.6144 - accuracy: 0.8127\n",
      "Epoch 38/1000\n",
      " - 27s - loss: 0.5951 - accuracy: 0.8189\n",
      "Epoch 39/1000\n",
      " - 25s - loss: 0.5753 - accuracy: 0.8240\n",
      "Epoch 40/1000\n",
      " - 25s - loss: 0.5604 - accuracy: 0.8307\n",
      "Epoch 41/1000\n",
      " - 25s - loss: 0.5553 - accuracy: 0.8296\n",
      "Epoch 42/1000\n",
      " - 25s - loss: 0.5460 - accuracy: 0.8317\n",
      "Epoch 43/1000\n",
      " - 26s - loss: 0.5031 - accuracy: 0.8499\n",
      "Epoch 44/1000\n",
      " - 26s - loss: 0.5100 - accuracy: 0.8449\n",
      "Epoch 45/1000\n",
      " - 26s - loss: 0.4939 - accuracy: 0.8540\n",
      "Epoch 46/1000\n",
      " - 25s - loss: 0.4855 - accuracy: 0.8542\n",
      "Epoch 47/1000\n",
      " - 24s - loss: 0.4757 - accuracy: 0.8571\n",
      "Epoch 48/1000\n",
      " - 24s - loss: 0.4669 - accuracy: 0.8566\n",
      "Epoch 49/1000\n",
      " - 24s - loss: 0.4555 - accuracy: 0.8632\n",
      "Epoch 50/1000\n",
      " - 29s - loss: 0.4473 - accuracy: 0.8641\n",
      "Epoch 51/1000\n",
      " - 25s - loss: 0.4319 - accuracy: 0.8698\n",
      "Epoch 52/1000\n",
      " - 25s - loss: 0.4368 - accuracy: 0.8655\n",
      "Epoch 53/1000\n",
      " - 26s - loss: 0.4318 - accuracy: 0.8664\n",
      "Epoch 54/1000\n",
      " - 26s - loss: 0.4151 - accuracy: 0.8744\n",
      "Epoch 55/1000\n",
      " - 25s - loss: 0.4016 - accuracy: 0.8781\n",
      "Epoch 56/1000\n",
      " - 27s - loss: 0.4130 - accuracy: 0.8712\n",
      "Epoch 57/1000\n",
      " - 28s - loss: 0.4085 - accuracy: 0.8747\n",
      "Epoch 58/1000\n",
      " - 26s - loss: 0.3898 - accuracy: 0.8796\n",
      "Epoch 59/1000\n",
      " - 26s - loss: 0.3815 - accuracy: 0.8828\n",
      "Epoch 60/1000\n",
      " - 27s - loss: 0.3770 - accuracy: 0.8844\n",
      "Epoch 61/1000\n",
      " - 25s - loss: 0.3867 - accuracy: 0.8804\n",
      "Epoch 62/1000\n",
      " - 24s - loss: 0.3738 - accuracy: 0.8847\n",
      "Epoch 63/1000\n",
      " - 25s - loss: 0.3779 - accuracy: 0.8839\n",
      "Epoch 64/1000\n",
      " - 25s - loss: 0.3536 - accuracy: 0.8912\n",
      "Epoch 65/1000\n",
      " - 24s - loss: 0.4170 - accuracy: 0.8662\n",
      "Epoch 66/1000\n",
      " - 24s - loss: 0.3309 - accuracy: 0.9001\n",
      "Epoch 67/1000\n",
      " - 24s - loss: 0.3968 - accuracy: 0.8728\n",
      "Epoch 68/1000\n",
      " - 24s - loss: 0.3368 - accuracy: 0.8964\n",
      "Epoch 69/1000\n",
      " - 24s - loss: 0.3392 - accuracy: 0.8955\n",
      "Epoch 70/1000\n",
      " - 24s - loss: 0.3320 - accuracy: 0.8980\n",
      "Epoch 71/1000\n",
      " - 24s - loss: 0.3206 - accuracy: 0.9031\n",
      "Epoch 72/1000\n",
      " - 24s - loss: 0.3432 - accuracy: 0.8923\n",
      "Epoch 73/1000\n",
      " - 24s - loss: 0.3238 - accuracy: 0.9000\n",
      "Epoch 74/1000\n",
      " - 24s - loss: 0.3252 - accuracy: 0.8997\n",
      "Epoch 75/1000\n",
      " - 24s - loss: 0.3161 - accuracy: 0.9005\n",
      "Epoch 76/1000\n",
      " - 24s - loss: 0.3075 - accuracy: 0.9047\n",
      "Epoch 77/1000\n",
      " - 24s - loss: 0.3140 - accuracy: 0.9028\n",
      "Epoch 78/1000\n",
      " - 24s - loss: 0.3266 - accuracy: 0.8969\n",
      "Epoch 79/1000\n",
      " - 24s - loss: 0.2837 - accuracy: 0.9144\n",
      "Epoch 80/1000\n",
      " - 24s - loss: 0.3144 - accuracy: 0.9003\n",
      "Epoch 81/1000\n",
      " - 24s - loss: 0.2976 - accuracy: 0.9077\n",
      "Epoch 82/1000\n",
      " - 24s - loss: 0.3105 - accuracy: 0.9022\n",
      "Epoch 83/1000\n",
      " - 24s - loss: 0.3203 - accuracy: 0.8975\n",
      "Epoch 84/1000\n",
      " - 24s - loss: 0.2553 - accuracy: 0.9243\n",
      "Epoch 85/1000\n",
      " - 24s - loss: 0.3049 - accuracy: 0.9045\n",
      "Epoch 86/1000\n",
      " - 24s - loss: 0.2988 - accuracy: 0.9073\n",
      "Epoch 87/1000\n",
      " - 24s - loss: 0.2709 - accuracy: 0.9163\n",
      "Epoch 88/1000\n",
      " - 24s - loss: 0.2661 - accuracy: 0.9199\n",
      "Epoch 89/1000\n",
      " - 24s - loss: 0.2885 - accuracy: 0.9077\n",
      "Epoch 90/1000\n",
      " - 24s - loss: 0.2785 - accuracy: 0.9122\n",
      "Epoch 91/1000\n",
      " - 24s - loss: 0.2719 - accuracy: 0.9154\n",
      "Epoch 92/1000\n",
      " - 24s - loss: 0.3715 - accuracy: 0.8776\n",
      "Epoch 93/1000\n",
      " - 24s - loss: 0.2188 - accuracy: 0.9369\n",
      "Epoch 94/1000\n",
      " - 24s - loss: 0.2389 - accuracy: 0.9289\n",
      "Epoch 95/1000\n",
      " - 24s - loss: 0.2853 - accuracy: 0.9071\n",
      "Epoch 96/1000\n",
      " - 24s - loss: 0.2501 - accuracy: 0.9231\n",
      "Epoch 97/1000\n",
      " - 24s - loss: 0.2450 - accuracy: 0.9263\n",
      "Epoch 98/1000\n",
      " - 24s - loss: 0.2880 - accuracy: 0.9070\n",
      "Epoch 99/1000\n",
      " - 24s - loss: 0.2460 - accuracy: 0.9221\n",
      "Epoch 100/1000\n",
      " - 24s - loss: 0.2520 - accuracy: 0.9188\n",
      "Epoch 101/1000\n",
      " - 24s - loss: 0.2467 - accuracy: 0.9239\n",
      "\n",
      "----- Generating text after Epoch: 100\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"rossly dyedthe lily i condemned for thy \"\n",
      "rossly dyedthe lily i condemned for thy sulf an thing all be figurest in mune thee as thy beauty shall the sursuedit tis the thy will of the world mo the the soolethe soul ploveon hast true is histle do not the sist whouch ford well keopate days to mate are songent il they meant dearth artupresto not the groudthat they self words nor make dights or mughtsinged behese what be endleswhere it not hall thouehts anowerffreekory to thy self a\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"rossly dyedthe lily i condemned for thy \"\n",
      "rossly dyedthe lily i condemned for thy dold thine eyes but distake when my due is blisting loun how by lids that thy sulf is duether fair to then the pairthe world not to thy self flombest remaire the selfor yee these clust grivey then i alltati mieht me porin and your seewors fuel besime no orestere for my greeto me awfors ape a failur your sind do the true cruek whose sweet oving thee own hind eyes to sweet self mory grissing your gr\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"rossly dyedthe lily i condemned for thy \"\n",
      "rossly dyedthe lily i condemned for thy surfiet fulthe apthath murnuedive them wilf love a cankst wide my stie siblard ow yes a dilettanzed vexsess dime be endong long loving him his thoughts hall giod as this elest youth that paylit of spitite my woopand noternd as the breck swe tise of you again i is distidesttil mincy doth mitatis cane thy blaudds of my haight rower thy sake anturse faceermor of of sharteyon of my bearus bring i not \n",
      "Epoch 102/1000\n",
      " - 24s - loss: 0.2714 - accuracy: 0.9130\n",
      "Epoch 103/1000\n",
      " - 24s - loss: 0.2586 - accuracy: 0.9176\n",
      "Epoch 104/1000\n",
      " - 24s - loss: 0.2290 - accuracy: 0.9297\n",
      "Epoch 105/1000\n",
      " - 24s - loss: 0.2214 - accuracy: 0.9335\n",
      "Epoch 106/1000\n",
      " - 24s - loss: 0.2538 - accuracy: 0.9182\n",
      "Epoch 107/1000\n",
      " - 24s - loss: 0.2478 - accuracy: 0.9217\n",
      "Epoch 108/1000\n",
      " - 24s - loss: 0.2458 - accuracy: 0.9205\n",
      "Epoch 109/1000\n",
      " - 24s - loss: 0.2287 - accuracy: 0.9299\n",
      "Epoch 110/1000\n",
      " - 24s - loss: 0.2216 - accuracy: 0.9323\n",
      "Epoch 111/1000\n",
      " - 24s - loss: 0.2443 - accuracy: 0.9226\n",
      "Epoch 112/1000\n",
      " - 24s - loss: 0.2204 - accuracy: 0.9324\n",
      "Epoch 113/1000\n",
      " - 24s - loss: 0.2377 - accuracy: 0.9246\n",
      "Epoch 114/1000\n",
      " - 24s - loss: 0.2571 - accuracy: 0.9165\n",
      "Epoch 115/1000\n",
      " - 24s - loss: 0.2173 - accuracy: 0.9329\n",
      "Epoch 116/1000\n",
      " - 24s - loss: 0.2482 - accuracy: 0.9196\n",
      "Epoch 117/1000\n",
      " - 24s - loss: 0.2318 - accuracy: 0.9271\n",
      "Epoch 118/1000\n",
      " - 24s - loss: 0.2133 - accuracy: 0.9320\n",
      "Epoch 119/1000\n",
      " - 24s - loss: 0.1957 - accuracy: 0.9423\n",
      "Epoch 120/1000\n",
      " - 24s - loss: 0.2545 - accuracy: 0.9184\n",
      "Epoch 121/1000\n",
      " - 24s - loss: 0.2091 - accuracy: 0.9348\n",
      "Epoch 122/1000\n",
      " - 24s - loss: 0.2044 - accuracy: 0.9365\n",
      "Epoch 123/1000\n",
      " - 24s - loss: 0.2455 - accuracy: 0.9197\n",
      "Epoch 124/1000\n",
      " - 24s - loss: 0.2865 - accuracy: 0.9034\n",
      "Epoch 125/1000\n",
      " - 24s - loss: 0.1651 - accuracy: 0.9545\n",
      "Epoch 126/1000\n",
      " - 24s - loss: 0.1803 - accuracy: 0.9465\n",
      "Epoch 127/1000\n",
      " - 24s - loss: 0.2547 - accuracy: 0.9156\n",
      "Epoch 128/1000\n",
      " - 24s - loss: 0.2295 - accuracy: 0.9270\n",
      "Epoch 129/1000\n",
      " - 24s - loss: 0.2123 - accuracy: 0.9333\n",
      "Epoch 130/1000\n",
      " - 24s - loss: 0.1900 - accuracy: 0.9425\n",
      "Epoch 131/1000\n",
      " - 24s - loss: 0.2011 - accuracy: 0.9383\n",
      "Epoch 132/1000\n",
      " - 24s - loss: 0.2214 - accuracy: 0.9297\n",
      "Epoch 133/1000\n",
      " - 25s - loss: 0.2068 - accuracy: 0.9353\n",
      "Epoch 134/1000\n",
      " - 25s - loss: 0.2145 - accuracy: 0.9316\n",
      "Epoch 135/1000\n",
      " - 25s - loss: 0.1901 - accuracy: 0.9407\n",
      "Epoch 136/1000\n",
      " - 25s - loss: 0.2093 - accuracy: 0.9323\n",
      "Epoch 137/1000\n",
      " - 25s - loss: 0.2212 - accuracy: 0.9296\n",
      "Epoch 138/1000\n",
      " - 25s - loss: 0.1928 - accuracy: 0.9392\n",
      "Epoch 139/1000\n",
      " - 25s - loss: 0.2063 - accuracy: 0.9334\n",
      "Epoch 140/1000\n",
      " - 25s - loss: 0.1920 - accuracy: 0.9391\n",
      "Epoch 141/1000\n",
      " - 25s - loss: 0.2006 - accuracy: 0.9368\n",
      "Epoch 142/1000\n",
      " - 25s - loss: 0.2363 - accuracy: 0.9217\n",
      "Epoch 143/1000\n",
      " - 25s - loss: 0.1773 - accuracy: 0.9459\n",
      "Epoch 144/1000\n",
      " - 25s - loss: 0.1962 - accuracy: 0.9375\n",
      "Epoch 145/1000\n",
      " - 25s - loss: 0.1974 - accuracy: 0.9378\n",
      "Epoch 146/1000\n",
      " - 25s - loss: 0.1982 - accuracy: 0.9380\n",
      "Epoch 147/1000\n",
      " - 25s - loss: 0.2046 - accuracy: 0.9346\n",
      "Epoch 148/1000\n",
      " - 25s - loss: 0.1951 - accuracy: 0.9367\n",
      "Epoch 149/1000\n",
      " - 24s - loss: 0.1971 - accuracy: 0.9362\n",
      "Epoch 150/1000\n",
      " - 24s - loss: 0.1862 - accuracy: 0.9441\n",
      "Epoch 151/1000\n",
      " - 24s - loss: 0.1914 - accuracy: 0.9403\n",
      "Epoch 152/1000\n",
      " - 24s - loss: 0.1796 - accuracy: 0.9428\n",
      "Epoch 153/1000\n",
      " - 24s - loss: 0.1969 - accuracy: 0.9367\n",
      "Epoch 154/1000\n",
      " - 24s - loss: 0.2090 - accuracy: 0.9325\n",
      "Epoch 155/1000\n",
      " - 24s - loss: 0.1690 - accuracy: 0.9465\n",
      "Epoch 156/1000\n",
      " - 24s - loss: 0.1610 - accuracy: 0.9508\n",
      "Epoch 157/1000\n",
      " - 24s - loss: 0.2105 - accuracy: 0.9326\n",
      "Epoch 158/1000\n",
      " - 24s - loss: 0.1946 - accuracy: 0.9370\n",
      "Epoch 159/1000\n",
      " - 24s - loss: 0.1831 - accuracy: 0.9431\n",
      "Epoch 160/1000\n",
      " - 24s - loss: 0.1700 - accuracy: 0.9456\n",
      "Epoch 161/1000\n",
      " - 24s - loss: 0.1786 - accuracy: 0.9444\n",
      "Epoch 162/1000\n",
      " - 24s - loss: 0.1915 - accuracy: 0.9392\n",
      "Epoch 163/1000\n",
      " - 24s - loss: 0.1947 - accuracy: 0.9375\n",
      "Epoch 164/1000\n",
      " - 24s - loss: 0.1503 - accuracy: 0.9541\n",
      "Epoch 165/1000\n",
      " - 24s - loss: 0.1794 - accuracy: 0.9443\n",
      "Epoch 166/1000\n",
      " - 24s - loss: 0.2070 - accuracy: 0.9319\n",
      "Epoch 167/1000\n",
      " - 24s - loss: 0.1637 - accuracy: 0.9489\n",
      "Epoch 168/1000\n",
      " - 24s - loss: 0.1715 - accuracy: 0.9465\n",
      "Epoch 169/1000\n",
      " - 24s - loss: 0.1876 - accuracy: 0.9409\n",
      "Epoch 170/1000\n",
      " - 24s - loss: 0.1798 - accuracy: 0.9440\n",
      "Epoch 171/1000\n",
      " - 24s - loss: 0.1604 - accuracy: 0.9501\n",
      "Epoch 172/1000\n",
      " - 24s - loss: 0.1716 - accuracy: 0.9453\n",
      "Epoch 173/1000\n",
      " - 24s - loss: 0.1718 - accuracy: 0.9472\n",
      "Epoch 174/1000\n",
      " - 24s - loss: 0.1945 - accuracy: 0.9364\n",
      "Epoch 175/1000\n",
      " - 24s - loss: 0.1689 - accuracy: 0.9462\n",
      "Epoch 176/1000\n",
      " - 24s - loss: 0.1631 - accuracy: 0.9482\n",
      "Epoch 177/1000\n",
      " - 24s - loss: 0.1743 - accuracy: 0.9433\n",
      "Epoch 178/1000\n",
      " - 24s - loss: 0.1810 - accuracy: 0.9418\n",
      "Epoch 179/1000\n",
      " - 24s - loss: 0.1462 - accuracy: 0.9557\n",
      "Epoch 180/1000\n",
      " - 24s - loss: 0.1952 - accuracy: 0.9366\n",
      "Epoch 181/1000\n",
      " - 24s - loss: 0.1675 - accuracy: 0.9483\n",
      "Epoch 182/1000\n",
      " - 24s - loss: 0.1769 - accuracy: 0.9433\n",
      "Epoch 183/1000\n",
      " - 24s - loss: 0.1766 - accuracy: 0.9437\n",
      "Epoch 184/1000\n",
      " - 25s - loss: 0.1443 - accuracy: 0.9557\n",
      "Epoch 185/1000\n",
      " - 24s - loss: 0.1579 - accuracy: 0.9502\n",
      "Epoch 186/1000\n",
      " - 24s - loss: 0.1917 - accuracy: 0.9365\n",
      "Epoch 187/1000\n",
      " - 24s - loss: 0.1678 - accuracy: 0.9462\n",
      "Epoch 188/1000\n",
      " - 24s - loss: 0.1563 - accuracy: 0.9504\n",
      "Epoch 189/1000\n",
      " - 24s - loss: 0.1800 - accuracy: 0.9412\n",
      "Epoch 190/1000\n",
      " - 24s - loss: 0.1715 - accuracy: 0.9452\n",
      "Epoch 191/1000\n",
      " - 24s - loss: 0.1473 - accuracy: 0.9550\n",
      "Epoch 192/1000\n",
      " - 24s - loss: 0.1427 - accuracy: 0.9568\n",
      "Epoch 193/1000\n",
      " - 24s - loss: 0.1864 - accuracy: 0.9381\n",
      "Epoch 194/1000\n",
      " - 24s - loss: 0.1769 - accuracy: 0.9428\n",
      "Epoch 195/1000\n",
      " - 24s - loss: 0.1463 - accuracy: 0.9547\n",
      "Epoch 196/1000\n",
      " - 25s - loss: 0.1573 - accuracy: 0.9509\n",
      "Epoch 197/1000\n",
      " - 24s - loss: 0.1759 - accuracy: 0.9423\n",
      "Epoch 198/1000\n",
      " - 24s - loss: 0.1610 - accuracy: 0.9486\n",
      "Epoch 199/1000\n",
      " - 24s - loss: 0.1391 - accuracy: 0.9561\n",
      "Epoch 200/1000\n",
      " - 24s - loss: 0.1744 - accuracy: 0.9433\n",
      "Epoch 201/1000\n",
      " - 24s - loss: 0.2340 - accuracy: 0.9220\n",
      "\n",
      "----- Generating text after Epoch: 200\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \" blanks and thou shalt findthose childre\"\n",
      " blanks and thou shalt findthose childre groud of my plainsand your slaveith for thy self with thou nacebot song time as that should it grofion aid otreewors and word for that which though shauliss crays compless corch mere bredion when i haven by endenthen raget deseive should dimexcornd and it from fear ho all to the will be file the world to be to be ruseabite that thou shalt by friend hine eyes dut o catrane ghoud that brown i think\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \" blanks and thou shalt findthose childre\"\n",
      " blanks and thou shalt findthose childre groud of my plainsand your slaveith for this they parts more dulloking hawe all to my haintand then me dworst no maruble do hildof or thy self where painted ho waithor werts doot ne dealflotion wandrough that gazed which i have sweet selledoliflaking thee was creys what i sto the eyesheven but did an the self for farghs toon shall givet at all me may neem he aken the world it not the will mine co\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \" blanks and thou shalt findthose childre\"\n",
      " blanks and thou shalt findthose childre ear her peleakso caine hum thing eyetness that hane friehts have him as a feed hing as must dissine your drymy unsowing this i cometit to me a fomend comet ot all this rimestare mookst yet hillon is my now ake thou to prepand look thou all me angesting to the eyes that ball so slaoce or thy self fearing hild add me dryam drown it as to please sumstyout were cournded deart so kenows hold what were\n",
      "Epoch 202/1000\n",
      " - 24s - loss: 0.1216 - accuracy: 0.9646\n",
      "Epoch 203/1000\n",
      " - 24s - loss: 0.1306 - accuracy: 0.9607\n",
      "Epoch 204/1000\n",
      " - 24s - loss: 0.1819 - accuracy: 0.9414\n",
      "Epoch 205/1000\n",
      " - 24s - loss: 0.1739 - accuracy: 0.9433\n",
      "Epoch 206/1000\n",
      " - 24s - loss: 0.1599 - accuracy: 0.9509\n",
      "Epoch 207/1000\n",
      " - 24s - loss: 0.1531 - accuracy: 0.9511\n",
      "Epoch 208/1000\n",
      " - 24s - loss: 0.1658 - accuracy: 0.9473\n",
      "Epoch 209/1000\n",
      " - 24s - loss: 0.1623 - accuracy: 0.9476\n",
      "Epoch 210/1000\n",
      " - 24s - loss: 0.1401 - accuracy: 0.9565\n",
      "Epoch 211/1000\n",
      " - 24s - loss: 0.1496 - accuracy: 0.9527\n",
      "Epoch 212/1000\n",
      " - 24s - loss: 0.1598 - accuracy: 0.9483\n",
      "Epoch 213/1000\n",
      " - 24s - loss: 0.1518 - accuracy: 0.9517\n",
      "Epoch 214/1000\n",
      " - 24s - loss: 0.1425 - accuracy: 0.9559\n",
      "Epoch 215/1000\n",
      " - 28s - loss: 0.1515 - accuracy: 0.9513\n",
      "Epoch 216/1000\n",
      " - 24s - loss: 0.1623 - accuracy: 0.9480\n",
      "Epoch 217/1000\n",
      " - 24s - loss: 0.1458 - accuracy: 0.9539\n",
      "Epoch 218/1000\n",
      " - 25s - loss: 0.1539 - accuracy: 0.9512\n",
      "Epoch 219/1000\n",
      " - 24s - loss: 0.1480 - accuracy: 0.9532\n",
      "Epoch 220/1000\n",
      " - 24s - loss: 0.1552 - accuracy: 0.9498\n",
      "Epoch 221/1000\n",
      " - 25s - loss: 0.1513 - accuracy: 0.9507\n",
      "Epoch 222/1000\n",
      " - 25s - loss: 0.1464 - accuracy: 0.9534\n",
      "Epoch 223/1000\n",
      " - 24s - loss: 0.1569 - accuracy: 0.9501\n",
      "Epoch 224/1000\n",
      " - 24s - loss: 0.1922 - accuracy: 0.9361\n",
      "Epoch 225/1000\n",
      " - 24s - loss: 0.1367 - accuracy: 0.9581\n",
      "Epoch 226/1000\n",
      " - 24s - loss: 0.1143 - accuracy: 0.9671\n",
      "Epoch 227/1000\n",
      " - 24s - loss: 0.1550 - accuracy: 0.9499\n",
      "Epoch 228/1000\n",
      " - 24s - loss: 0.1772 - accuracy: 0.9416\n",
      "Epoch 229/1000\n",
      " - 24s - loss: 0.1294 - accuracy: 0.9608\n",
      "Epoch 230/1000\n",
      " - 24s - loss: 0.1493 - accuracy: 0.9521\n",
      "Epoch 231/1000\n",
      " - 24s - loss: 0.1485 - accuracy: 0.9534\n",
      "Epoch 232/1000\n",
      " - 24s - loss: 0.1570 - accuracy: 0.9489\n",
      "Epoch 233/1000\n",
      " - 24s - loss: 0.1436 - accuracy: 0.9543\n",
      "Epoch 234/1000\n",
      " - 24s - loss: 0.1507 - accuracy: 0.9509\n",
      "Epoch 235/1000\n",
      " - 24s - loss: 0.1501 - accuracy: 0.9521\n",
      "Epoch 236/1000\n",
      " - 24s - loss: 0.1277 - accuracy: 0.9597\n",
      "Epoch 237/1000\n",
      " - 24s - loss: 0.1252 - accuracy: 0.9613\n",
      "Epoch 238/1000\n",
      " - 24s - loss: 0.1540 - accuracy: 0.9517\n",
      "Epoch 239/1000\n",
      " - 24s - loss: 0.1751 - accuracy: 0.9430\n",
      "Epoch 240/1000\n",
      " - 24s - loss: 0.1419 - accuracy: 0.9563\n",
      "Epoch 241/1000\n",
      " - 24s - loss: 0.1142 - accuracy: 0.9662\n",
      "Epoch 242/1000\n",
      " - 24s - loss: 0.1571 - accuracy: 0.9488\n",
      "Epoch 243/1000\n",
      " - 24s - loss: 0.1654 - accuracy: 0.9455\n",
      "Epoch 244/1000\n",
      " - 24s - loss: 0.1283 - accuracy: 0.9599\n",
      "Epoch 245/1000\n",
      " - 24s - loss: 0.1896 - accuracy: 0.9372\n",
      "Epoch 246/1000\n",
      " - 24s - loss: 0.1072 - accuracy: 0.9685\n",
      "Epoch 247/1000\n",
      " - 24s - loss: 0.1191 - accuracy: 0.9640\n",
      "Epoch 248/1000\n",
      " - 24s - loss: 0.1700 - accuracy: 0.9453\n",
      "Epoch 249/1000\n",
      " - 24s - loss: 0.1658 - accuracy: 0.9457\n",
      "Epoch 250/1000\n",
      " - 24s - loss: 0.1058 - accuracy: 0.9686\n",
      "Epoch 251/1000\n",
      " - 24s - loss: 0.1336 - accuracy: 0.9576\n",
      "Epoch 252/1000\n",
      " - 24s - loss: 0.1631 - accuracy: 0.9454\n",
      "Epoch 253/1000\n",
      " - 24s - loss: 0.1484 - accuracy: 0.9524\n",
      "Epoch 254/1000\n",
      " - 24s - loss: 0.1171 - accuracy: 0.9643\n",
      "Epoch 255/1000\n",
      " - 24s - loss: 0.1473 - accuracy: 0.9513\n",
      "Epoch 256/1000\n",
      " - 24s - loss: 0.1638 - accuracy: 0.9453\n",
      "Epoch 257/1000\n",
      " - 24s - loss: 0.1186 - accuracy: 0.9624\n",
      "Epoch 258/1000\n",
      " - 24s - loss: 0.1463 - accuracy: 0.9516\n",
      "Epoch 259/1000\n",
      " - 24s - loss: 0.1663 - accuracy: 0.9459\n",
      "Epoch 260/1000\n",
      " - 24s - loss: 0.1514 - accuracy: 0.9517\n",
      "Epoch 261/1000\n",
      " - 24s - loss: 0.1009 - accuracy: 0.9712\n",
      "Epoch 262/1000\n",
      " - 24s - loss: 0.1279 - accuracy: 0.9594\n",
      "Epoch 263/1000\n",
      " - 24s - loss: 0.1848 - accuracy: 0.9379\n",
      "Epoch 264/1000\n",
      " - 24s - loss: 0.1209 - accuracy: 0.9627\n",
      "Epoch 265/1000\n",
      " - 24s - loss: 0.1145 - accuracy: 0.9643\n",
      "Epoch 266/1000\n",
      " - 24s - loss: 0.1631 - accuracy: 0.9456\n",
      "Epoch 267/1000\n",
      " - 24s - loss: 0.1418 - accuracy: 0.9538\n",
      "Epoch 268/1000\n",
      " - 24s - loss: 0.1026 - accuracy: 0.9702\n",
      "Epoch 269/1000\n",
      " - 24s - loss: 0.1568 - accuracy: 0.9485\n",
      "Epoch 270/1000\n",
      " - 24s - loss: 0.1392 - accuracy: 0.9548\n",
      "Epoch 271/1000\n",
      " - 24s - loss: 0.1202 - accuracy: 0.9628\n",
      "Epoch 272/1000\n",
      " - 24s - loss: 0.1322 - accuracy: 0.9575\n",
      "Epoch 273/1000\n",
      " - 24s - loss: 0.1943 - accuracy: 0.9349\n",
      "Epoch 274/1000\n",
      " - 24s - loss: 0.1081 - accuracy: 0.9674\n",
      "Epoch 275/1000\n",
      " - 24s - loss: 0.1200 - accuracy: 0.9628\n",
      "Epoch 276/1000\n",
      " - 24s - loss: 0.1366 - accuracy: 0.9562\n",
      "Epoch 277/1000\n",
      " - 24s - loss: 0.1307 - accuracy: 0.9603\n",
      "Epoch 278/1000\n",
      " - 24s - loss: 0.1235 - accuracy: 0.9615\n",
      "Epoch 279/1000\n",
      " - 24s - loss: 0.1583 - accuracy: 0.9468\n",
      "Epoch 280/1000\n",
      " - 24s - loss: 0.1268 - accuracy: 0.9598\n",
      "Epoch 281/1000\n",
      " - 24s - loss: 0.1195 - accuracy: 0.9623\n",
      "Epoch 282/1000\n",
      " - 24s - loss: 0.1385 - accuracy: 0.9557\n",
      "Epoch 283/1000\n",
      " - 24s - loss: 0.1555 - accuracy: 0.9482\n",
      "Epoch 284/1000\n",
      " - 24s - loss: 0.1232 - accuracy: 0.9597\n",
      "Epoch 285/1000\n",
      " - 24s - loss: 0.0959 - accuracy: 0.9712\n",
      "Epoch 286/1000\n",
      " - 24s - loss: 0.1367 - accuracy: 0.9552\n",
      "Epoch 287/1000\n",
      " - 24s - loss: 0.1677 - accuracy: 0.9444\n",
      "Epoch 288/1000\n",
      " - 24s - loss: 0.1210 - accuracy: 0.9616\n",
      "Epoch 289/1000\n",
      " - 24s - loss: 0.1139 - accuracy: 0.9647\n",
      "Epoch 290/1000\n",
      " - 24s - loss: 0.1479 - accuracy: 0.9530\n",
      "Epoch 291/1000\n",
      " - 24s - loss: 0.1164 - accuracy: 0.9628\n",
      "Epoch 292/1000\n",
      " - 24s - loss: 0.1208 - accuracy: 0.9609\n",
      "Epoch 293/1000\n",
      " - 24s - loss: 0.1571 - accuracy: 0.9479\n",
      "Epoch 294/1000\n",
      " - 24s - loss: 0.1313 - accuracy: 0.9572\n",
      "Epoch 295/1000\n",
      " - 24s - loss: 0.1004 - accuracy: 0.9684\n",
      "Epoch 296/1000\n",
      " - 24s - loss: 0.1392 - accuracy: 0.9556\n",
      "Epoch 297/1000\n",
      " - 24s - loss: 0.1621 - accuracy: 0.9456\n",
      "Epoch 298/1000\n",
      " - 24s - loss: 0.1154 - accuracy: 0.9647\n",
      "Epoch 299/1000\n",
      " - 24s - loss: 0.1184 - accuracy: 0.9632\n",
      "Epoch 300/1000\n",
      " - 24s - loss: 0.1572 - accuracy: 0.9474\n",
      "Epoch 301/1000\n",
      " - 24s - loss: 0.1262 - accuracy: 0.9597\n",
      "\n",
      "----- Generating text after Epoch: 300\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"writeabove a mortal pitch that struck me\"\n",
      "writeabove a mortal pitch that struck me dearnaf may the dowh dreffre dith days cometit to a ytend caust belith dithites firs to wit were as not grold thy breastithougant when my blaod in hacthand age my grain and thee your thou thy self thee boby naterndne elremase leaknong and his his crucht comet it as thou are to me a caull what do worght i would say me bentle reasoms saye thing is thy othar whose shall what you ar my love that they\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"writeabove a mortal pitch that struck me\"\n",
      "writeabove a mortal pitch that struck me dearnalest come it sweetthe murbe or there for and thinh and blindss as thy sweet theme by own hil kells for my grain thy beauty shall thy beauty be suble to suce eyes but distins eye her fair for canne in by eyear being freenthe ampeting aguts oot sweet self porrough thou art forsh wombs oot deservel the stayso in thy self all thoughts hollt heaven fayshin time threefope my wrieking didwart a pa\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"writeabove a mortal pitch that struck me\"\n",
      "writeabove a mortal pitch that struck mest wordts to with thou art fall tion suns though to jot sied endmed former by and courtand bomade asmecaion hath the down ake the world not to let give threefore forgefor atnot thou art stratges his thy saghtshor she thuse forthing of my pay thy self wormse died to agatith did maystand dear my song eyesh priding nitelaking acce my refiedthe onced to staterin caunce timethy long thoughts ouly fair \n",
      "Epoch 302/1000\n",
      " - 24s - loss: 0.1134 - accuracy: 0.9653\n",
      "Epoch 303/1000\n",
      " - 24s - loss: 0.1094 - accuracy: 0.9669\n",
      "Epoch 304/1000\n",
      " - 24s - loss: 0.1381 - accuracy: 0.9545\n",
      "Epoch 305/1000\n",
      " - 24s - loss: 0.1397 - accuracy: 0.9540\n",
      "Epoch 306/1000\n",
      " - 24s - loss: 0.1264 - accuracy: 0.9595\n",
      "Epoch 307/1000\n",
      " - 24s - loss: 0.1096 - accuracy: 0.9659\n",
      "Epoch 308/1000\n",
      " - 24s - loss: 0.1248 - accuracy: 0.9603\n",
      "Epoch 309/1000\n",
      " - 24s - loss: 0.1401 - accuracy: 0.9543\n",
      "Epoch 310/1000\n",
      " - 24s - loss: 0.1543 - accuracy: 0.9491\n",
      "Epoch 311/1000\n",
      " - 24s - loss: 0.0937 - accuracy: 0.9720\n",
      "Epoch 312/1000\n",
      " - 24s - loss: 0.1115 - accuracy: 0.9644\n",
      "Epoch 313/1000\n",
      " - 24s - loss: 0.1359 - accuracy: 0.9571\n",
      "Epoch 314/1000\n",
      " - 24s - loss: 0.1271 - accuracy: 0.9582\n",
      "Epoch 315/1000\n",
      " - 24s - loss: 0.1346 - accuracy: 0.9559\n",
      "Epoch 316/1000\n",
      " - 24s - loss: 0.1451 - accuracy: 0.9518\n",
      "Epoch 317/1000\n",
      " - 24s - loss: 0.0932 - accuracy: 0.9721\n",
      "Epoch 318/1000\n",
      " - 24s - loss: 0.1113 - accuracy: 0.9645\n",
      "Epoch 319/1000\n",
      " - 24s - loss: 0.1287 - accuracy: 0.9588\n",
      "Epoch 320/1000\n",
      " - 24s - loss: 0.1434 - accuracy: 0.9539\n",
      "Epoch 321/1000\n",
      " - 24s - loss: 0.1230 - accuracy: 0.9599\n",
      "Epoch 322/1000\n",
      " - 24s - loss: 0.1028 - accuracy: 0.9682\n",
      "Epoch 323/1000\n",
      " - 24s - loss: 0.1185 - accuracy: 0.9619\n",
      "Epoch 324/1000\n",
      " - 24s - loss: 0.1192 - accuracy: 0.9613\n",
      "Epoch 325/1000\n",
      " - 24s - loss: 0.1373 - accuracy: 0.9543\n",
      "Epoch 326/1000\n",
      " - 24s - loss: 0.1187 - accuracy: 0.9619\n",
      "Epoch 327/1000\n",
      " - 24s - loss: 0.1172 - accuracy: 0.9622\n",
      "Epoch 328/1000\n",
      " - 24s - loss: 0.1219 - accuracy: 0.9601\n",
      "Epoch 329/1000\n",
      " - 24s - loss: 0.1361 - accuracy: 0.9554\n",
      "Epoch 330/1000\n",
      " - 24s - loss: 0.1118 - accuracy: 0.9646\n",
      "Epoch 331/1000\n",
      " - 24s - loss: 0.0991 - accuracy: 0.9690\n",
      "Epoch 332/1000\n",
      " - 24s - loss: 0.1347 - accuracy: 0.9566\n",
      "Epoch 333/1000\n",
      " - 25s - loss: 0.1190 - accuracy: 0.9608\n",
      "Epoch 334/1000\n",
      " - 24s - loss: 0.1089 - accuracy: 0.9658\n",
      "Epoch 335/1000\n",
      " - 24s - loss: 0.1251 - accuracy: 0.9586\n",
      "Epoch 336/1000\n",
      " - 24s - loss: 0.1201 - accuracy: 0.9620\n",
      "Epoch 337/1000\n",
      " - 24s - loss: 0.1176 - accuracy: 0.9611\n",
      "Epoch 338/1000\n",
      " - 24s - loss: 0.1354 - accuracy: 0.9553\n",
      "Epoch 339/1000\n",
      " - 27s - loss: 0.1087 - accuracy: 0.9652\n",
      "Epoch 340/1000\n",
      " - 24s - loss: 0.0916 - accuracy: 0.9719\n",
      "Epoch 341/1000\n",
      " - 27s - loss: 0.1304 - accuracy: 0.9586\n",
      "Epoch 342/1000\n",
      " - 26s - loss: 0.1509 - accuracy: 0.9501\n",
      "Epoch 343/1000\n",
      " - 26s - loss: 0.1123 - accuracy: 0.9646\n",
      "Epoch 344/1000\n",
      " - 26s - loss: 0.0900 - accuracy: 0.9730\n",
      "Epoch 345/1000\n",
      " - 24s - loss: 0.1357 - accuracy: 0.9562\n",
      "Epoch 346/1000\n",
      " - 24s - loss: 0.1417 - accuracy: 0.9533\n",
      "Epoch 347/1000\n",
      " - 24s - loss: 0.1044 - accuracy: 0.9668\n",
      "Epoch 348/1000\n",
      " - 25s - loss: 0.0990 - accuracy: 0.9693\n",
      "Epoch 349/1000\n",
      " - 24s - loss: 0.1267 - accuracy: 0.9594\n",
      "Epoch 350/1000\n",
      " - 24s - loss: 0.1313 - accuracy: 0.9567\n",
      "Epoch 351/1000\n",
      " - 24s - loss: 0.1166 - accuracy: 0.9626\n",
      "Epoch 352/1000\n",
      " - 24s - loss: 0.1070 - accuracy: 0.9657\n",
      "Epoch 353/1000\n",
      " - 24s - loss: 0.1151 - accuracy: 0.9638\n",
      "Epoch 354/1000\n",
      " - 24s - loss: 0.1191 - accuracy: 0.9626\n",
      "Epoch 355/1000\n",
      " - 24s - loss: 0.1455 - accuracy: 0.9530\n",
      "Epoch 356/1000\n",
      " - 24s - loss: 0.0984 - accuracy: 0.9695\n",
      "Epoch 357/1000\n",
      " - 24s - loss: 0.0935 - accuracy: 0.9705\n",
      "Epoch 358/1000\n",
      " - 24s - loss: 0.1723 - accuracy: 0.9428\n",
      "Epoch 359/1000\n",
      " - 24s - loss: 0.0963 - accuracy: 0.9699\n",
      "Epoch 360/1000\n",
      " - 24s - loss: 0.0962 - accuracy: 0.9707\n",
      "Epoch 361/1000\n",
      " - 24s - loss: 0.1348 - accuracy: 0.9557\n",
      "Epoch 362/1000\n",
      " - 24s - loss: 0.1227 - accuracy: 0.9599\n",
      "Epoch 363/1000\n",
      " - 25s - loss: 0.1191 - accuracy: 0.9606\n",
      "Epoch 364/1000\n",
      " - 24s - loss: 0.1147 - accuracy: 0.9633\n",
      "Epoch 365/1000\n",
      " - 24s - loss: 0.0997 - accuracy: 0.9699\n",
      "Epoch 366/1000\n",
      " - 24s - loss: 0.1188 - accuracy: 0.9605\n",
      "Epoch 367/1000\n",
      " - 24s - loss: 0.1347 - accuracy: 0.9557\n",
      "Epoch 368/1000\n",
      " - 24s - loss: 0.1156 - accuracy: 0.9617\n",
      "Epoch 369/1000\n",
      " - 24s - loss: 0.0932 - accuracy: 0.9716\n",
      "Epoch 370/1000\n",
      " - 24s - loss: 0.1229 - accuracy: 0.9600\n",
      "Epoch 371/1000\n",
      " - 24s - loss: 0.1128 - accuracy: 0.9640\n",
      "Epoch 372/1000\n",
      " - 24s - loss: 0.1094 - accuracy: 0.9649\n",
      "Epoch 373/1000\n",
      " - 24s - loss: 0.1097 - accuracy: 0.9645\n",
      "Epoch 374/1000\n",
      " - 24s - loss: 0.1458 - accuracy: 0.9533\n",
      "Epoch 375/1000\n",
      " - 24s - loss: 0.0972 - accuracy: 0.9690\n",
      "Epoch 376/1000\n",
      " - 24s - loss: 0.1093 - accuracy: 0.9657\n",
      "Epoch 377/1000\n",
      " - 24s - loss: 0.1071 - accuracy: 0.9660\n",
      "Epoch 378/1000\n",
      " - 24s - loss: 0.1113 - accuracy: 0.9648\n",
      "Epoch 379/1000\n",
      " - 24s - loss: 0.1250 - accuracy: 0.9586\n",
      "Epoch 380/1000\n",
      " - 24s - loss: 0.1555 - accuracy: 0.9481\n",
      "Epoch 381/1000\n",
      " - 24s - loss: 0.0933 - accuracy: 0.9706\n",
      "Epoch 382/1000\n",
      " - 24s - loss: 0.0703 - accuracy: 0.9788\n",
      "Epoch 383/1000\n",
      " - 24s - loss: 0.1359 - accuracy: 0.9571\n",
      "Epoch 384/1000\n",
      " - 24s - loss: 0.1504 - accuracy: 0.9504\n",
      "Epoch 385/1000\n",
      " - 24s - loss: 0.0920 - accuracy: 0.9712\n",
      "Epoch 386/1000\n",
      " - 24s - loss: 0.0888 - accuracy: 0.9735\n",
      "Epoch 387/1000\n",
      " - 24s - loss: 0.1541 - accuracy: 0.9490\n",
      "Epoch 388/1000\n",
      " - 24s - loss: 0.0916 - accuracy: 0.9724\n",
      "Epoch 389/1000\n",
      " - 24s - loss: 0.0934 - accuracy: 0.9714\n",
      "Epoch 390/1000\n",
      " - 24s - loss: 0.1168 - accuracy: 0.9613\n",
      "Epoch 391/1000\n",
      " - 24s - loss: 0.1379 - accuracy: 0.9540\n",
      "Epoch 392/1000\n",
      " - 24s - loss: 0.1152 - accuracy: 0.9614\n",
      "Epoch 393/1000\n",
      " - 24s - loss: 0.1126 - accuracy: 0.9633\n",
      "Epoch 394/1000\n",
      " - 24s - loss: 0.1621 - accuracy: 0.9469\n",
      "Epoch 395/1000\n",
      " - 24s - loss: 0.0712 - accuracy: 0.9798\n",
      "Epoch 396/1000\n",
      " - 24s - loss: 0.0686 - accuracy: 0.9805\n",
      "Epoch 397/1000\n",
      " - 24s - loss: 0.1589 - accuracy: 0.9459\n",
      "Epoch 398/1000\n",
      " - 24s - loss: 0.1357 - accuracy: 0.9557\n",
      "Epoch 399/1000\n",
      " - 24s - loss: 0.0926 - accuracy: 0.9711\n",
      "Epoch 400/1000\n",
      " - 24s - loss: 0.1253 - accuracy: 0.9586\n",
      "Epoch 401/1000\n",
      " - 24s - loss: 0.0898 - accuracy: 0.9728\n",
      "\n",
      "----- Generating text after Epoch: 400\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"t me quitefor you in me can nothing wort\"\n",
      "t me quitefor you in me can nothing worth both mine eye to bitwhen but the fairtwey mutht the hes by awfors orefonges that pallt gace were vorghand dearrymost all me me dowh die poortand their i notrsel bland and then by thy breast thy blesthin bounti sacks and thy self all the groustape thrife on thee when holl three poor his aware to mise and so me unfored on my praise dethin the thoughts when to the besime of my blesst thy love be of\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"t me quitefor you in me can nothing wort\"\n",
      "t me quitefor you in me can nothing worthspreng lies the cuntas thich shall fall giol see that thou maching of agassto ramale budnot ance that writ i thou art varges doth is me dis cringabe now he worls for my sont when thing eyes but deseives for unifeed the pendle dood illyour earth distell reasomy wort stanl guitto ourand himead the wrom this trays thy blambhto die fornsthy kingwhose all me out distile not blesse rymas that now dith \n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"t me quitefor you in me can nothing wort\"\n",
      "t me quitefor you in me can nothing worth bebut him may the breses wear more and this a fairfle pairabe virwhen i maty eict lot giest me spolet coonfringand thay sind where tood and chong to griceated houn hatherlest by timestideto previngand dowh not tay see world i varand loves mo degrineshulf and invanymo chapl overss you like eyel bettand astend anters be wike what should me more sweet respoitt the stresed though venss dith thee ald\n",
      "Epoch 402/1000\n",
      " - 24s - loss: 0.1055 - accuracy: 0.9669\n",
      "Epoch 403/1000\n",
      " - 24s - loss: 0.1352 - accuracy: 0.9556\n",
      "Epoch 404/1000\n",
      " - 24s - loss: 0.1082 - accuracy: 0.9660\n",
      "Epoch 405/1000\n",
      " - 24s - loss: 0.0967 - accuracy: 0.9695\n",
      "Epoch 406/1000\n",
      " - 24s - loss: 0.1453 - accuracy: 0.9509\n",
      "Epoch 407/1000\n",
      " - 24s - loss: 0.0882 - accuracy: 0.9729\n",
      "Epoch 408/1000\n",
      " - 24s - loss: 0.0971 - accuracy: 0.9693\n",
      "Epoch 409/1000\n",
      " - 24s - loss: 0.1255 - accuracy: 0.9592\n",
      "Epoch 410/1000\n",
      " - 24s - loss: 0.1117 - accuracy: 0.9637\n",
      "Epoch 411/1000\n",
      " - 24s - loss: 0.0905 - accuracy: 0.9720\n",
      "Epoch 412/1000\n",
      " - 24s - loss: 0.0914 - accuracy: 0.9714\n",
      "Epoch 413/1000\n",
      " - 24s - loss: 0.1481 - accuracy: 0.9505\n",
      "Epoch 414/1000\n",
      " - 24s - loss: 0.1129 - accuracy: 0.9632\n",
      "Epoch 415/1000\n",
      " - 24s - loss: 0.0912 - accuracy: 0.9719\n",
      "Epoch 416/1000\n",
      " - 24s - loss: 0.1044 - accuracy: 0.9665\n",
      "Epoch 417/1000\n",
      " - 24s - loss: 0.1145 - accuracy: 0.9626\n",
      "Epoch 418/1000\n",
      " - 24s - loss: 0.0976 - accuracy: 0.9683\n",
      "Epoch 419/1000\n",
      " - 24s - loss: 0.1094 - accuracy: 0.9644\n",
      "Epoch 420/1000\n",
      " - 24s - loss: 0.1089 - accuracy: 0.9664\n",
      "Epoch 421/1000\n",
      " - 24s - loss: 0.1102 - accuracy: 0.9650\n",
      "Epoch 422/1000\n",
      " - 24s - loss: 0.1100 - accuracy: 0.9637\n",
      "Epoch 423/1000\n",
      " - 24s - loss: 0.0995 - accuracy: 0.9688\n",
      "Epoch 424/1000\n",
      " - 24s - loss: 0.1108 - accuracy: 0.9638\n",
      "Epoch 425/1000\n",
      " - 24s - loss: 0.0993 - accuracy: 0.9683\n",
      "Epoch 426/1000\n",
      " - 24s - loss: 0.1065 - accuracy: 0.9655\n",
      "Epoch 427/1000\n",
      " - 24s - loss: 0.1160 - accuracy: 0.9625\n",
      "Epoch 428/1000\n",
      " - 24s - loss: 0.1062 - accuracy: 0.9665\n",
      "Epoch 429/1000\n",
      " - 24s - loss: 0.0895 - accuracy: 0.9727\n",
      "Epoch 430/1000\n",
      " - 24s - loss: 0.1028 - accuracy: 0.9663\n",
      "Epoch 431/1000\n",
      " - 24s - loss: 0.0960 - accuracy: 0.9697\n",
      "Epoch 432/1000\n",
      " - 24s - loss: 0.0984 - accuracy: 0.9688\n",
      "Epoch 433/1000\n",
      " - 24s - loss: 0.1232 - accuracy: 0.9592\n",
      "Epoch 434/1000\n",
      " - 24s - loss: 0.1037 - accuracy: 0.9677\n",
      "Epoch 435/1000\n",
      " - 24s - loss: 0.0852 - accuracy: 0.9732\n",
      "Epoch 436/1000\n",
      " - 24s - loss: 0.1325 - accuracy: 0.9564\n",
      "Epoch 437/1000\n",
      " - 24s - loss: 0.0949 - accuracy: 0.9691\n",
      "Epoch 438/1000\n",
      " - 24s - loss: 0.0804 - accuracy: 0.9760\n",
      "Epoch 439/1000\n",
      " - 25s - loss: 0.1324 - accuracy: 0.9558\n",
      "Epoch 440/1000\n",
      " - 24s - loss: 0.1104 - accuracy: 0.9632\n",
      "Epoch 441/1000\n",
      " - 24s - loss: 0.1142 - accuracy: 0.9630\n",
      "Epoch 442/1000\n",
      " - 24s - loss: 0.0904 - accuracy: 0.9714\n",
      "Epoch 443/1000\n",
      " - 24s - loss: 0.0857 - accuracy: 0.9724\n",
      "Epoch 444/1000\n",
      " - 24s - loss: 0.0988 - accuracy: 0.9680\n",
      "Epoch 445/1000\n",
      " - 24s - loss: 0.1067 - accuracy: 0.9643\n",
      "Epoch 446/1000\n",
      " - 24s - loss: 0.1110 - accuracy: 0.9643\n",
      "Epoch 447/1000\n",
      " - 24s - loss: 0.1044 - accuracy: 0.9665\n",
      "Epoch 448/1000\n",
      " - 24s - loss: 0.0886 - accuracy: 0.9724\n",
      "Epoch 449/1000\n",
      " - 24s - loss: 0.0936 - accuracy: 0.9720\n",
      "Epoch 450/1000\n",
      " - 24s - loss: 0.1429 - accuracy: 0.9529\n",
      "Epoch 451/1000\n",
      " - 24s - loss: 0.1130 - accuracy: 0.9622\n",
      "Epoch 452/1000\n",
      " - 25s - loss: 0.0613 - accuracy: 0.9822\n",
      "Epoch 453/1000\n",
      " - 24s - loss: 0.1188 - accuracy: 0.9617\n",
      "Epoch 454/1000\n",
      " - 24s - loss: 0.1317 - accuracy: 0.9574\n",
      "Epoch 455/1000\n",
      " - 24s - loss: 0.0849 - accuracy: 0.9745\n",
      "Epoch 456/1000\n",
      " - 24s - loss: 0.0856 - accuracy: 0.9728\n",
      "Epoch 457/1000\n",
      " - 24s - loss: 0.1729 - accuracy: 0.9423\n",
      "Epoch 458/1000\n",
      " - 24s - loss: 0.0768 - accuracy: 0.9771\n",
      "Epoch 459/1000\n",
      " - 24s - loss: 0.0900 - accuracy: 0.9720\n",
      "Epoch 460/1000\n",
      " - 24s - loss: 0.1095 - accuracy: 0.9652\n",
      "Epoch 461/1000\n",
      " - 24s - loss: 0.1252 - accuracy: 0.9589\n",
      "Epoch 462/1000\n",
      " - 24s - loss: 0.0937 - accuracy: 0.9699\n",
      "Epoch 463/1000\n",
      " - 24s - loss: 0.0751 - accuracy: 0.9782\n",
      "Epoch 464/1000\n",
      " - 26s - loss: 0.1045 - accuracy: 0.9656\n",
      "Epoch 465/1000\n",
      " - 25s - loss: 0.1255 - accuracy: 0.9586\n",
      "Epoch 466/1000\n",
      " - 25s - loss: 0.1010 - accuracy: 0.9676\n",
      "Epoch 467/1000\n",
      " - 26s - loss: 0.0876 - accuracy: 0.9733\n",
      "Epoch 468/1000\n",
      " - 25s - loss: 0.1017 - accuracy: 0.9689\n",
      "Epoch 469/1000\n",
      " - 26s - loss: 0.1037 - accuracy: 0.9659\n",
      "Epoch 470/1000\n",
      " - 25s - loss: 0.1083 - accuracy: 0.9654\n",
      "Epoch 471/1000\n",
      " - 26s - loss: 0.0995 - accuracy: 0.9681\n",
      "Epoch 472/1000\n",
      " - 26s - loss: 0.1138 - accuracy: 0.9635\n",
      "Epoch 473/1000\n",
      " - 26s - loss: 0.1001 - accuracy: 0.9675\n",
      "Epoch 474/1000\n",
      " - 28s - loss: 0.1056 - accuracy: 0.9655\n",
      "Epoch 475/1000\n",
      " - 28s - loss: 0.0730 - accuracy: 0.9783\n",
      "Epoch 476/1000\n",
      " - 25s - loss: 0.1129 - accuracy: 0.9637\n",
      "Epoch 477/1000\n",
      " - 28s - loss: 0.1215 - accuracy: 0.9593\n",
      "Epoch 478/1000\n",
      " - 26s - loss: 0.0962 - accuracy: 0.9687\n",
      "Epoch 479/1000\n",
      " - 25s - loss: 0.0730 - accuracy: 0.9787\n",
      "Epoch 480/1000\n",
      " - 25s - loss: 0.1115 - accuracy: 0.9636\n",
      "Epoch 481/1000\n",
      " - 29s - loss: 0.1249 - accuracy: 0.9599\n",
      "Epoch 482/1000\n",
      " - 30s - loss: 0.1047 - accuracy: 0.9670\n",
      "Epoch 483/1000\n",
      " - 27s - loss: 0.0846 - accuracy: 0.9738\n",
      "Epoch 484/1000\n",
      " - 27s - loss: 0.0939 - accuracy: 0.9702\n",
      "Epoch 485/1000\n",
      " - 25s - loss: 0.0966 - accuracy: 0.9695\n",
      "Epoch 486/1000\n",
      " - 26s - loss: 0.1143 - accuracy: 0.9625\n",
      "Epoch 487/1000\n",
      " - 27s - loss: 0.0785 - accuracy: 0.9756\n",
      "Epoch 488/1000\n",
      " - 27s - loss: 0.1094 - accuracy: 0.9644\n",
      "Epoch 489/1000\n",
      " - 24s - loss: 0.1031 - accuracy: 0.9666\n",
      "Epoch 490/1000\n",
      " - 24s - loss: 0.0973 - accuracy: 0.9683\n",
      "Epoch 491/1000\n",
      " - 24s - loss: 0.0802 - accuracy: 0.9744\n",
      "Epoch 492/1000\n",
      " - 24s - loss: 0.1082 - accuracy: 0.9645\n",
      "Epoch 493/1000\n",
      " - 24s - loss: 0.1222 - accuracy: 0.9595\n",
      "Epoch 494/1000\n",
      " - 24s - loss: 0.0793 - accuracy: 0.9753\n",
      "Epoch 495/1000\n",
      " - 24s - loss: 0.0719 - accuracy: 0.9778\n",
      "Epoch 496/1000\n",
      " - 24s - loss: 0.1186 - accuracy: 0.9592\n",
      "Epoch 497/1000\n",
      " - 24s - loss: 0.1336 - accuracy: 0.9562\n",
      "Epoch 498/1000\n",
      " - 24s - loss: 0.0831 - accuracy: 0.9739\n",
      "Epoch 499/1000\n",
      " - 24s - loss: 0.0830 - accuracy: 0.9749\n",
      "Epoch 500/1000\n",
      " - 24s - loss: 0.0772 - accuracy: 0.9765\n",
      "Epoch 501/1000\n",
      " - 24s - loss: 0.1055 - accuracy: 0.9661\n",
      "\n",
      "----- Generating text after Epoch: 500\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"ou mayst be false and yet i know it not \"\n",
      "ou mayst be false and yet i know it not so mure more deepor of neethe canges denweceive thee awaywith orenwhere fore them so then then bebut tidine the though threefor him see for of mine eye as thy beauty being fresh retoor all to ylear greewhen lookst weyeto chentthat the world me plaise not singant in my heart the lose now dith deart to ame thy sigut in thing in they have and where it not thou shalt brow canrant not i my have all the\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"ou mayst be false and yet i know it not \"\n",
      "ou mayst be false and yet i know it not so mure eotbut tiss comet hendiess worth distind as the plats and this i downers to be risedear as though truehs die for thy sould deepe pay the pless that thy self wormst is baintlege versewhen tray mine eye her all as i thou art groffore nathing tweet not makned i nave thee die not bond doth distich deceiveone when my best is deliess contowstant wanturnd im must confearsed whenl it not for then \n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"ou mayst be false and yet i know it not \"\n",
      "ou mayst be false and yet i know it not migst thing in by hang impappapent this faimuprisstyou carttand prain buhwhore love as my friend as fieds yor in eye hath earther dearwhich a consend quilt of the tise imest were commetiou adw omentidss tie sing the daythat being hen not ablinglest chuntbough thou marges dear rife bressind no way my foil as dottorand rubras belong thy hund and murie swert istites distinstitite thou sighto not tare\n",
      "Epoch 502/1000\n",
      " - 24s - loss: 0.1256 - accuracy: 0.9576\n",
      "Epoch 503/1000\n",
      " - 24s - loss: 0.0832 - accuracy: 0.9735\n",
      "Epoch 504/1000\n",
      " - 24s - loss: 0.0968 - accuracy: 0.9676\n",
      "Epoch 505/1000\n",
      " - 24s - loss: 0.1111 - accuracy: 0.9637\n",
      "Epoch 506/1000\n",
      " - 24s - loss: 0.0780 - accuracy: 0.9767\n",
      "Epoch 507/1000\n",
      " - 24s - loss: 0.0847 - accuracy: 0.9723\n",
      "Epoch 508/1000\n",
      " - 24s - loss: 0.1035 - accuracy: 0.9663\n",
      "Epoch 509/1000\n",
      " - 24s - loss: 0.1185 - accuracy: 0.9606\n",
      "Epoch 510/1000\n",
      " - 24s - loss: 0.0710 - accuracy: 0.9781\n",
      "Epoch 511/1000\n",
      " - 24s - loss: 0.0947 - accuracy: 0.9694\n",
      "Epoch 512/1000\n",
      " - 24s - loss: 0.1104 - accuracy: 0.9639\n",
      "Epoch 513/1000\n",
      " - 24s - loss: 0.0971 - accuracy: 0.9690\n",
      "Epoch 514/1000\n",
      " - 24s - loss: 0.1089 - accuracy: 0.9644\n",
      "Epoch 515/1000\n",
      " - 24s - loss: 0.0903 - accuracy: 0.9714\n",
      "Epoch 516/1000\n",
      " - 24s - loss: 0.0755 - accuracy: 0.9778\n",
      "Epoch 517/1000\n",
      " - 24s - loss: 0.1247 - accuracy: 0.9581\n",
      "Epoch 518/1000\n",
      " - 24s - loss: 0.1032 - accuracy: 0.9654\n",
      "Epoch 519/1000\n",
      " - 24s - loss: 0.0629 - accuracy: 0.9823\n",
      "Epoch 520/1000\n",
      " - 25s - loss: 0.0827 - accuracy: 0.9748\n",
      "Epoch 521/1000\n",
      " - 24s - loss: 0.1217 - accuracy: 0.9588\n",
      "Epoch 522/1000\n",
      " - 24s - loss: 0.1010 - accuracy: 0.9665\n",
      "Epoch 523/1000\n",
      " - 24s - loss: 0.0859 - accuracy: 0.9732\n",
      "Epoch 524/1000\n",
      " - 24s - loss: 0.0749 - accuracy: 0.9779\n",
      "Epoch 525/1000\n",
      " - 24s - loss: 0.1128 - accuracy: 0.9625\n",
      "Epoch 526/1000\n",
      " - 24s - loss: 0.1051 - accuracy: 0.9664\n",
      "Epoch 527/1000\n",
      " - 24s - loss: 0.0850 - accuracy: 0.9734\n",
      "Epoch 528/1000\n",
      " - 24s - loss: 0.0952 - accuracy: 0.9707\n",
      "Epoch 529/1000\n",
      " - 24s - loss: 0.0975 - accuracy: 0.9688\n",
      "Epoch 530/1000\n",
      " - 24s - loss: 0.0875 - accuracy: 0.9708\n",
      "Epoch 531/1000\n",
      " - 24s - loss: 0.0862 - accuracy: 0.9718\n",
      "Epoch 532/1000\n",
      " - 24s - loss: 0.0844 - accuracy: 0.9729\n",
      "Epoch 533/1000\n",
      " - 24s - loss: 0.1323 - accuracy: 0.9561\n",
      "Epoch 534/1000\n",
      " - 24s - loss: 0.0866 - accuracy: 0.9725\n",
      "Epoch 535/1000\n",
      " - 24s - loss: 0.0647 - accuracy: 0.9816\n",
      "Epoch 536/1000\n",
      " - 24s - loss: 0.1116 - accuracy: 0.9642\n",
      "Epoch 537/1000\n",
      " - 24s - loss: 0.1210 - accuracy: 0.9596\n",
      "Epoch 538/1000\n",
      " - 24s - loss: 0.0812 - accuracy: 0.9748\n",
      "Epoch 539/1000\n",
      " - 24s - loss: 0.0722 - accuracy: 0.9776\n",
      "Epoch 540/1000\n",
      " - 24s - loss: 0.1121 - accuracy: 0.9633\n",
      "Epoch 541/1000\n",
      " - 24s - loss: 0.1059 - accuracy: 0.9648\n",
      "Epoch 542/1000\n",
      " - 24s - loss: 0.0719 - accuracy: 0.9783\n",
      "Epoch 543/1000\n",
      " - 24s - loss: 0.1014 - accuracy: 0.9670\n",
      "Epoch 544/1000\n",
      " - 24s - loss: 0.0858 - accuracy: 0.9732\n",
      "Epoch 545/1000\n",
      " - 24s - loss: 0.0874 - accuracy: 0.9724\n",
      "Epoch 546/1000\n",
      " - 24s - loss: 0.1099 - accuracy: 0.9637\n",
      "Epoch 547/1000\n",
      " - 24s - loss: 0.0937 - accuracy: 0.9705\n",
      "Epoch 548/1000\n",
      " - 24s - loss: 0.0758 - accuracy: 0.9758\n",
      "Epoch 549/1000\n",
      " - 24s - loss: 0.0889 - accuracy: 0.9713\n",
      "Epoch 550/1000\n",
      " - 24s - loss: 0.1136 - accuracy: 0.9624\n",
      "Epoch 551/1000\n",
      " - 24s - loss: 0.0920 - accuracy: 0.9702\n",
      "Epoch 552/1000\n",
      " - 24s - loss: 0.0701 - accuracy: 0.9780\n",
      "Epoch 553/1000\n",
      " - 24s - loss: 0.1002 - accuracy: 0.9670\n",
      "Epoch 554/1000\n",
      " - 24s - loss: 0.1169 - accuracy: 0.9630\n",
      "Epoch 555/1000\n",
      " - 24s - loss: 0.0938 - accuracy: 0.9696\n",
      "Epoch 556/1000\n",
      " - 24s - loss: 0.0526 - accuracy: 0.9855\n",
      "Epoch 557/1000\n",
      " - 24s - loss: 0.0687 - accuracy: 0.9796\n",
      "Epoch 558/1000\n",
      " - 24s - loss: 0.1755 - accuracy: 0.9410\n",
      "Epoch 559/1000\n",
      " - 24s - loss: 0.0840 - accuracy: 0.9733\n",
      "Epoch 560/1000\n",
      " - 24s - loss: 0.0520 - accuracy: 0.9854\n",
      "Epoch 561/1000\n",
      " - 24s - loss: 0.0884 - accuracy: 0.9717\n",
      "Epoch 562/1000\n",
      " - 24s - loss: 0.1607 - accuracy: 0.9471\n",
      "Epoch 563/1000\n",
      " - 24s - loss: 0.0852 - accuracy: 0.9740\n",
      "Epoch 564/1000\n",
      " - 24s - loss: 0.0751 - accuracy: 0.9764\n",
      "Epoch 565/1000\n",
      " - 24s - loss: 0.0911 - accuracy: 0.9702\n",
      "Epoch 566/1000\n",
      " - 24s - loss: 0.0958 - accuracy: 0.9689\n",
      "Epoch 567/1000\n",
      " - 24s - loss: 0.0943 - accuracy: 0.9686\n",
      "Epoch 568/1000\n",
      " - 24s - loss: 0.0707 - accuracy: 0.9781\n",
      "Epoch 569/1000\n",
      " - 24s - loss: 0.0909 - accuracy: 0.9706\n",
      "Epoch 570/1000\n",
      " - 24s - loss: 0.1136 - accuracy: 0.9633\n",
      "Epoch 571/1000\n",
      " - 24s - loss: 0.0926 - accuracy: 0.9699\n",
      "Epoch 572/1000\n",
      " - 24s - loss: 0.0616 - accuracy: 0.9807\n",
      "Epoch 573/1000\n",
      " - 24s - loss: 0.0884 - accuracy: 0.9723\n",
      "Epoch 574/1000\n",
      " - 24s - loss: 0.1382 - accuracy: 0.9538\n",
      "Epoch 575/1000\n",
      " - 24s - loss: 0.0863 - accuracy: 0.9733\n",
      "Epoch 576/1000\n",
      " - 24s - loss: 0.0667 - accuracy: 0.9799\n",
      "Epoch 577/1000\n",
      " - 24s - loss: 0.0828 - accuracy: 0.9736\n",
      "Epoch 578/1000\n",
      " - 24s - loss: 0.0980 - accuracy: 0.9684\n",
      "Epoch 579/1000\n",
      " - 24s - loss: 0.1030 - accuracy: 0.9668\n",
      "Epoch 580/1000\n",
      " - 24s - loss: 0.0947 - accuracy: 0.9703\n",
      "Epoch 581/1000\n",
      " - 24s - loss: 0.0687 - accuracy: 0.9787\n",
      "Epoch 582/1000\n",
      " - 24s - loss: 0.1051 - accuracy: 0.9655\n",
      "Epoch 583/1000\n",
      " - 24s - loss: 0.1012 - accuracy: 0.9672\n",
      "Epoch 584/1000\n",
      " - 24s - loss: 0.0812 - accuracy: 0.9735\n",
      "Epoch 585/1000\n",
      " - 24s - loss: 0.0739 - accuracy: 0.9778\n",
      "Epoch 586/1000\n",
      " - 24s - loss: 0.0812 - accuracy: 0.9752\n",
      "Epoch 587/1000\n",
      " - 24s - loss: 0.1149 - accuracy: 0.9610\n",
      "Epoch 588/1000\n",
      " - 24s - loss: 0.0818 - accuracy: 0.9742\n",
      "Epoch 589/1000\n",
      " - 24s - loss: 0.0750 - accuracy: 0.9766\n",
      "Epoch 590/1000\n",
      " - 24s - loss: 0.0951 - accuracy: 0.9691\n",
      "Epoch 591/1000\n",
      " - 24s - loss: 0.0947 - accuracy: 0.9693\n",
      "Epoch 592/1000\n",
      " - 24s - loss: 0.0793 - accuracy: 0.9748\n",
      "Epoch 593/1000\n",
      " - 24s - loss: 0.0775 - accuracy: 0.9754\n",
      "Epoch 594/1000\n",
      " - 24s - loss: 0.1066 - accuracy: 0.9647\n",
      "Epoch 595/1000\n",
      " - 24s - loss: 0.0958 - accuracy: 0.9682\n",
      "Epoch 596/1000\n",
      " - 24s - loss: 0.0687 - accuracy: 0.9787\n",
      "Epoch 597/1000\n",
      " - 24s - loss: 0.0827 - accuracy: 0.9731\n",
      "Epoch 598/1000\n",
      " - 24s - loss: 0.1101 - accuracy: 0.9646\n",
      "Epoch 599/1000\n",
      " - 24s - loss: 0.0705 - accuracy: 0.9786\n",
      "Epoch 600/1000\n",
      " - 24s - loss: 0.0719 - accuracy: 0.9781\n",
      "Epoch 601/1000\n",
      " - 24s - loss: 0.0989 - accuracy: 0.9674\n",
      "\n",
      "----- Generating text after Epoch: 600\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"that thou mayst have thy will if thou tu\"\n",
      "that thou mayst have thy will if thou tushin is for and illforr is truesith of thy diedfor cruel with thee as thy beauty shall the sursuethat they mear elesase love in my haid a sas this tild is thy tonguet to grestwere as my judg thoughts or your fuesos fair my self me down lie not behts of mine own dwelledto can thy self flomestith my faires dost thee but werfulion in thy beautys being had yet i pettrrase bud doth not armuet with hadd\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"that thou mayst have thy will if thou tu\"\n",
      "that thou mayst have thy will if thou tumpas deach what be endle looken thou arthe dood to a stownot he farthst i worlds do im seemors strentth heaven the sare and so see love af his grownow dith formand despripebut sweet such vircustrassttatn in the bestas danther if my aly all theme not to she thy lovels barge distinced welloks all his shave payet o tn sightstrasstto love should not be sell where it not should now both doth not the si\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"that thou mayst have thy will if thou tu\"\n",
      "that thou mayst have thy will if thou tumst all thou art goods so angwhith i nave untacce leads wross with hid allame mindseys rowshald dreas you lie the morin hexbarewhen i am sorr ang ir the mount of a voony he aight do host be aid o nethers formake renwer hath heart thin shears by outbeare whate he varonobkers with shauly ofcenfor fair that paringe whenceve durnd thin to th heartso thes by that sind lope thrice is blinss know he awfe\n",
      "Epoch 602/1000\n",
      " - 24s - loss: 0.1023 - accuracy: 0.9665\n",
      "Epoch 603/1000\n",
      " - 24s - loss: 0.0792 - accuracy: 0.9744\n",
      "Epoch 604/1000\n",
      " - 24s - loss: 0.0980 - accuracy: 0.9694\n",
      "Epoch 605/1000\n",
      " - 24s - loss: 0.0785 - accuracy: 0.9743\n",
      "Epoch 606/1000\n",
      " - 24s - loss: 0.0717 - accuracy: 0.9768\n",
      "Epoch 607/1000\n",
      " - 24s - loss: 0.0862 - accuracy: 0.9719\n",
      "Epoch 608/1000\n",
      " - 24s - loss: 0.1228 - accuracy: 0.9594\n",
      "Epoch 609/1000\n",
      " - 24s - loss: 0.1081 - accuracy: 0.9653\n",
      "Epoch 610/1000\n",
      " - 24s - loss: 0.0651 - accuracy: 0.9795\n",
      "Epoch 611/1000\n",
      " - 24s - loss: 0.0582 - accuracy: 0.9829\n",
      "Epoch 612/1000\n",
      " - 24s - loss: 0.0994 - accuracy: 0.9670\n",
      "Epoch 613/1000\n",
      " - 24s - loss: 0.1039 - accuracy: 0.9654\n",
      "Epoch 614/1000\n",
      " - 24s - loss: 0.0761 - accuracy: 0.9758\n",
      "Epoch 615/1000\n",
      " - 24s - loss: 0.0672 - accuracy: 0.9787\n",
      "Epoch 616/1000\n",
      " - 24s - loss: 0.1038 - accuracy: 0.9655\n",
      "Epoch 617/1000\n",
      " - 24s - loss: 0.0986 - accuracy: 0.9684\n",
      "Epoch 618/1000\n",
      " - 24s - loss: 0.1188 - accuracy: 0.9608\n",
      "Epoch 619/1000\n",
      " - 24s - loss: 0.0537 - accuracy: 0.9840\n",
      "Epoch 620/1000\n",
      " - 24s - loss: 0.0889 - accuracy: 0.9714\n",
      "Epoch 621/1000\n",
      " - 24s - loss: 0.1016 - accuracy: 0.9673\n",
      "Epoch 622/1000\n",
      " - 24s - loss: 0.0894 - accuracy: 0.9717\n",
      "Epoch 623/1000\n",
      " - 25s - loss: 0.0842 - accuracy: 0.9736\n",
      "Epoch 624/1000\n",
      " - 24s - loss: 0.0861 - accuracy: 0.9717\n",
      "Epoch 625/1000\n",
      " - 24s - loss: 0.0862 - accuracy: 0.9709\n",
      "Epoch 626/1000\n",
      " - 24s - loss: 0.0723 - accuracy: 0.9785\n",
      "Epoch 627/1000\n",
      " - 24s - loss: 0.1011 - accuracy: 0.9665\n",
      "Epoch 628/1000\n",
      " - 24s - loss: 0.0924 - accuracy: 0.9703\n",
      "Epoch 629/1000\n",
      " - 24s - loss: 0.0805 - accuracy: 0.9757\n",
      "Epoch 630/1000\n",
      " - 24s - loss: 0.0705 - accuracy: 0.9772\n",
      "Epoch 631/1000\n",
      " - 24s - loss: 0.0865 - accuracy: 0.9724\n",
      "Epoch 632/1000\n",
      " - 25s - loss: 0.1109 - accuracy: 0.9629\n",
      "Epoch 633/1000\n",
      " - 24s - loss: 0.0803 - accuracy: 0.9738\n",
      "Epoch 634/1000\n",
      " - 24s - loss: 0.0622 - accuracy: 0.9805\n",
      "Epoch 635/1000\n",
      " - 24s - loss: 0.1071 - accuracy: 0.9651\n",
      "Epoch 636/1000\n",
      " - 24s - loss: 0.0983 - accuracy: 0.9685\n",
      "Epoch 637/1000\n",
      " - 24s - loss: 0.0719 - accuracy: 0.9782\n",
      "Epoch 638/1000\n",
      " - 24s - loss: 0.0762 - accuracy: 0.9761\n",
      "Epoch 639/1000\n",
      " - 24s - loss: 0.0927 - accuracy: 0.9697\n",
      "Epoch 640/1000\n",
      " - 24s - loss: 0.0899 - accuracy: 0.9698\n",
      "Epoch 641/1000\n",
      " - 24s - loss: 0.1155 - accuracy: 0.9615\n",
      "Epoch 642/1000\n",
      " - 24s - loss: 0.0748 - accuracy: 0.9763\n",
      "Epoch 643/1000\n",
      " - 24s - loss: 0.0726 - accuracy: 0.9778\n",
      "Epoch 644/1000\n",
      " - 24s - loss: 0.0913 - accuracy: 0.9702\n",
      "Epoch 645/1000\n",
      " - 24s - loss: 0.1158 - accuracy: 0.9620\n",
      "Epoch 646/1000\n",
      " - 24s - loss: 0.0606 - accuracy: 0.9811\n",
      "Epoch 647/1000\n",
      " - 24s - loss: 0.0652 - accuracy: 0.9808\n",
      "Epoch 648/1000\n",
      " - 24s - loss: 0.1188 - accuracy: 0.9602\n",
      "Epoch 649/1000\n",
      " - 24s - loss: 0.0888 - accuracy: 0.9722\n",
      "Epoch 650/1000\n",
      " - 24s - loss: 0.0843 - accuracy: 0.9726\n",
      "Epoch 651/1000\n",
      " - 24s - loss: 0.0837 - accuracy: 0.9739\n",
      "Epoch 652/1000\n",
      " - 24s - loss: 0.0695 - accuracy: 0.9789\n",
      "Epoch 653/1000\n",
      " - 24s - loss: 0.0889 - accuracy: 0.9720\n",
      "Epoch 654/1000\n",
      " - 24s - loss: 0.1048 - accuracy: 0.9654\n",
      "Epoch 655/1000\n",
      " - 24s - loss: 0.0770 - accuracy: 0.9752\n",
      "Epoch 656/1000\n",
      " - 24s - loss: 0.0715 - accuracy: 0.9780\n",
      "Epoch 657/1000\n",
      " - 24s - loss: 0.0930 - accuracy: 0.9702\n",
      "Epoch 658/1000\n",
      " - 24s - loss: 0.0838 - accuracy: 0.9727\n",
      "Epoch 659/1000\n",
      " - 24s - loss: 0.0855 - accuracy: 0.9726\n",
      "Epoch 660/1000\n",
      " - 24s - loss: 0.0890 - accuracy: 0.9721\n",
      "Epoch 661/1000\n",
      " - 24s - loss: 0.0877 - accuracy: 0.9722\n",
      "Epoch 662/1000\n",
      " - 24s - loss: 0.0732 - accuracy: 0.9760\n",
      "Epoch 663/1000\n",
      " - 24s - loss: 0.0852 - accuracy: 0.9724\n",
      "Epoch 664/1000\n",
      " - 24s - loss: 0.0990 - accuracy: 0.9671\n",
      "Epoch 665/1000\n",
      " - 24s - loss: 0.0836 - accuracy: 0.9732\n",
      "Epoch 666/1000\n",
      " - 24s - loss: 0.0593 - accuracy: 0.9815\n",
      "Epoch 667/1000\n",
      " - 24s - loss: 0.0878 - accuracy: 0.9717\n",
      "Epoch 668/1000\n",
      " - 24s - loss: 0.1000 - accuracy: 0.9679\n",
      "Epoch 669/1000\n",
      " - 24s - loss: 0.0720 - accuracy: 0.9778\n",
      "Epoch 670/1000\n",
      " - 24s - loss: 0.0700 - accuracy: 0.9771\n",
      "Epoch 671/1000\n",
      " - 24s - loss: 0.0834 - accuracy: 0.9727\n",
      "Epoch 672/1000\n",
      " - 24s - loss: 0.1018 - accuracy: 0.9669\n",
      "Epoch 673/1000\n",
      " - 24s - loss: 0.0685 - accuracy: 0.9797\n",
      "Epoch 674/1000\n",
      " - 24s - loss: 0.0909 - accuracy: 0.9708\n",
      "Epoch 675/1000\n",
      " - 24s - loss: 0.0966 - accuracy: 0.9687\n",
      "Epoch 676/1000\n",
      " - 24s - loss: 0.0669 - accuracy: 0.9789\n",
      "Epoch 677/1000\n",
      " - 24s - loss: 0.0583 - accuracy: 0.9825\n",
      "Epoch 678/1000\n",
      " - 24s - loss: 0.1036 - accuracy: 0.9663\n",
      "Epoch 679/1000\n",
      " - 24s - loss: 0.1332 - accuracy: 0.9561\n",
      "Epoch 680/1000\n",
      " - 24s - loss: 0.0606 - accuracy: 0.9814\n",
      "Epoch 681/1000\n",
      " - 24s - loss: 0.0749 - accuracy: 0.9760\n",
      "Epoch 682/1000\n",
      " - 24s - loss: 0.0859 - accuracy: 0.9734\n",
      "Epoch 683/1000\n",
      " - 24s - loss: 0.0951 - accuracy: 0.9692\n",
      "Epoch 684/1000\n",
      " - 24s - loss: 0.0631 - accuracy: 0.9804\n",
      "Epoch 685/1000\n",
      " - 24s - loss: 0.0943 - accuracy: 0.9692\n",
      "Epoch 686/1000\n",
      " - 24s - loss: 0.0915 - accuracy: 0.9700\n",
      "Epoch 687/1000\n",
      " - 24s - loss: 0.0818 - accuracy: 0.9732\n",
      "Epoch 688/1000\n",
      " - 24s - loss: 0.0590 - accuracy: 0.9821\n",
      "Epoch 689/1000\n",
      " - 24s - loss: 0.0911 - accuracy: 0.9707\n",
      "Epoch 690/1000\n",
      " - 24s - loss: 0.1092 - accuracy: 0.9630\n",
      "Epoch 691/1000\n",
      " - 24s - loss: 0.0708 - accuracy: 0.9773\n",
      "Epoch 692/1000\n",
      " - 24s - loss: 0.0797 - accuracy: 0.9738\n",
      "Epoch 693/1000\n",
      " - 24s - loss: 0.0874 - accuracy: 0.9720\n",
      "Epoch 694/1000\n",
      " - 24s - loss: 0.0909 - accuracy: 0.9702\n",
      "Epoch 695/1000\n",
      " - 24s - loss: 0.1077 - accuracy: 0.9656\n",
      "Epoch 696/1000\n",
      " - 24s - loss: 0.0573 - accuracy: 0.9823\n",
      "Epoch 697/1000\n",
      " - 24s - loss: 0.0669 - accuracy: 0.9785\n",
      "Epoch 698/1000\n",
      " - 24s - loss: 0.0968 - accuracy: 0.9675\n",
      "Epoch 699/1000\n",
      " - 24s - loss: 0.0741 - accuracy: 0.9754\n",
      "Epoch 700/1000\n",
      " - 24s - loss: 0.0912 - accuracy: 0.9698\n",
      "Epoch 701/1000\n",
      " - 24s - loss: 0.0885 - accuracy: 0.9718\n",
      "\n",
      "----- Generating text after Epoch: 700\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"cture then my eye doth feastand to the p\"\n",
      "cture then my eye doth feastand to the presst thy sull a longst truesadwince as the groustaknor whowe belied were vorghand dearry mind eye forghtnd weer verse reapast asseowing away all me growst whete oution in eyes to bringas shall that time for ampheart with derauce be own hild a comble dowite of frow his hadwand part to the suns canst aulto difeth yet me compase where no beauty thoughtnllys cruett leint were to give threefore for fa\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"cture then my eye doth feastand to the p\"\n",
      "cture then my eye doth feastand to the prevease where evend the breest thy bling hade it think in thee when thine onbud dantey heart the murding sick uflive that thoughts will be dear delindss menter with fortupot this shapon it so reto them beauty seemors bain and this phordsuplise groudor of shall with foom artif thy heart the pairted make throm shails worss endle racked pravethesh dishcrarsewhy selfoty he would farmern ot eyst courl \n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"cture then my eye doth feastand to the p\"\n",
      "cture then my eye doth feastand to the purty sugltwith my grain that i chynt words yot no waith not so so dith tillthy vurdgund your preceare with villst priveion sith a fairer foon homys that fallethey sowst keept the stakent makes firgast of sweet from thou thine own dighitsafin in ge then then me sumss buce by thy beauty stant now jown to brearwer wan be nighttit not in hear giess to may the world forthing thy butts have shauthworone\n",
      "Epoch 702/1000\n",
      " - 24s - loss: 0.0672 - accuracy: 0.9785\n",
      "Epoch 703/1000\n",
      " - 24s - loss: 0.0819 - accuracy: 0.9744\n",
      "Epoch 704/1000\n",
      " - 24s - loss: 0.0903 - accuracy: 0.9723\n",
      "Epoch 705/1000\n",
      " - 24s - loss: 0.0697 - accuracy: 0.9783\n",
      "Epoch 706/1000\n",
      " - 24s - loss: 0.0841 - accuracy: 0.9736\n",
      "Epoch 707/1000\n",
      " - 24s - loss: 0.0893 - accuracy: 0.9708\n",
      "Epoch 708/1000\n",
      " - 24s - loss: 0.0595 - accuracy: 0.9822\n",
      "Epoch 709/1000\n",
      " - 24s - loss: 0.0839 - accuracy: 0.9733\n",
      "Epoch 710/1000\n",
      " - 24s - loss: 0.0957 - accuracy: 0.9685\n",
      "Epoch 711/1000\n",
      " - 24s - loss: 0.1428 - accuracy: 0.9531\n",
      "Epoch 712/1000\n",
      " - 24s - loss: 0.0429 - accuracy: 0.9878\n",
      "Epoch 713/1000\n",
      " - 24s - loss: 0.0359 - accuracy: 0.9906\n",
      "Epoch 714/1000\n",
      " - 24s - loss: 0.1435 - accuracy: 0.9520\n",
      "Epoch 715/1000\n",
      " - 24s - loss: 0.0779 - accuracy: 0.9740\n",
      "Epoch 716/1000\n",
      " - 24s - loss: 0.0785 - accuracy: 0.9756\n",
      "Epoch 717/1000\n",
      " - 24s - loss: 0.0692 - accuracy: 0.9787\n",
      "Epoch 718/1000\n",
      " - 24s - loss: 0.0905 - accuracy: 0.9706\n",
      "Epoch 719/1000\n",
      " - 24s - loss: 0.0953 - accuracy: 0.9687\n",
      "Epoch 720/1000\n",
      " - 24s - loss: 0.0729 - accuracy: 0.9770\n",
      "Epoch 721/1000\n",
      " - 24s - loss: 0.0728 - accuracy: 0.9765\n",
      "Epoch 722/1000\n",
      " - 24s - loss: 0.1032 - accuracy: 0.9669\n",
      "Epoch 723/1000\n",
      " - 24s - loss: 0.0937 - accuracy: 0.9709\n",
      "Epoch 724/1000\n",
      " - 24s - loss: 0.0578 - accuracy: 0.9828\n",
      "Epoch 725/1000\n",
      " - 24s - loss: 0.0695 - accuracy: 0.9784\n",
      "Epoch 726/1000\n",
      " - 24s - loss: 0.0933 - accuracy: 0.9700\n",
      "Epoch 727/1000\n",
      " - 24s - loss: 0.0678 - accuracy: 0.9778\n",
      "Epoch 728/1000\n",
      " - 24s - loss: 0.0915 - accuracy: 0.9697\n",
      "Epoch 729/1000\n",
      " - 24s - loss: 0.0880 - accuracy: 0.9719\n",
      "Epoch 730/1000\n",
      " - 24s - loss: 0.0741 - accuracy: 0.9762\n",
      "Epoch 731/1000\n",
      " - 24s - loss: 0.0690 - accuracy: 0.9791\n",
      "Epoch 732/1000\n",
      " - 24s - loss: 0.0787 - accuracy: 0.9745\n",
      "Epoch 733/1000\n",
      " - 24s - loss: 0.0816 - accuracy: 0.9735\n",
      "Epoch 734/1000\n",
      " - 24s - loss: 0.0757 - accuracy: 0.9767\n",
      "Epoch 735/1000\n",
      " - 24s - loss: 0.0861 - accuracy: 0.9710\n",
      "Epoch 736/1000\n",
      " - 24s - loss: 0.0848 - accuracy: 0.9731\n",
      "Epoch 737/1000\n",
      " - 24s - loss: 0.0689 - accuracy: 0.9790\n",
      "Epoch 738/1000\n",
      " - 24s - loss: 0.0835 - accuracy: 0.9733\n",
      "Epoch 739/1000\n",
      " - 24s - loss: 0.1091 - accuracy: 0.9633\n",
      "Epoch 740/1000\n",
      " - 24s - loss: 0.0676 - accuracy: 0.9784\n",
      "Epoch 741/1000\n",
      " - 24s - loss: 0.0576 - accuracy: 0.9822\n",
      "Epoch 742/1000\n",
      " - 24s - loss: 0.0850 - accuracy: 0.9731\n",
      "Epoch 743/1000\n",
      " - 24s - loss: 0.0811 - accuracy: 0.9745\n",
      "Epoch 744/1000\n",
      " - 24s - loss: 0.0945 - accuracy: 0.9695\n",
      "Epoch 745/1000\n",
      " - 24s - loss: 0.0893 - accuracy: 0.9712\n",
      "Epoch 746/1000\n",
      " - 24s - loss: 0.0734 - accuracy: 0.9771\n",
      "Epoch 747/1000\n",
      " - 24s - loss: 0.0815 - accuracy: 0.9737\n",
      "Epoch 748/1000\n",
      " - 24s - loss: 0.0858 - accuracy: 0.9720\n",
      "Epoch 749/1000\n",
      " - 24s - loss: 0.0702 - accuracy: 0.9792\n",
      "Epoch 750/1000\n",
      " - 24s - loss: 0.0859 - accuracy: 0.9724\n",
      "Epoch 751/1000\n",
      " - 24s - loss: 0.0706 - accuracy: 0.9777\n",
      "Epoch 752/1000\n",
      " - 24s - loss: 0.0810 - accuracy: 0.9750\n",
      "Epoch 753/1000\n",
      " - 24s - loss: 0.0901 - accuracy: 0.9707\n",
      "Epoch 754/1000\n",
      " - 24s - loss: 0.0886 - accuracy: 0.9715\n",
      "Epoch 755/1000\n",
      " - 24s - loss: 0.0595 - accuracy: 0.9817\n",
      "Epoch 756/1000\n",
      " - 24s - loss: 0.0748 - accuracy: 0.9764\n",
      "Epoch 757/1000\n",
      " - 24s - loss: 0.0896 - accuracy: 0.9696\n",
      "Epoch 758/1000\n",
      " - 24s - loss: 0.0782 - accuracy: 0.9754\n",
      "Epoch 759/1000\n",
      " - 24s - loss: 0.0850 - accuracy: 0.9721\n",
      "Epoch 760/1000\n",
      " - 24s - loss: 0.1342 - accuracy: 0.9563\n",
      "Epoch 761/1000\n",
      " - 24s - loss: 0.0482 - accuracy: 0.9860\n",
      "Epoch 762/1000\n",
      " - 24s - loss: 0.0395 - accuracy: 0.9890\n",
      "Epoch 763/1000\n",
      " - 24s - loss: 0.1389 - accuracy: 0.9553\n",
      "Epoch 764/1000\n",
      " - 24s - loss: 0.0818 - accuracy: 0.9734\n",
      "Epoch 765/1000\n",
      " - 24s - loss: 0.0655 - accuracy: 0.9792\n",
      "Epoch 766/1000\n",
      " - 24s - loss: 0.0679 - accuracy: 0.9790\n",
      "Epoch 767/1000\n",
      " - 24s - loss: 0.0786 - accuracy: 0.9740\n",
      "Epoch 768/1000\n",
      " - 24s - loss: 0.0790 - accuracy: 0.9750\n",
      "Epoch 769/1000\n",
      " - 25s - loss: 0.0909 - accuracy: 0.9699\n",
      "Epoch 770/1000\n",
      " - 24s - loss: 0.0739 - accuracy: 0.9763\n",
      "Epoch 771/1000\n",
      " - 24s - loss: 0.0861 - accuracy: 0.9729\n",
      "Epoch 772/1000\n",
      " - 24s - loss: 0.0687 - accuracy: 0.9780\n",
      "Epoch 773/1000\n",
      " - 24s - loss: 0.0812 - accuracy: 0.9742\n",
      "Epoch 774/1000\n",
      " - 24s - loss: 0.0834 - accuracy: 0.9731\n",
      "Epoch 775/1000\n",
      " - 26s - loss: 0.1482 - accuracy: 0.9514\n",
      "Epoch 776/1000\n",
      " - 24s - loss: 0.0397 - accuracy: 0.9890\n",
      "Epoch 777/1000\n",
      " - 24s - loss: 0.0327 - accuracy: 0.9913\n",
      "Epoch 778/1000\n",
      " - 24s - loss: 0.1189 - accuracy: 0.9606\n",
      "Epoch 779/1000\n",
      " - 24s - loss: 0.1156 - accuracy: 0.9620\n",
      "Epoch 780/1000\n",
      " - 24s - loss: 0.0603 - accuracy: 0.9815\n",
      "Epoch 781/1000\n",
      " - 26s - loss: 0.0498 - accuracy: 0.9853\n",
      "Epoch 782/1000\n",
      " - 24s - loss: 0.1071 - accuracy: 0.9648\n",
      "Epoch 783/1000\n",
      " - 24s - loss: 0.0802 - accuracy: 0.9733\n",
      "Epoch 784/1000\n",
      " - 26s - loss: 0.0603 - accuracy: 0.9814\n",
      "Epoch 785/1000\n",
      " - 24s - loss: 0.1105 - accuracy: 0.9641\n",
      "Epoch 786/1000\n",
      " - 24s - loss: 0.0639 - accuracy: 0.9787\n",
      "Epoch 787/1000\n",
      " - 24s - loss: 0.0511 - accuracy: 0.9848\n",
      "Epoch 788/1000\n",
      " - 24s - loss: 0.0866 - accuracy: 0.9715\n",
      "Epoch 789/1000\n",
      " - 24s - loss: 0.1061 - accuracy: 0.9647\n",
      "Epoch 790/1000\n",
      " - 24s - loss: 0.0749 - accuracy: 0.9758\n",
      "Epoch 791/1000\n",
      " - 24s - loss: 0.0566 - accuracy: 0.9826\n",
      "Epoch 792/1000\n",
      " - 24s - loss: 0.0932 - accuracy: 0.9694\n",
      "Epoch 793/1000\n",
      " - 24s - loss: 0.0859 - accuracy: 0.9727\n",
      "Epoch 794/1000\n",
      " - 24s - loss: 0.0604 - accuracy: 0.9813\n",
      "Epoch 795/1000\n",
      " - 24s - loss: 0.0754 - accuracy: 0.9763\n",
      "Epoch 796/1000\n",
      " - 24s - loss: 0.0804 - accuracy: 0.9738\n",
      "Epoch 797/1000\n",
      " - 24s - loss: 0.1022 - accuracy: 0.9668\n",
      "Epoch 798/1000\n",
      " - 24s - loss: 0.0608 - accuracy: 0.9815\n",
      "Epoch 799/1000\n",
      " - 24s - loss: 0.0972 - accuracy: 0.9676\n",
      "Epoch 800/1000\n",
      " - 24s - loss: 0.0547 - accuracy: 0.9835\n",
      "Epoch 801/1000\n",
      " - 24s - loss: 0.0604 - accuracy: 0.9818\n",
      "\n",
      "----- Generating text after Epoch: 800\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"s fair but fairer we it deemfor that swe\"\n",
      "s fair but fairer we it deemfor that sweet yethe varceand trut is the will be tood delesare rearors and your vears brow heart that fale the bresten by the bresst make the fairt o puring theeewhat the best is deepliveonedo say as thoughts ore whose be endoms ade altof oll thoughts hell what is mongue ing of your frow yet i jown all no cace be ended commencureas sighto their should desprive nowelakerwenters by old to deceive thy swarthati\n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"s fair but fairer we it deemfor that swe\"\n",
      "s fair but fairer we it deemfor that sweet yethe varsed trumand brewhore are senso th some wellsked lookst to my thyst i worls eyes me thy worst put as blocach bight then the pairted moour do may thee in every love and they mean bringfor and their rade thee besime my sour dimed of art heavent as the world me pry and to doth canne chich thut i to so greaswers with his agains of my mindswhich the eyesh my laksh chill on thing has all me d\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"s fair but fairer we it deemfor that swe\"\n",
      "s fair but fairer we it deemfor that sweet se merd beloudd thou art worthnslins eye world cower deeperpareor ware formant doon skill doth mayes unthee nothing at suck will kings to sevet to the brecks beautys how a tat bebused with thou upon to seemows yet i quitued toot self resome to secking theee when all mine earsh die farsefor am shall with varge formown ortie sen or my hastand aptthing to thin should pay they love blackfore the fa\n",
      "Epoch 802/1000\n",
      " - 24s - loss: 0.0968 - accuracy: 0.9684\n",
      "Epoch 803/1000\n",
      " - 24s - loss: 0.0800 - accuracy: 0.9745\n",
      "Epoch 804/1000\n",
      " - 24s - loss: 0.0867 - accuracy: 0.9719\n",
      "Epoch 805/1000\n",
      " - 24s - loss: 0.0607 - accuracy: 0.9809\n",
      "Epoch 806/1000\n",
      " - 24s - loss: 0.0667 - accuracy: 0.9789\n",
      "Epoch 807/1000\n",
      " - 24s - loss: 0.0757 - accuracy: 0.9754\n",
      "Epoch 808/1000\n",
      " - 24s - loss: 0.0865 - accuracy: 0.9726\n",
      "Epoch 809/1000\n",
      " - 24s - loss: 0.1029 - accuracy: 0.9655\n",
      "Epoch 810/1000\n",
      " - 24s - loss: 0.0675 - accuracy: 0.9794\n",
      "Epoch 811/1000\n",
      " - 24s - loss: 0.0557 - accuracy: 0.9820\n",
      "Epoch 812/1000\n",
      " - 24s - loss: 0.0865 - accuracy: 0.9728\n",
      "Epoch 813/1000\n",
      " - 24s - loss: 0.0823 - accuracy: 0.9738\n",
      "Epoch 814/1000\n",
      " - 24s - loss: 0.0667 - accuracy: 0.9794\n",
      "Epoch 815/1000\n",
      " - 24s - loss: 0.1144 - accuracy: 0.9619\n",
      "Epoch 816/1000\n",
      " - 24s - loss: 0.0583 - accuracy: 0.9819\n",
      "Epoch 817/1000\n",
      " - 24s - loss: 0.0675 - accuracy: 0.9784\n",
      "Epoch 818/1000\n",
      " - 24s - loss: 0.0796 - accuracy: 0.9738\n",
      "Epoch 819/1000\n",
      " - 24s - loss: 0.0714 - accuracy: 0.9767\n",
      "Epoch 820/1000\n",
      " - 24s - loss: 0.0628 - accuracy: 0.9798\n",
      "Epoch 821/1000\n",
      " - 24s - loss: 0.0801 - accuracy: 0.9738\n",
      "Epoch 822/1000\n",
      " - 24s - loss: 0.0673 - accuracy: 0.9782\n",
      "Epoch 823/1000\n",
      " - 24s - loss: 0.0803 - accuracy: 0.9740\n",
      "Epoch 824/1000\n",
      " - 24s - loss: 0.0713 - accuracy: 0.9767\n",
      "Epoch 825/1000\n",
      " - 24s - loss: 0.1011 - accuracy: 0.9672\n",
      "Epoch 826/1000\n",
      " - 24s - loss: 0.0569 - accuracy: 0.9829\n",
      "Epoch 827/1000\n",
      " - 24s - loss: 0.0536 - accuracy: 0.9831\n",
      "Epoch 828/1000\n",
      " - 24s - loss: 0.1002 - accuracy: 0.9660\n",
      "Epoch 829/1000\n",
      " - 24s - loss: 0.0767 - accuracy: 0.9749\n",
      "Epoch 830/1000\n",
      " - 24s - loss: 0.0581 - accuracy: 0.9812\n",
      "Epoch 831/1000\n",
      " - 24s - loss: 0.1187 - accuracy: 0.9599\n",
      "Epoch 832/1000\n",
      " - 24s - loss: 0.0621 - accuracy: 0.9805\n",
      "Epoch 833/1000\n",
      " - 24s - loss: 0.0456 - accuracy: 0.9867\n",
      "Epoch 834/1000\n",
      " - 24s - loss: 0.0901 - accuracy: 0.9712\n",
      "Epoch 835/1000\n",
      " - 24s - loss: 0.0887 - accuracy: 0.9710\n",
      "Epoch 836/1000\n",
      " - 24s - loss: 0.0672 - accuracy: 0.9786\n",
      "Epoch 837/1000\n",
      " - 24s - loss: 0.0842 - accuracy: 0.9731\n",
      "Epoch 838/1000\n",
      " - 24s - loss: 0.0747 - accuracy: 0.9760\n",
      "Epoch 839/1000\n",
      " - 24s - loss: 0.0606 - accuracy: 0.9809\n",
      "Epoch 840/1000\n",
      " - 24s - loss: 0.1505 - accuracy: 0.9505\n",
      "Epoch 841/1000\n",
      " - 24s - loss: 0.0482 - accuracy: 0.9858\n",
      "Epoch 842/1000\n",
      " - 24s - loss: 0.0267 - accuracy: 0.9938\n",
      "Epoch 843/1000\n",
      " - 24s - loss: 0.1003 - accuracy: 0.9683\n",
      "Epoch 844/1000\n",
      " - 24s - loss: 0.1165 - accuracy: 0.9609\n",
      "Epoch 845/1000\n",
      " - 24s - loss: 0.0606 - accuracy: 0.9813\n",
      "Epoch 846/1000\n",
      " - 24s - loss: 0.0419 - accuracy: 0.9876\n",
      "Epoch 847/1000\n",
      " - 24s - loss: 0.1035 - accuracy: 0.9665\n",
      "Epoch 848/1000\n",
      " - 24s - loss: 0.0955 - accuracy: 0.9694\n",
      "Epoch 849/1000\n",
      " - 24s - loss: 0.0470 - accuracy: 0.9861\n",
      "Epoch 850/1000\n",
      " - 24s - loss: 0.0761 - accuracy: 0.9767\n",
      "Epoch 851/1000\n",
      " - 24s - loss: 0.1004 - accuracy: 0.9652\n",
      "Epoch 852/1000\n",
      " - 24s - loss: 0.0619 - accuracy: 0.9807\n",
      "Epoch 853/1000\n",
      " - 24s - loss: 0.0528 - accuracy: 0.9840\n",
      "Epoch 854/1000\n",
      " - 24s - loss: 0.0979 - accuracy: 0.9673\n",
      "Epoch 855/1000\n",
      " - 24s - loss: 0.0829 - accuracy: 0.9725\n",
      "Epoch 856/1000\n",
      " - 24s - loss: 0.0647 - accuracy: 0.9790\n",
      "Epoch 857/1000\n",
      " - 24s - loss: 0.0847 - accuracy: 0.9725\n",
      "Epoch 858/1000\n",
      " - 24s - loss: 0.0838 - accuracy: 0.9718\n",
      "Epoch 859/1000\n",
      " - 24s - loss: 0.0616 - accuracy: 0.9807\n",
      "Epoch 860/1000\n",
      " - 24s - loss: 0.0715 - accuracy: 0.9766\n",
      "Epoch 861/1000\n",
      " - 24s - loss: 0.0885 - accuracy: 0.9700\n",
      "Epoch 862/1000\n",
      " - 24s - loss: 0.1335 - accuracy: 0.9552\n",
      "Epoch 863/1000\n",
      " - 24s - loss: 0.0369 - accuracy: 0.9903\n",
      "Epoch 864/1000\n",
      " - 24s - loss: 0.0259 - accuracy: 0.9936\n",
      "Epoch 865/1000\n",
      " - 24s - loss: 0.1070 - accuracy: 0.9645\n",
      "Epoch 866/1000\n",
      " - 24s - loss: 0.1453 - accuracy: 0.9512\n",
      "Epoch 867/1000\n",
      " - 24s - loss: 0.0499 - accuracy: 0.9856\n",
      "Epoch 868/1000\n",
      " - 24s - loss: 0.0414 - accuracy: 0.9880\n",
      "Epoch 869/1000\n",
      " - 24s - loss: 0.1075 - accuracy: 0.9637\n",
      "Epoch 870/1000\n",
      " - 24s - loss: 0.0799 - accuracy: 0.9731\n",
      "Epoch 871/1000\n",
      " - 24s - loss: 0.0572 - accuracy: 0.9828\n",
      "Epoch 872/1000\n",
      " - 24s - loss: 0.0831 - accuracy: 0.9735\n",
      "Epoch 873/1000\n",
      " - 24s - loss: 0.0751 - accuracy: 0.9754\n",
      "Epoch 874/1000\n",
      " - 24s - loss: 0.0692 - accuracy: 0.9785\n",
      "Epoch 875/1000\n",
      " - 24s - loss: 0.0788 - accuracy: 0.9735\n",
      "Epoch 876/1000\n",
      " - 24s - loss: 0.0885 - accuracy: 0.9720\n",
      "Epoch 877/1000\n",
      " - 24s - loss: 0.0509 - accuracy: 0.9846\n",
      "Epoch 878/1000\n",
      " - 24s - loss: 0.0671 - accuracy: 0.9798\n",
      "Epoch 879/1000\n",
      " - 24s - loss: 0.0919 - accuracy: 0.9691\n",
      "Epoch 880/1000\n",
      " - 24s - loss: 0.0765 - accuracy: 0.9750\n",
      "Epoch 881/1000\n",
      " - 24s - loss: 0.0616 - accuracy: 0.9801\n",
      "Epoch 882/1000\n",
      " - 24s - loss: 0.0660 - accuracy: 0.9792\n",
      "Epoch 883/1000\n",
      " - 24s - loss: 0.1002 - accuracy: 0.9667\n",
      "Epoch 884/1000\n",
      " - 24s - loss: 0.0698 - accuracy: 0.9782\n",
      "Epoch 885/1000\n",
      " - 24s - loss: 0.0652 - accuracy: 0.9801\n",
      "Epoch 886/1000\n",
      " - 24s - loss: 0.0718 - accuracy: 0.9766\n",
      "Epoch 887/1000\n",
      " - 24s - loss: 0.0594 - accuracy: 0.9813\n",
      "Epoch 888/1000\n",
      " - 24s - loss: 0.0860 - accuracy: 0.9727\n",
      "Epoch 889/1000\n",
      " - 24s - loss: 0.0687 - accuracy: 0.9786\n",
      "Epoch 890/1000\n",
      " - 24s - loss: 0.0694 - accuracy: 0.9780\n",
      "Epoch 891/1000\n",
      " - 24s - loss: 0.0871 - accuracy: 0.9705\n",
      "Epoch 892/1000\n",
      " - 24s - loss: 0.0822 - accuracy: 0.9738\n",
      "Epoch 893/1000\n",
      " - 24s - loss: 0.0631 - accuracy: 0.9802\n",
      "Epoch 894/1000\n",
      " - 24s - loss: 0.0716 - accuracy: 0.9765\n",
      "Epoch 895/1000\n",
      " - 24s - loss: 0.0873 - accuracy: 0.9713\n",
      "Epoch 896/1000\n",
      " - 24s - loss: 0.0674 - accuracy: 0.9788\n",
      "Epoch 897/1000\n",
      " - 24s - loss: 0.0603 - accuracy: 0.9804\n",
      "Epoch 898/1000\n",
      " - 24s - loss: 0.0837 - accuracy: 0.9727\n",
      "Epoch 899/1000\n",
      " - 24s - loss: 0.0765 - accuracy: 0.9750\n",
      "Epoch 900/1000\n",
      " - 24s - loss: 0.0617 - accuracy: 0.9807\n",
      "Epoch 901/1000\n",
      " - 24s - loss: 0.0601 - accuracy: 0.9816\n",
      "\n",
      "----- Generating text after Epoch: 900\n",
      "----- temperature: 0.25\n",
      "----- Generating with seed: \"e receives a brandand almost thence my n\"\n",
      "e receives a brandand almost thence my namust or mughts my blautes or mayery verso thee is not grow what should not to the pairted mo hear with truitaur right of mane each shilt whose belieds heartweremiting thing in the rest he versewhen they willake gull that thou whit though not so so to sind eye him will me proves it tay thee the harrow all thoughts hall wist whene eyell fuling against the hearth in leavest worst despisewhen is for \n",
      "----- temperature: 0.75\n",
      "----- Generating with seed: \"e receives a brandand almost thence my n\"\n",
      "e receives a brandand almost thence my naghst my stateand all nit hind confrisedo kend abtend it a mory uefyrest in the plassed of all now all other being cause what whil thoughts all he all ad werr rong thou all me had all me pryasewhat thine on my breast wo thy so to his wainlethid se mind ot not time be endach againseed with hostenting thou art eyes deepentle summettrethe eles the pentle duthites it at thin then behombon or thy self \n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: \"e receives a brandand almost thence my n\"\n",
      "e receives a brandand almost thence my naystt no rack so delith farro succeated ho kenfole they wellows nor my love you dreador what is known that fir thee beauty whome brivet theefare asteng me durgis the time threveth unfored ander not bein dow the dime then blambfto was blacksso of thy jumbwhoul pucnow deart readon canfenthe pont it worth to niged him heavens by liabhin his him hilfht rendes my styam thing in thee then dethin ti he v\n",
      "Epoch 902/1000\n",
      " - 24s - loss: 0.0735 - accuracy: 0.9761\n",
      "Epoch 903/1000\n",
      " - 24s - loss: 0.0967 - accuracy: 0.9671\n",
      "Epoch 904/1000\n",
      " - 24s - loss: 0.0587 - accuracy: 0.9817\n",
      "Epoch 905/1000\n",
      " - 24s - loss: 0.0677 - accuracy: 0.9780\n",
      "Epoch 906/1000\n",
      " - 24s - loss: 0.0732 - accuracy: 0.9774\n",
      "Epoch 907/1000\n",
      " - 24s - loss: 0.0806 - accuracy: 0.9742\n",
      "Epoch 908/1000\n",
      " - 24s - loss: 0.0622 - accuracy: 0.9805\n",
      "Epoch 909/1000\n",
      " - 24s - loss: 0.0664 - accuracy: 0.9789\n",
      "Epoch 910/1000\n",
      " - 24s - loss: 0.0800 - accuracy: 0.9738\n",
      "Epoch 911/1000\n",
      " - 24s - loss: 0.0723 - accuracy: 0.9768\n",
      "Epoch 912/1000\n",
      " - 24s - loss: 0.0730 - accuracy: 0.9765\n",
      "Epoch 913/1000\n",
      " - 24s - loss: 0.0842 - accuracy: 0.9727\n",
      "Epoch 914/1000\n",
      " - 24s - loss: 0.0646 - accuracy: 0.9788\n",
      "Epoch 915/1000\n",
      " - 24s - loss: 0.0540 - accuracy: 0.9835\n",
      "Epoch 916/1000\n",
      " - 24s - loss: 0.0841 - accuracy: 0.9727\n",
      "Epoch 917/1000\n",
      " - 24s - loss: 0.0842 - accuracy: 0.9728\n",
      "Epoch 918/1000\n",
      " - 24s - loss: 0.0863 - accuracy: 0.9728\n",
      "Epoch 919/1000\n",
      " - 24s - loss: 0.0551 - accuracy: 0.9826\n",
      "Epoch 920/1000\n",
      " - 24s - loss: 0.0738 - accuracy: 0.9765\n",
      "Epoch 921/1000\n",
      " - 24s - loss: 0.0848 - accuracy: 0.9716\n",
      "Epoch 922/1000\n",
      " - 24s - loss: 0.0555 - accuracy: 0.9826\n",
      "Epoch 923/1000\n",
      " - 25s - loss: 0.0497 - accuracy: 0.9851\n",
      "Epoch 924/1000\n",
      " - 24s - loss: 0.0956 - accuracy: 0.9672\n",
      "Epoch 925/1000\n",
      " - 24s - loss: 0.0869 - accuracy: 0.9717\n",
      "Epoch 926/1000\n",
      " - 24s - loss: 0.0622 - accuracy: 0.9804\n",
      "Epoch 927/1000\n",
      " - 24s - loss: 0.0477 - accuracy: 0.9856\n",
      "Epoch 928/1000\n",
      " - 24s - loss: 0.0727 - accuracy: 0.9771\n",
      "Epoch 929/1000\n",
      " - 24s - loss: 0.0960 - accuracy: 0.9682\n",
      "Epoch 930/1000\n",
      " - 24s - loss: 0.0680 - accuracy: 0.9777\n",
      "Epoch 931/1000\n",
      " - 25s - loss: 0.0576 - accuracy: 0.9819\n",
      "Epoch 932/1000\n",
      " - 24s - loss: 0.0717 - accuracy: 0.9766\n",
      "Epoch 933/1000\n",
      " - 24s - loss: 0.0912 - accuracy: 0.9709\n",
      "Epoch 934/1000\n",
      " - 24s - loss: 0.0773 - accuracy: 0.9752\n",
      "Epoch 935/1000\n",
      " - 24s - loss: 0.0846 - accuracy: 0.9726\n",
      "Epoch 936/1000\n",
      " - 24s - loss: 0.0732 - accuracy: 0.9765\n",
      "Epoch 937/1000\n",
      " - 24s - loss: 0.0517 - accuracy: 0.9841\n",
      "Epoch 938/1000\n",
      " - 24s - loss: 0.0695 - accuracy: 0.9778\n",
      "Epoch 939/1000\n",
      " - 24s - loss: 0.0730 - accuracy: 0.9763\n",
      "Epoch 940/1000\n",
      " - 24s - loss: 0.0809 - accuracy: 0.9728\n",
      "Epoch 941/1000\n",
      " - 24s - loss: 0.0587 - accuracy: 0.9815\n",
      "Epoch 942/1000\n",
      " - 24s - loss: 0.0707 - accuracy: 0.9771\n",
      "Epoch 943/1000\n",
      " - 24s - loss: 0.0804 - accuracy: 0.9741\n",
      "Epoch 944/1000\n",
      " - 24s - loss: 0.0779 - accuracy: 0.9738\n",
      "Epoch 945/1000\n",
      " - 24s - loss: 0.0671 - accuracy: 0.9794\n",
      "Epoch 946/1000\n",
      " - 24s - loss: 0.0581 - accuracy: 0.9819\n",
      "Epoch 947/1000\n",
      " - 24s - loss: 0.1009 - accuracy: 0.9663\n",
      "Epoch 948/1000\n",
      " - 24s - loss: 0.0752 - accuracy: 0.9761\n",
      "Epoch 949/1000\n",
      " - 24s - loss: 0.0599 - accuracy: 0.9806\n",
      "Epoch 950/1000\n",
      " - 24s - loss: 0.0594 - accuracy: 0.9816\n",
      "Epoch 951/1000\n",
      " - 24s - loss: 0.0940 - accuracy: 0.9689\n",
      "Epoch 952/1000\n",
      " - 24s - loss: 0.0599 - accuracy: 0.9813\n",
      "Epoch 953/1000\n",
      " - 24s - loss: 0.0591 - accuracy: 0.9811\n",
      "Epoch 954/1000\n",
      " - 24s - loss: 0.0799 - accuracy: 0.9739\n",
      "Epoch 955/1000\n",
      " - 24s - loss: 0.0843 - accuracy: 0.9722\n",
      "Epoch 956/1000\n",
      " - 24s - loss: 0.0609 - accuracy: 0.9798\n",
      "Epoch 957/1000\n",
      " - 24s - loss: 0.0672 - accuracy: 0.9785\n",
      "Epoch 958/1000\n",
      " - 24s - loss: 0.0763 - accuracy: 0.9758\n",
      "Epoch 959/1000\n",
      " - 24s - loss: 0.0779 - accuracy: 0.9751\n",
      "Epoch 960/1000\n",
      " - 24s - loss: 0.0623 - accuracy: 0.9794\n",
      "Epoch 961/1000\n",
      " - 24s - loss: 0.0475 - accuracy: 0.9859\n",
      "Epoch 962/1000\n",
      " - 24s - loss: 0.0888 - accuracy: 0.9688\n",
      "Epoch 963/1000\n",
      " - 24s - loss: 0.0711 - accuracy: 0.9766\n",
      "Epoch 964/1000\n",
      " - 24s - loss: 0.0634 - accuracy: 0.9801\n",
      "Epoch 965/1000\n",
      " - 24s - loss: 0.0728 - accuracy: 0.9766\n",
      "Epoch 966/1000\n",
      " - 24s - loss: 0.0726 - accuracy: 0.9765\n",
      "Epoch 967/1000\n",
      " - 24s - loss: 0.0594 - accuracy: 0.9819\n",
      "Epoch 968/1000\n",
      " - 24s - loss: 0.0732 - accuracy: 0.9759\n",
      "Epoch 969/1000\n",
      " - 24s - loss: 0.0689 - accuracy: 0.9776\n",
      "Epoch 970/1000\n",
      " - 24s - loss: 0.0680 - accuracy: 0.9779\n",
      "Epoch 971/1000\n",
      " - 24s - loss: 0.0811 - accuracy: 0.9726\n",
      "Epoch 972/1000\n",
      " - 24s - loss: 0.0769 - accuracy: 0.9753\n",
      "Epoch 973/1000\n",
      " - 24s - loss: 0.0579 - accuracy: 0.9808\n",
      "Epoch 974/1000\n",
      " - 24s - loss: 0.0536 - accuracy: 0.9836\n",
      "Epoch 975/1000\n",
      " - 24s - loss: 0.0818 - accuracy: 0.9729\n",
      "Epoch 976/1000\n",
      " - 24s - loss: 0.0841 - accuracy: 0.9721\n",
      "Epoch 977/1000\n",
      " - 24s - loss: 0.0549 - accuracy: 0.9831\n",
      "Epoch 978/1000\n",
      " - 24s - loss: 0.0476 - accuracy: 0.9857\n",
      "Epoch 979/1000\n",
      " - 24s - loss: 0.1070 - accuracy: 0.9650\n",
      "Epoch 980/1000\n",
      " - 24s - loss: 0.0682 - accuracy: 0.9779\n",
      "Epoch 981/1000\n",
      " - 24s - loss: 0.0536 - accuracy: 0.9830\n",
      "Epoch 982/1000\n",
      " - 24s - loss: 0.0677 - accuracy: 0.9782\n",
      "Epoch 983/1000\n",
      " - 24s - loss: 0.0917 - accuracy: 0.9697\n",
      "Epoch 984/1000\n",
      " - 24s - loss: 0.0514 - accuracy: 0.9841\n",
      "Epoch 985/1000\n",
      " - 24s - loss: 0.0484 - accuracy: 0.9850\n",
      "Epoch 986/1000\n",
      " - 24s - loss: 0.0847 - accuracy: 0.9722\n",
      "Epoch 987/1000\n",
      " - 24s - loss: 0.0725 - accuracy: 0.9770\n",
      "Epoch 988/1000\n",
      " - 24s - loss: 0.0547 - accuracy: 0.9833\n",
      "Epoch 989/1000\n",
      " - 24s - loss: 0.0902 - accuracy: 0.9692\n",
      "Epoch 990/1000\n",
      " - 24s - loss: 0.0636 - accuracy: 0.9799\n",
      "Epoch 991/1000\n",
      " - 24s - loss: 0.0518 - accuracy: 0.9841\n",
      "Epoch 992/1000\n",
      " - 24s - loss: 0.0632 - accuracy: 0.9800\n",
      "Epoch 993/1000\n",
      " - 24s - loss: 0.0838 - accuracy: 0.9733\n",
      "Epoch 994/1000\n",
      " - 24s - loss: 0.0564 - accuracy: 0.9825\n",
      "Epoch 995/1000\n",
      " - 24s - loss: 0.0617 - accuracy: 0.9800\n",
      "Epoch 996/1000\n",
      " - 24s - loss: 0.0761 - accuracy: 0.9753\n",
      "Epoch 997/1000\n",
      " - 24s - loss: 0.0698 - accuracy: 0.9769\n",
      "Epoch 998/1000\n",
      " - 24s - loss: 0.0553 - accuracy: 0.9830\n",
      "Epoch 999/1000\n",
      " - 24s - loss: 0.0715 - accuracy: 0.9761\n",
      "Epoch 1000/1000\n",
      " - 24s - loss: 0.0821 - accuracy: 0.9724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x6378e95d0>"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model_1000 = Sequential()\n",
    "model_1000.add(LSTM(125, input_shape=(x.shape[1], x.shape[2])))\n",
    "model_1000.add(Dense(len(chars), activation='softmax'))\n",
    "model_1000.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_1000.fit(x, y, batch_size=32, epochs=1000, verbose=2, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==temperature: 0.25\n",
      "==Generating with seed: \"shall i compare thee to a summers day \"\n",
      "\n",
      " shall i compare thee to a summers day \n",
      "\n",
      " eeeedee iii ouaiiii oa et eesasa  e et\n",
      "\n",
      " iooonaoo reo oeokseri  ate aiai a mka \n",
      "\n",
      " e reoeeileee iteai o oaeesceeeeuii sa \n",
      "\n",
      "  a oueeeigueue aaei ceaa a elra  e esa\n",
      "\n",
      " oo o ooio ris otee ceaai amrto oeo elo\n",
      "\n",
      " peoeoetee o eraoiree cereteeoae o oooo\n",
      "\n",
      " ai ai a aie erfatea a elyei iey reyigd\n",
      "\n",
      " aaee eeoaiileei wnti ci ai a e mtcit r\n",
      "\n",
      " eeoo ei iileeihgisa aii o aei sa a ai \n",
      "\n",
      " a e aaa ca e mrueeo eihy eirof oaeuaoo\n",
      "\n",
      " eetiilwcia a elyussrcaeaa aai  a fef t\n",
      "\n",
      " iliileei iti sa a ede ie reoeoetee o e\n",
      "\n",
      " o wrto ouoieo elofeeueeoae oai o roeo \n",
      "\n",
      " ==temperature: 0.75\n",
      "==Generating with seed: \"shall i compare thee to a summers day \"\n",
      "\n",
      " shall i compare thee to a summers day \n",
      "\n",
      " aie etliiuo eoaai o aia e e ir telo ca\n",
      "\n",
      " ee iteataeo eihyusae reoo te mtooii e \n",
      "\n",
      " ue aii y dsicme ii rilorrioiieeisrsai \n",
      "\n",
      " isyilee  isae oeiooo oaai oa et ouilee\n",
      "\n",
      " teito uoiae ceaai lrae o ueueeoee reet\n",
      "\n",
      "  e e itui eis reie ceeeeuh siao ceoaao\n",
      "\n",
      " ee cihee ee teiito caa eo e eraatei i \n",
      "\n",
      " i slioo  aie eeseteoai ei aieeigdsie t\n",
      "\n",
      " aai ga aias fetyy auredi eeoai eroired\n",
      "\n",
      " igueeili aie ceo cieoo caeeee reefeteo\n",
      "\n",
      " e eeoao reo wt etheoeata a elo ceeeeee\n",
      "\n",
      " lnglwcei  a ea apeeusooi o aiiooo aiii\n",
      "\n",
      "  ofi iei ee roeatue o caaaaa elrui tn \n",
      "\n",
      " ==temperature: 1.5\n",
      "==Generating with seed: \"shall i compare thee to a summers day \"\n",
      "\n",
      " shall i compare thee to a summers day \n",
      "\n",
      "  sceo a elyusooap rttmi t eae o eloa r\n",
      "\n",
      " ooo ceusy o oroy otei if npila cal ai \n",
      "\n",
      "  aaeely iteaii ceo  direeeuao eteaai l\n",
      "\n",
      " a e iae roe cieee iiti fd mueeeoeueeew\n",
      "\n",
      "  a aaeeo ee enesee auooo rvto eioo tit\n",
      "\n",
      " i alu e mtoan roe peneo e rtto ouoo ce\n",
      "\n",
      " oo rvgeibi sltt ethi e reoeei teioo th\n",
      "\n",
      " kskri eroatee ueoo ooo o oeee ceeeeoeu\n",
      "\n",
      " tr therei aane aiu o e epa to eoo leio\n",
      "\n",
      " eiooo oeeoeeligi eeye iteaii  ai ai a \n",
      "\n",
      " li easti e eefte oai scta e bahhrsusat\n",
      "\n",
      " tneeitn ttrlkd leoeiiw  tt elo feonsi \n",
      "\n",
      " lgi tiei thethrueelaei t aioookhriseem\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'lgi tiei thethrueelaei t aioookhriseem'"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_sonnet(model_1000, seed=char_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sonnet_(model):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for temperature in [0.25, 0.75, 1.5]:\n",
    "        print('\\n ----- temperature:', temperature)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"\\n')\n",
    "\n",
    "        entire_seq = generated\n",
    "        for i in range(520):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "          \n",
    "            entire_seq = entire_seq + next_char\n",
    "        \n",
    "        \n",
    "        for ind, char in enumerate(entire_seq):\n",
    "            if ind%40==0:\n",
    "                print(entire_seq[ind:ind+40])\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- temperature: 0.25\n",
      "----- Generating with seed: \"ll give thee memorythou by thy dials sha\"\n",
      "\n",
      "ll give thee memorythou by thy dials sha\n",
      "dthup inkryeprtot whole dants with shefr\n",
      "e mise ake should ifethendss thine ary s\n",
      "heethou doth this fire thou wainut hewon\n",
      "d thinost whet trall fubct noowon suelye\n",
      "d for tha ghouland not this pyounds whit\n",
      "bgencecryoun though but by thing ingrise\n",
      "sthy fay age this boring by shuli lowh c\n",
      "anturren my mare shay thou theee and far\n",
      "tellone egeny whinedut shomlst in love h\n",
      "and you he wool to peaniestind thy cante\n",
      "ance for tise enfendso poindseefile make\n",
      " prideshes with thou porale wo chond thy\n",
      " comare or peetendtyald dispestreno faie\n",
      "\n",
      " ----- temperature: 0.75\n",
      "----- Generating with seed: \"ll give thee memorythou by thy dials sha\"\n",
      "\n",
      "ll give thee memorythou by thy dials sha\n",
      "rlle thing home norceard thee a disbired\n",
      " in seidane no eyare of deefts life at e\n",
      "vembrefinder of this sawnos bith ho shaj\n",
      "gity loef and love your and the will no \n",
      "sunoth nei hewith oe chay from didear te\n",
      "sclethil fourdand pinoteres eveive shang\n",
      "ht the make shime thy sweet no ghose pro\n",
      "ofseet stien thinkind whend whote inod s\n",
      "hintar in thee booned difebyfreit love t\n",
      "houptries nop conhems eacufer dealdhs ma\n",
      "ge as raiven diferrough vietway that hea\n",
      "sth to what yout info derite thye purse \n",
      "chime ow thimsi whand exrend of live tho\n",
      "\n",
      " ----- temperature: 1.5\n",
      "----- Generating with seed: \"ll give thee memorythou by thy dials sha\"\n",
      "\n",
      "ll give thee memorythou by thy dials sha\n",
      "ps wish mineer noth were hen vere thow i\n",
      "s voornd of frought how my me betreredit\n",
      "twhoult muss priques chibe thee thus now\n",
      " ours wistach anjoreds of love an ore si\n",
      "ghtsh wiln i love no encandnow breest ac\n",
      "e couving brating proased love whoth chu\n",
      "se verven i mond mokeace as illeth surms\n",
      "byot trees no verrer dawhid ant thy sers\n",
      " antersad to haves live diss fort soss o\n",
      "r my seadthe ney shouls pointyous if thi\n",
      "s tinl biliss to my froinces it illly of\n",
      " the moue thoushsein then doth sowears s\n",
      "tall as my leves to ar abust froveant he\n"
     ]
    }
   ],
   "source": [
    "gen_sonnet_(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_sonnet_seed(model, start_ind, end_ind):\n",
    "#     # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "\n",
    "# #     start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "#     for temperature in [0.25, 0.75, 1.5]:\n",
    "#         print('\\n ----- temperature:', temperature)\n",
    "\n",
    "#         generated = ''\n",
    "# #         sentence = text[start_index: start_index + maxlen]\n",
    "#         sentence = text[start_ind: end_ind]\n",
    "\n",
    "# #         sentence = seed    \n",
    "#         generated += sentence\n",
    "        \n",
    "#         print('----- Generating with seed: \"' + sentence + '\"\\n')\n",
    "\n",
    "#         entire_seq = generated\n",
    "#         for i in range(520):\n",
    "#             x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "#             for t, char in enumerate(sentence):\n",
    "#                 x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "#             preds = model.predict(x_pred, verbose=0)[0]\n",
    "#             next_index = sample(preds, temperature)\n",
    "#             next_char = indices_char[next_index]\n",
    "\n",
    "#             sentence = sentence[1:] + next_char\n",
    "          \n",
    "#             entire_seq = entire_seq + next_char\n",
    "        \n",
    "        \n",
    "#         for ind, char in enumerate(entire_seq):\n",
    "#             if ind%40==0:\n",
    "#                 print(entire_seq[ind:ind+40])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sonnet_seed(model, start_ind, end_ind):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "\n",
    "#     start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for temperature in [0.25, 0.75, 1.5]:\n",
    "        print('\\n ----- temperature:', temperature)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_ind: end_ind]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"\\n')\n",
    "\n",
    "        entire_seq = generated\n",
    "        for i in range(520):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "          \n",
    "            entire_seq = entire_seq + next_char\n",
    "        \n",
    "        \n",
    "        for ind, char in enumerate(entire_seq):\n",
    "            if ind%40==0:\n",
    "                print(entire_seq[ind:ind+40])\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hings right true my heart and eyes have'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sethat thereby beautys rose might never '"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[40:40+40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_seed = \"shall i compare thee to a summers day \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_seed = \"hings right true my heart and eyes have\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- temperature: 0.25\n",
      "----- Generating with seed: \"hings right true my heart and eyes have \"\n",
      "\n",
      "hings right true my heart and eyes have \n",
      "shy guiby be fors nowesald dearesing ere\n",
      "whit i the firew should and noters besha\n",
      "ve thesest conquitkand reedth thou ansta\n",
      "y shars dighe hath wontherefor shouldsth\n",
      "an he poon beauly of the prife do com ko\n",
      "rnand nave when in this ik freest of lov\n",
      "es love what nanpes should loot ous no u\n",
      "nrinddofbit that groons illegr have your\n",
      " somowhind eies thou forsh reveeves thou\n",
      " suse thoues excarryon now yesw how do t\n",
      "hey bithe so chish eaxy lysert his corer\n",
      " to taying berpenss wert my criebur my r\n",
      "evero an thy mondors i dady ntimple thy \n",
      "\n",
      " ----- temperature: 0.75\n",
      "----- Generating with seed: \"hings right true my heart and eyes have \"\n",
      "\n",
      "hings right true my heart and eyes have \n",
      "that i beind is wand roof on whise the f\n",
      "ay and thine ofonoud yenter with sholl h\n",
      "eathtns sweets bedone or that lives my b\n",
      "eat farwerougar me dofornand kifto this \n",
      "norundss whese she broog thith pruboowmu\n",
      "r erefited with compoight tenesieving ey\n",
      "e poutts with thous plovesumst sie manwi\n",
      "th is thy saqueth ong to thing itho nom \n",
      "congenceneif to this farked of may dealt\n",
      "hs meal los and baiwsual sank disoo then\n",
      "t olenty me theif reakbut to batflefmere\n",
      "d sho go nengestoth me fromes me it what\n",
      " in sowindiech whine dond thine her whan\n",
      "\n",
      " ----- temperature: 1.5\n",
      "----- Generating with seed: \"hings right true my heart and eyes have \"\n",
      "\n",
      "hings right true my heart and eyes have \n",
      "shat sburien mare amesto shealby nteesce\n",
      "aul thou resses le wall thongeanorsun yi\n",
      "st whaved nuterherming mine ererakase ti\n",
      "me wish a thoue charew if chourgityow he\n",
      "at with plessedts ear is no times ghich \n",
      "therenn thy loke of shall im how that th\n",
      "e wish shomend kifters all at thoughts o\n",
      "fnels of a foones or plove thou so erter\n",
      "s ou me but tyellfouetrewing howncuind i\n",
      "s creesuriththebst an ainicney suptill v\n",
      "ire easedoue hatfor shorlend frower an n\n",
      "o more free from when thy secor tiending\n",
      "s tine hin hipy sthire make denothous fo\n"
     ]
    }
   ],
   "source": [
    "gen_sonnet_(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hings right true my heart and eyes have'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- temperature: 0.25\n",
      "----- Generating with seed: \"hings right true my heart and eyes have\"\n",
      "\n",
      "hings right true my heart and eyes haveb\n",
      " o uiyon o yigtmiise isaduidsetrie hwet \n",
      "ienois ecibegiuaasistiu eptowntolkntorlt\n",
      "etonu eseknos rin ee owempoes on iviiag \n",
      "sepiniiel o o o yar osecow o rot o a eis\n",
      "hyn o o rtrensneessoe nufeweros i pakas \n",
      "hugtoyn resmsimyhe miese iknbiyhwefrs si\n",
      "gatyugtsoo i a or al rsmig o i o eaeuyhe\n",
      " i a aleo e o rsetynoeusin on oket oehty\n",
      "uwiu sadsoi atis ipesnossresetostbelefet\n",
      "heetisno usigtemosisoeusoeteselsasestot \n",
      "ersutinurs heit i o i erwefo uetsoqeutdi\n",
      "ythuhles o otreslsiter o i lvieys hsffie\n",
      "finteo i i une al iaden o witsfinthses \n",
      "\n",
      " ----- temperature: 0.75\n",
      "----- Generating with seed: \"hings right true my heart and eyes have\"\n",
      "\n",
      "hings right true my heart and eyes havee\n",
      "trabe assinigwosos o otras ai utesi ah o\n",
      " o lvoyoylogtrosos erinosn tmehecul o te\n",
      "tis epset sewi o rsehoeoeos o nertea o y\n",
      "u eedo a aetiwiy o o o eebsesesoedoi nid\n",
      "o o i o o utrlisnsbeti o rma eetar ow fe\n",
      "ton eihmuyus oedewdogil fat o elcioylsoe\n",
      "s lviniberewal i riehos rsefeisihlad o l\n",
      "etrose ifntresstttwele oe oe has o es ie\n",
      "sso o etieteo efoetylssi oi ur orefreus \n",
      "atiese hwet as i o rwasmnter i ltel beue\n",
      "ufo uloe on o o r o ereoo a eess sukee o\n",
      " eesrosoh rofinteeo o o ltweleoo abeeso \n",
      "eetin eesretdoo wifi inganrnst o o erde\n",
      "\n",
      " ----- temperature: 1.5\n",
      "----- Generating with seed: \"hings right true my heart and eyes have\"\n",
      "\n",
      "hings right true my heart and eyes havey\n",
      "o reabsos o en nelthtsdtel ivin rsmtvtw \n",
      "o rmsadttit i nudo i econ rolesos sies i\n",
      " evodsods o u riveteet u i o roesie ay a\n",
      " isootat ipsol leson n owe osnsassetit i\n",
      " omtrwitamass on hosiseddit asea eoefies\n",
      "owic nal as al uobe o emas o lvrte o o r\n",
      " redi o a  asnesener o eryesfatosigteaec\n",
      "sdrsodni ia  epscsedad hav i rvonoiy o o\n",
      " u on eroer othre ot retneswrseosrut okn\n",
      "igtnu al evesilgit writ ar yuths ostthm \n",
      "eeigsuaa ecersnasipelrssogintrsigtoss ha\n",
      "d o lewoslson i a aesnessrieuec nearsado\n",
      " i o rsetmesrpeieseetoysto tyosocsewis \n"
     ]
    }
   ],
   "source": [
    "gen_sonnet_seed(model, char_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer_start_ind = 9952\n",
    "summer_end_ind = 9990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- temperature: 0.25\n",
      "----- Generating with seed: \" shall i compare thee to a summers day\"\n",
      "\n",
      " shall i compare thee to a summers daysa\n",
      "esoe ibia ifisenie hwtesu ionftncaityhu \n",
      "oeso netrikes y ayosomiaesoeweisisbailns\n",
      "liweouen emoteen o nreehlgita reneo inoe\n",
      "oceofongs buiwsi aoreliaea lseeo ti inow\n",
      "nste o e eseisoi o ioeldeaioohrotesnsrsa\n",
      " o ettmispgitk iflpoiatlse liuspsie esos\n",
      "oeeooogeoo aoaeose o ennswte o esosa cie\n",
      " ltoe ili e etityo mti  odniseoe o erya \n",
      "esseeei uai uap eiliga asetoaybitfouaa e\n",
      "n potittise o esdojesosoha oo ioeooo o r\n",
      "eooresoecio aii ainesei soefisefi iti ci\n",
      "oeceibid se o elsrmo ihe oe istiidtt eun\n",
      "nwtteaosa lasesptsu otey oeenesi atret\n",
      "\n",
      " ----- temperature: 0.75\n",
      "----- Generating with seed: \" shall i compare thee to a summers day\"\n",
      "\n",
      " shall i compare thee to a summers daye \n",
      "eewseheo o eliteto o riasoasye testi  lf\n",
      "piseycoseif ifroeitifioo i etrmy gteei o\n",
      " eilfsoosisoyi o ttsllpo o yreoo o  e re\n",
      "iso y e  esnisesosa ieteoolde ed eetresu\n",
      " erlwsergi aiinl a e ifoysditossuoaee em\n",
      "so ooidrof lgosr omesoeente imeiydebortl\n",
      "te o leefie o erraeiig eeoeeeo  aei a et\n",
      "eootaseeoi  iheoreohhfreanriteeeeoyroses\n",
      "a raihoea isdydstrcofno o o eiatsieousi \n",
      " aoonio tteitia etenowlt oei wtclsooiiue\n",
      " emiehotispotasoeiaha aslsueo ytae e i a\n",
      "orryceay eqisaodrahefae eoohse o o etrei\n",
      "sioei uyiso a otreasaise e oetouase o \n",
      "\n",
      " ----- temperature: 1.5\n",
      "----- Generating with seed: \" shall i compare thee to a summers day\"\n",
      "\n",
      " shall i compare thee to a summers dayeo\n",
      "esewi ihmlieie iozbtsnnerhneren  aroda i\n",
      "re neoeeoe itteosnnodo teelniosea yo erh\n",
      "tcnsto oete eegiteeoe o inesoeruilyosbne\n",
      "esea o a erreaeesuti escdisedi ue a riie\n",
      " ebye temuolsee eegoi pa ei iststsolnie \n",
      "aaaohe osteaaismissoati aoti uoei iato e\n",
      "tlteoutelosbeyo   qre  a pitous vdiswe i\n",
      "rtnmeerte raseesotlmhe o ornaeilise eeeb\n",
      "yewt mfceei teoo netdetmorlo uye tkortth\n",
      "freetnisssioiho fmeteraaao rieo irfeeeo \n",
      "ooieenennso etlisiofa itraefscetr o ueso\n",
      "psi eesa orrsi emssetesno et estoosdseie\n",
      "tesu a elraseoretomoetisoi aoe slligy \n"
     ]
    }
   ],
   "source": [
    "gen_sonnet_seed(model, summer_start_ind, summer_end_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t they pay the vess chould not book ho l\n"
     ]
    }
   ],
   "source": [
    "# # choose random index \n",
    "# start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "# # 40 character snippet to seed new sequence\n",
    "# sentence = text[start_index: start_index + maxlen]\n",
    "\n",
    "# # or \n",
    "# # sentence = char_seed\n",
    "\n",
    "# # run through 400 characters\n",
    "# for i in range(400):\n",
    "#     # predictions 40 characters to choose by 61 possible characters\n",
    "#     x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "#     for t, char in enumerate(sentence):\n",
    "#         # fill in 1 at that character (row /40) in index of character (column)\n",
    "#         x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "#     # generate prob of next character (array of probabilites for each character)\n",
    "#     preds = model.predict(x_pred, verbose=0)[0]\n",
    "#     # pick character from distribution of pred (output=index)\n",
    "#     next_index = sample(preds, temperature)\n",
    "#     # use index to find character\n",
    "#     next_char = indices_char[next_index]\n",
    "\n",
    "#     # add character to sentence seeded, replace 1st character with last new character \n",
    "#     sentence = sentence[1:] + next_char\n",
    "\n",
    "# #     sys.stdout.write(next_char)\n",
    "# # sys.stdout.write(sentence)\n",
    "# # sys.stdout.flush()\n",
    "# print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
